<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- favicon-->
    <link rel="shortcut icon" href="assets/images/favicon.ico">
    <!-- Site Title-->
    <title>Xai - Website</title>
    <meta name="description" content="Science and technology for the eXplanation of AI decision making">
    <!-- Bootstrap CSS file-->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">
    <!-- Flickity CSS file-->
    <link href="assets/css/flickity.min.css" rel="stylesheet">
    <!-- Main CSS file-->
    <link href="assets/css/style.css" rel="stylesheet">
    <!-- Fontawesome 5 CSS file-->
    <link href="assets/css/fontawesome-all.min.css" rel="stylesheet">
    <!-- Magnific Popup CSS-->
    <link href="assets/css/magnific-popup.css" rel="stylesheet">
    <!-- Google Fonts-->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;700&amp;display=swap">
  </head>
  <body>
    <!-- Navbar-->
    <div class="site-header header-bottom-area">
      <nav class="navbar navbar-expand-lg navbar-light sticky">
        <div class="container"><a class="navbar-brand" href="index.html"><img class="site-logo" src="assets/images/logo/xai_logo_color.png" alt="Logo"></a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
          <div class="collapse navbar-collapse" id="navbarNavDropdown">
            <ul class="navbar-nav mx-auto">
              <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
              <li class="nav-item"><a class="nav-link" href="about.html">Project details</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="research-lines.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research Lines</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="line_1.html">Local to global</a><a class="dropdown-item" href="line_2.html">Casual reasoning</a><a class="dropdown-item" href="line_3.html">Platform and XUI</a><a class="dropdown-item" href="line_4.html">Case studies</a><a class="dropdown-item" href="line_5.html">Ethics and legal</a></div>
              </li>
              <li class="nav-item"><a class="nav-link" href="people.html">People</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="resources.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Publications and Resources</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="resources.html#publications">Publications</a><a class="dropdown-item" href="resources.html#thesis">Thesis</a></div>
              </li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="#" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">News</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="news.html">All News</a><a class="dropdown-item" href="dist-seminars.html">Distinguished seminars</a><a class="dropdown-item" href="internal-events.html">Internal Events</a></div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </div>
    <!-- End Navbar-->
    <article class="entry">
      <div class="entry-content">
        <div class="bg-yellow pt-6 pt-lg-8 pb-4 pb-lg-5">
          <div class="container">
            <div class="row">
              <div class="col-lg-8 offset-lg-2">
                <header class="entry-header text-center">
                  <h2 class="entry-title display-5 font-weight-bold">From statistical to causal and mechanistic, physical explanations</h2>
                </header>
              </div>
            </div>
          </div>
        </div>
        <!-- image-->
        <div class="bg-half">
          <div class="container">
            <div class="row justify-content-lg-center">
              <div class="col-lg-4">
                <div class="bg-black">
                  <div class="py-lg-7 px-lg-6 py-md-6 px-md-5 py-5 px-4">
                    <div class="text-white pr-lg-4 text-center">
                      <h1 class="display-1 mb-1 font-weight-bolder">2</h1>
                      <h5>LINE</h5>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="container mt-6">
          <div class="row justify-content-lg-center mt-6">
            <div class="col-lg-8">
              <!--h4 Abstract-->
              <p class="lead">We humans reason and understand in complementary and complex ways, and we think both fast and slow. When thinking slow, we reference previous evidence in our memory, and remember similar cases to the one we are dealing with; we reason logically, sometimes by first principles, trying to build a theory of the world, or directly applying said principles to the world; we often infer causal relationships between objects, allowing us to act purposefully to achieve our goals. These inherently human skills are usually lost both on the black box, which rarely relies on deliberate slow reasoning in favor of fast pattern matching, and on the explanations themselves, which rarely present the user with the tools to properly understand. Conversely, in fast thinking, we leverage heuristics, stereotypes, and approximations, and aim to get a “good enough” result while thinking the least amount possible. Unsurprisingly, fast thinking is a primary source of undesired outcomes and biased results. In XAI, we find this dichotomy in the different languages expressing explanations: fast thinking is predicated upon simple languages for fast and approximate understanding, such as feature importance, and prototypes, while slow thinking involves more complex languages and structures, such as logical theories, knowledge bases, and causal models.</p>
              <p class="lead">In this research line, we aim to integrate slow thinking along three different and possibly complementary directions, namely causality, knowledge injection, and logical reasoning. Orthogonally to these directions, we aim to target slow thinking both internally to the explanation algorithm, that is, to have the explanation algorithm itself think slowly, and by design, that is, to have the black box itself thinking slowly.</p>
              <h5 class="mt-6">2.1 Causality</h5>Inferring a causal model is central to properly understanding a phenomenon. Following [6], a synergy paper with the HumaneAI project, where we survey the causal literature, we identify two families of causal models: graphical models, in which we infer the causal relationships and induced distributions of observed variables, and potential outcome models, in which we assume observed variables to be the outcome of a causal model, and we look to infer the counterfactual outcome of an intervention in the model. Graphical models encode variables and their conditional dependency relations, allowing us to understand what variables influence others. Pearl's do-calculus introduced a formal calculus for intervention on causal models, allowing their users to purposefully act on the data knowing what each action will result into. Inferring a causal model is of benefit both for the user, who can test interventional actions, and to the black box, that can leverage it to perform better predictions. Explanation algorithms can leverage causal models for better feature importance computation, as it is the case for our proposal CALIME [CG21], in which we learn a causal model to infer feature importance in a principled way. We detail our work in Attachment A.1.3
              <h5 class="mt-6">2.2 Knowledge integration</h5>Modern black boxes tend to rely on neural and subsymbolic approaches that are in stark contrast with human knowledge, which is usually symbolic in nature. The XAI community has shown an increasing interest both in symbolic knowledge injection in subsymbolic models [7], and more generally in neuro-symbolic integration. This trend is of great interest for domains with large knowledge bases, such as healthcare and Natural Language Processing (NLP) [8]. Several NLP tasks can leverage external structured and unstructured knowledge in the form of structured knowledge bases [9], e.g., Wikipedia, or free-form text [10]. This allows the models to leverage a set of relevant facts in the knowledge base, and provide them to the user to explain its reasoning. Some recent approaches go as far as using the whole live and raw web as a knowledge base, and search through it for useful facts to aid the prediction. Aside from injection, background knowledge can also be used post-hoc to align the black box learned concepts with given concepts. Besides a review of the literature, in this stream of research we have proposed two works: Doctor XAI [PPP2020], already presented in Section 1.3, and TriplEx [SMM2021].
              <h6 class="mt-3">2.2.1 TriplEx</h6>In [SMM2021] we have developed TriplEx, an algorithm for explanation of Transformer-based models. TriplEx aims to locally explain text classification models on a plethora of tasks: natural language inference, semantic text similarity, and text classification.
              Given some text x to classify, TriplEx extracts a set of factual triples T, which form the basis of the explanation. Then, TriplEx looks for perturbations of T along given semantic dimensions, which vary according to the task at hand, to look for edge cases in which the black box’s prediction is preserved. In other words, TriplEx looks to generate a semi-factual explanation. The search for perturbations is guided by an external knowledge base, specifically WordNet, that allows TriplEx to perturb text along different semantic dimensions. Keeping with our running example, TriplEx may perturb “mice” and replace it with “rodent” to verify whether the model has learned to apply the same reasoning with all rodents, and not just mice. Finally, TriplEx ranks the label-preserving perturbations according to their semantic distance: the larger the semantic perturbation, the better. Additionally, for Transformer models, TriplEx also provides an alignment score of each triple, indicating what triple is more relevant for the black box, allowing the user to have a finer granularity of explanation. TriplEx extracts explanations which are correct by construction, and semantic perturbations tend to be realistic and plausible, as measured by perplexity, an automatic evaluation of the plausibility of some text. Semantic perturbations retain realistic text, indicating that leveraging semantic perturbations does indeed generate realistic explanations.
              <h5 class="mt-6">2.3 Logic reasoning</h5>Logic is one of the most powerful languages to express slow thinking, as it enjoys several desirable properties. Logic programming allows us to induce discrete, noise-resistant, and explainable/declarative by design “programs as rules” with high levels of abstraction that mimics human reasoning. Derivations in logic yield deterministic proof trees that a user can inspect. Furthermore, logic programming lends itself to background knowledge injection, allowing the user to guide the model, even if partially, with concepts and theories that they already know to be true. These properties make it a perfect candidate language for slow thinking explanations.
              Statistical Relational Learning (STAR) aims to integrate logics, and by and large relational learning, and statistical learning. Some models, for instance, integrate a subsymbolic component, given by a black box, and a symbolic one, given by a logical theory, in an explainable by-design pipeline in which the black box is only tasked with learning a mapping from data to logical entities, and the logical theory is tasked with reasoning on top of the entities. An even tighter integration is presented by models directly encoding logic theories and predicates in subsymbolic structures, which often map logic connectives and quantifiers to predefined norms. Other works aim to constrain black box models with given knowledge in the form of First-Order Rules, or to extract a set of logical constraints learned by the black box.
              Our core approaches (LORE, GLocalX) are essentially logic-based, since they produce explanations in the form of rules (either directly inferred or as the result of abstracting sets of rules), and therefore it is natural to consider the surveyed logic-based approaches as candidates for extending the expressiveness of the explanation language of LORE and of the rule reasoning approach of GLocalX
            </div>
          </div>
        </div>
      </div>
      <div class="entry-content">
        <div class="bg-yellow pt-6 pt-lg-8 pb-4 pb-lg-5 mt-5">
          <div class="container">
            <div class="row"></div>
          </div>
        </div>
        <!-- image-->
        <div class="bg-half">
          <div class="container">
            <div class="row">
              <div class="col-lg-4">
                <div class="bg-black">
                  <div class="py-lg-5 px-lg-6 py-md-5 px-md-5 py-5 px-4">
                    <div class="text-white pr-lg-4 text-center">
                      <h3 class="mb-1 font-weight-bolder" id="publications">Publications</h3>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="container mb-6">
          <div class="row">
            <div class="row mt-5 justify-content-center" id="BGM2021">
              <div class="col-lg-1 text-right">
                <h4>22.</h4><small>[BGM2021]</small>
              </div>
              <div class="col-lg-8 bg-yellow p-3">
                <div class="accordion" id="accordion-twenty-one"></div><strong>Deriving a Single Interpretable Model by Merging Tree-Based Classifiers</strong><br><em>Bonsignori Valerio, Guidotti Riccardo, Monreale Anna</em> (2021) - Discovery Science
                <div class="collapse" id="collapse-twenty-one" aria-labelledby="heading-twenty-one" data-parent="#accordion-twenty-one">
                  <div class="bg-yellow">
                    <hr>
                    <p class="small"><strong>Abstract</strong></p>
                    <p class="small">Decision tree classifiers have been proved to be among the most interpretable models due to their intuitive structure that illustrates decision processes in form of logical rules. Unfortunately, more complex tree-based classifiers such as oblique trees and random forests overcome the accuracy of decision trees at the cost of becoming non interpretable. In this paper, we propose a method that takes as input any tree-based classifier and returns a single decision tree able to approximate its behavior. Our proposal merges tree-based classifiers by an intensional and extensional approach and applies a post-hoc explanation strategy. Our experiments shows that the retrieved single decision tree is at least as accurate as the original tree-based model, faithful, and more interpretable.</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-2 pl-3">
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-twenty-one" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="http://dx.doi.org/10.1007/978-3-030-88942-5_27" target="_blank">External Link</a></p>
                <p class="my-1"><small>Research Line <strong>1▪2</strong></small></p>
              </div>
              <div class="row mt-5 justify-content-center" id="GMP2019"></div>
              <div class="col-lg-1 text-right">
                <h4>43.</h4><small>[GMP2019]</small>
              </div>
              <div class="col-lg-8 bg-yellow p-3">
                <div class="accordion" id="accordion-forty-two"></div><strong>The AI black box explanation problem</strong><br><em>Guidotti Riccardo, Monreale Anna, Pedreschi Dino</em> (2019) - ERCIM News, 116, 12-13. In ERCIM News, 116, 12-13
                <div class="collapse" id="collapse-forty-two" aria-labelledby="heading-forty-two" data-parent="#accordion-forty-two">
                  <div class="bg-yellow">
                    <hr>
                    <p class="small"><strong>Abstract</strong></p>
                    <p class="small">nan</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-2 pl-3">
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://ercim-news.ercim.eu/images/stories/EN116/EN116-web.pdf#page=12" target="_blank">External Link</a></p>
                <p class="my-1"><small>Research Line <strong>1▪2▪3</strong></small></p>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="entry-content mt-0">
        <div class="container mb-10">
          <div class="row gx-lg-3 gy-3 mt-lg-4 mt-md-2 mt-2 mb-5">
            <h3>Researchers working on this line</h3>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Turini.jpg" alt="Franco Turini"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Franco<br/>Turini</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Full Professor</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 2 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Ruggieri.jpg" alt="Salvatore Ruggieri"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Salvatore<br/>Ruggieri</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Full Professor</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 2</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Setzu.jpg" alt="Mattia Setzu"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Mattia<br/>Setzu</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 2</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Metta.jpg" alt="Carlo Metta"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Carlo<br/>Metta</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Researcher</span></div>
                  <p class="mb-0">ISTI - CNR Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 2 ▪ 3 ▪4</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Beretta_.jpg" alt="Isacco Beretta_"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Isacco<br/>Beretta</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>2</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Marchiori Manerba.jpg" alt="Marta Marchiori Manerba"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Marta<br/>Marchiori Manerba</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 2 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Fontana.jpg" alt="Michele Fontana"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Michele<br/>Fontana</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0"></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Cinquini.jpg" alt="Martina Cinquini"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Martina<br/>Cinquini</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 2</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
          </div>
        </div>
      </div>
    </article>
    <!-- Footer-->
    <footer class="site-footer">
      <div class="footer-widgets">
        <div class="container">
          <div class="row gx-lg-5">
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-1">
                <h4 class="text-yellow mb-3">Principal Investigator</h4>
                <div class="text-white">
                  <p class="mb-0">Fosca Giannotti</p>
                  <p class="mb-0">Scuola Normale Superiore</p><br>
                  <p class="mb-0">Piazza dei Cavalieri, 7</p>
                  <p class="mb-0">56126 Pisa, Italy</p><br>
                  <p class="mb-0">Email: fosca.giannotti @ sns.it</p>
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-4">
                <div class="text-white">
                  <p>The XAI Project receives funding from the European Union's Horizon 2020 Excellent Science European Research Council (ERC) programme under grant agreement No. 834756</p>The views and opinions expressed in this website are the sole responsibility of the author and do not necessarily reflect the views of the European Commission.
                  <p></p><img class="mb-4" src="assets/images/logo-eu.jpg" alt="EU flag">
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-2">
                <ul>
                  <li><a href="index.html">Xai</a></li>
                  <li><a href="about.html">Project details</a></li>
                  <li><a href="research-lines.html">Research lines</a></li>
                  <li><a href="people.html">People</a></li>
                  <li><a href="resources.html">Resources</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="footer-bottom-area">
        <div class="container">
          <div class="row gx-lg-5 align-items-center">
            <div class="col-md-12"><span class="text-yellow strong">Webdesign: Daniele Fadda © 2022</span></div>
          </div>
        </div>
      </div>
    </footer>
    <!-- End Footer-->
    <!-- javascript files-->
    <!-- jquery-->
    <script src="assets/js/jquery.min.js"></script>
    <!-- lozad js-->
    <script src="assets/js/lozad.min.js"></script>
    <!-- Bootstrap js-->
    <script src="assets/js/bootstrap.bundle.min.js"></script>
    <!-- Aos js-->
    <script src="assets/js/aos.js"></script>
    <!-- Slick flickity js-->
    <script src="assets/js/flickity.pkgd.min.js"></script>
    <!-- Magnific popup js-->
    <script src="assets/js/jquery.magnific-popup.min.js"></script>
    <!-- Countdown js-->
    <script src="assets/js/jquery.countdown.js"></script>
    <!-- CountTo js-->
    <script src="assets/js/jquery.countTo.js"></script>
    <!-- Global - Main js-->
    <script src="assets/js/global.js"></script>
  </body>
</html>