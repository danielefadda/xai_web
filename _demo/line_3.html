<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- favicon-->
    <link rel="shortcut icon" href="assets/images/favicon.ico">
    <!-- Site Title-->
    <title>Xai - Website</title>
    <meta name="description" content="Science and technology for the eXplanation of AI decision making">
    <!-- Bootstrap CSS file-->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">
    <!-- Flickity CSS file-->
    <link href="assets/css/flickity.min.css" rel="stylesheet">
    <!-- Main CSS file-->
    <link href="assets/css/style.css" rel="stylesheet">
    <!-- Fontawesome 5 CSS file-->
    <link href="assets/css/fontawesome-all.min.css" rel="stylesheet">
    <!-- Magnific Popup CSS-->
    <link href="assets/css/magnific-popup.css" rel="stylesheet">
    <!-- Google Fonts-->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;700&amp;display=swap">
    <script type="text/javascript">
      // Matomo Code
      var _paq = window._paq = window._paq || [];
      /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
      _paq.push(['trackPageView']);
      _paq.push(['enableLinkTracking']);
      (function () {
      var u="//piwikdd.isti.cnr.it/";
      _paq.push(['setTrackerUrl', u+'piwik.php']);
      _paq.push(['setSiteId', '12']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
      })
      ();
    </script>
  </head>
  <body>
    <!-- Navbar-->
    <div class="site-header header-bottom-area">
      <nav class="navbar navbar-expand-lg navbar-light sticky">
        <div class="container"><a class="navbar-brand" href="index.html"><img class="site-logo" src="assets/images/logo/xai_logo_color.png" alt="Logo"></a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
          <div class="collapse navbar-collapse" id="navbarNavDropdown">
            <ul class="navbar-nav mx-auto">
              <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
              <li class="nav-item"><a class="nav-link" href="about.html">Project details</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="research-lines.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research Lines</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="line_1.html">1. Local to global</a><a class="dropdown-item" href="line_2.html">2. Casual reasoning</a><a class="dropdown-item" href="line_3.html">3. Platform and XUI</a><a class="dropdown-item" href="line_4.html">4. Case studies</a><a class="dropdown-item" href="line_5.html">5. Ethics and legal</a></div>
              </li>
              <li class="nav-item"><a class="nav-link" href="people.html">People</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="resources.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Publications and Resources</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="resources.html#publications">Publications</a><a class="dropdown-item" href="resources.html#thesis">Thesis</a></div>
              </li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="#" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">News</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="news.html">All News</a><a class="dropdown-item" href="dist-seminars.html">Distinguished seminars</a><a class="dropdown-item" href="internal-events.html">Internal Events</a></div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </div>
    <!-- End Navbar-->
    <article class="entry">
      <div class="entry-content">
        <div class="bg-yellow pt-6 pt-lg-8 pb-4 pb-lg-5">
          <div class="container">
            <div class="row">
              <div class="col-lg-8 offset-lg-2">
                <header class="entry-header text-center">
                  <h2 class="entry-title display-5 font-weight-bold">XAI Platform</h2>
                </header>
              </div>
            </div>
          </div>
        </div>
        <!-- image-->
        <div class="bg-half">
          <div class="container">
            <div class="row justify-content-lg-center">
              <div class="col-lg-4">
                <div class="bg-black">
                  <div class="py-lg-7 px-lg-6 py-md-6 px-md-5 py-5 px-4">
                    <div class="text-white pr-lg-4 text-center">
                      <h1 class="display-1 mb-1 font-weight-bolder">3</h1>
                      <h5>LINE</h5>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="container mt-6">
          <div class="row justify-content-lg-center mt-6">
            <div class="col-lg-8">
              <!--h4 Abstract-->
              <p class="lead">The objective of this line is the design and development of a XAI watchdog platform, i.e. an user interface that aims to explain a black-box model by acknowledging different types of explanations for different types of users and providing interactive explanations that the user can navigate. We started the design from the analysis of methods produced in the other research lines and popular approaches from the literature. The objective of the exploration is twofold: (i) identify algorithms and methods to construct the explanations around a bloack box; (ii) build an explanation process where the user can interact with both the black box model and the explanation layer, possibly combining multiple explanation methods with different capabilities. This brings to a platform design consisting of two parts: a software library that integrates a wide set of explanation methods, XAILib; a XUI (eXplainable User Interface) human-computer interface to let the users interact with the explanation layer</p>
              <h5 class="mt-6">XAI-Library</h5>The library has the objective of integrating in a coherent platform explanation algorithms developed within the XAI project or published in the literature. The main architecture of the library distinguishes three data types: tabular data; images data; text data.
              To have a uniform interface for a blackbox to be explained a dedicated wrapper has been designed that will expose all the functionalities required for classify instances from the model. The objective is to define a high-level grammar to setup an explanable analytical pipeline. By design, the library does not make any assumption on the models to be explained, but it relies on a set of interfaces designed around the most diffuse ML libraries (i.e. SciKit Learn, Keras, Tensorflow, Pytorch). For instance, a predict method is shared among the subclasses of the wrapper to adapt to models coming from any of these libraries. The wrapper is also responsible to apply data transformation to the instances to be classified to have a uniform data layer for all the methods.
              Different explanation methods generate different explanation formats. Thus, we defined a software interface to encapsulate the different explanation formats, by focusing on a classification of capabilities for each explanation. The functionalities we identified are: feature importance, exemplars, counterexemplars, rules, counterfactual rules. An explanation method can provide one or more of these capabilities, by implementing the corresponding method. The design of the library promotes the extension of the repertoire of methodologies with new ones. The interface allows to integrate existing methods and existing implementation (i.e. external explanation methods) easily, providing only the wrapper implementation.
              At the time of writing the library has been extended with methods proposed by our research team (LORE [GMG2019], ABELE [GMM2019], LASTS [GMS2020]) and taken from the literature (LIME [1], SHAP [11], IntGrad [16], GradCam [17], NAM [18], RISE [18]).
              The library has been exploited to power a few real-world case studies (detailed in the next section). These analytical cases gave us the possibility to prove the validity of the analytical pipeline of the library and to design suitable visual interfaces to deliver the outcome of the explanation to the final user. At the time of writing, the library has been used to create three interfaces for explanation methods in the healthcare domain.
              <div class="pb-md-2 mt-4"><a class="btn btn-outline-black" href="https://pypi.org/project/XAI-Library/" target="_blank">LINK TO THE REPOSITORY</a></div>
              <h5 class="mt-6">The Cardiac Risk evaluator</h5>The Cardiac Risk evaluator [] is a model developed by University of Coimbra for evaluating the probability of death for cardiac reasons in patients admitted to the Emergency Room. We developed a visual interface (to be submitted) to provide local explanations for each classified case. The explanation application exploits the LORE method of the library to provide a set of rules and counterfactual rules to give to the practitioner an explanation of the outcome of the model. A web-based visual interface provides the doctor with an interactive module where the specialist may probe the classification model by means of “what-if” queries and explanations. Besides the explanation capabilities, in collaboration with University of Coimbra, the interface introduces a verification-based approach based on model-testing to compute and visualize the confidence for the prediction, so that the user can better ponder the decision of the algorithm. This verification addresses two aspects: (i) a model-checker exploration of the neighborhood of the instance to discover opposite cases; (ii) a theorem prover to check the compliance of the proposed counter rules with a set of prior knowledge constraints of the case. The interface introduces a novel visual-based widget to explore cases related to the instance to be classified as suggested by the rule and counter-rule. A progressive exploration of the space of possibilities is enabled by a visual timeline that summarizes the path of exploration of the doctor, highlighting the progress of the related cases.
              <div class="pb-md-2 mt-4"><a class="btn btn-outline-black" href="https://kdd.isti.cnr.it/cre_vue" target="_blank">LINK TO THE PLATFORM</a></div>
              <h5 class="mt-6">Doctor XAI</h5>Doctor XAI [PPP2020] provides an explanation for the prediction of the next most probable diagnoses for a patient, given his/her recent clinical history. We developed a visual interface that exploits the progressive disclosure of information related to a local instance to be classified and explained. The explanation method relies on LORE and brigns evidence to the practitioners about relevant diagnoses and their temporal evolution. The complexity of this information is presented and modulated through a progressive disclosure mechanism, where not all the information is shown at once, but it is sequenced, with advanced features shown only in secondary views and only at the request of the user. This approach allows also to create separate interfaces with different levels of concepts, for example stopping at the first stages for the patient and giving the possibility to explore further for the medical specialist. Not all users need the same amount of information, and providing all information at once may be overwhelming.
              In  [MGY2021] we built a dedicated interface for an explainer, based on ABELE [GMM2019], for a black-box to classify instances of skin lesions images. The interface is developed to help physicians in the diagnosis of skin cancer. Following the principles of using multiple explanation methods, after classifying an instance, users are presented with two different explanation methods. A counterexample that shows an image classified differently, and a set of prototype images with the same classification.
              <div class="pb-md-2 mt-4"><a class="btn btn-outline-black" href="https://kdd.isti.cnr.it/DrXAI-viz" target="_blank">LINK TO THE PLATFORM</a></div>
            </div>
          </div>
        </div>
      </div>
      <div class="entry-content">
        <div class="bg-yellow pt-6 pt-lg-8 pb-4 pb-lg-5 mt-5">
          <div class="container">
            <div class="row"></div>
          </div>
        </div>
        <!-- image-->
        <div class="bg-half">
          <div class="container">
            <div class="row">
              <div class="col-lg-4">
                <div class="bg-black">
                  <div class="py-lg-5 px-lg-6 py-md-5 px-md-5 py-5 px-4">
                    <div class="text-white pr-lg-4 text-center">
                      <h3 class="mb-1 font-weight-bolder" id="publications">Publications</h3>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="container mb-6">
          <div class="row">
            <div class="row mt-5 justify-content-center" id="GMR2018">
              <div class="col-lg-1 text-right">
                <h4>1.</h4><small>[GMR2018]</small>
              </div>
              <div class="col-lg-8 bg-yellow p-3">
                <div class="accordion" id="accordion-zero"></div><strong>A Survey of Methods for Explaining Black Box Models</strong><br><em>Guidotti Riccardo, Monreale Anna, Ruggieri Salvatore, Turini Franco, Giannotti Fosca, Pedreschi Dino</em> (2022) - ACM Computing Surveys. In ACM computing surveys (CSUR), 51(5), 1-42.
                <div class="collapse" id="collapse-zero" aria-labelledby="heading-zero" data-parent="#accordion-zero">
                  <div class="bg-yellow">
                    <hr>
                    <p class="small"><strong>Abstract</strong></p>
                    <p class="small">In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-2 pl-3">
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-zero" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="http://dx.doi.org/10.1145/3236009" target="_blank">External Link</a></p>
                <p class="my-1"><small>Research Line <strong>1▪3</strong></small></p>
              </div>
              <div class="row mt-5 justify-content-center" id="BRF2022"></div>
              <div class="col-lg-1 text-right">
                <h4>7.</h4><small>[BRF2022]</small>
              </div>
              <div class="col-lg-8 bg-yellow p-3">
                <div class="accordion" id="accordion-six"></div><strong>Explaining Black Box with visual exploration of Latent Space</strong><br><em>Bodria Francesco, Rinzivillo Salvatore, Fadda Daniele, Guidotti Riccardo, Fosca Giannotti, Pedreschi Dino</em> (2022) - EUROVIS 2022
                <div class="collapse" id="collapse-six" aria-labelledby="heading-six" data-parent="#accordion-six">
                  <div class="bg-yellow">
                    <hr>
                    <p class="small"><strong>Abstract</strong></p>
                    <p class="small">Autoencoders are a powerful yet opaque feature reduction technique, on top of which we propose a novel way for the joint visual exploration of both latent and real space. By interactively exploiting the mapping between latent and real features, it is possible to unveil the meaning of latent features while providing deeper insight into the original variables. To achieve this goal, we exploit and re-adapt existing approaches from eXplainable Artificial Intelligence (XAI) to understand the relationships between the input and latent features. The uncovered relationships between input features and latent ones allow the user to understand the data structure concerning external variables such as the predictions of a classification model. We developed an interactive framework that visually explores the latent space and allows the user to understand the relationships of the input features with model prediction.</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-2 pl-3">
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-six" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
                <p class="my-1"><small>Research Line <strong>3</strong></small></p>
              </div>
              <div class="row mt-5 justify-content-center" id="GMP2019"></div>
              <div class="col-lg-1 text-right">
                <h4>44.</h4><small>[GMP2019]</small>
              </div>
              <div class="col-lg-8 bg-yellow p-3">
                <div class="accordion" id="accordion-forty-three"></div><strong>The AI black box explanation problem</strong><br><em>Guidotti Riccardo, Monreale Anna, Pedreschi Dino</em> (2019) - ERCIM News, 116, 12-13. In ERCIM News, 116, 12-13
                <div class="collapse" id="collapse-forty-three" aria-labelledby="heading-forty-three" data-parent="#accordion-forty-three">
                  <div class="bg-yellow">
                    <hr>
                    <p class="small"><strong>Abstract</strong></p>
                    <p class="small">nan</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-2 pl-3">
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://ercim-news.ercim.eu/images/stories/EN116/EN116-web.pdf#page=12" target="_blank">External Link</a></p>
                <p class="my-1"><small>Research Line <strong>1▪2▪3</strong></small></p>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="entry-content mt-0">
        <div class="container mb-10">
          <div class="row gx-lg-3 gy-3 mt-lg-4 mt-md-2 mt-2 mb-5">
            <h3>Researchers working on this line</h3>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Guidotti.jpg" alt="Riccardo Guidotti"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Riccardo<br/>Guidotti</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Assitant Professor</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 3 ▪ 4 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Rinzivillo.jpg" alt="Salvo Rinzivillo"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Salvo<br/>Rinzivillo</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Researcher</span></div>
                  <p class="mb-0">ISTI - CNR Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 3 ▪ 4 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Fadda.jpg" alt="Daniele Fadda"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Daniele<br/>Fadda</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Researcher</span></div>
                  <p class="mb-0">ISTI - CNR Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>3</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Naretto.jpg" alt="Francesca Naretto"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Francesca<br/>Naretto</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0">Scuola Normale</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 3 ▪ 4 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Bodria.jpg" alt="Francesco Bodria"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Francesco<br/>Bodria</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0">Scuola Normale</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 3</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Metta.jpg" alt="Carlo Metta"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Carlo<br/>Metta</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Researcher</span></div>
                  <p class="mb-0">ISTI - CNR Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 2 ▪ 3 ▪4</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Cappuccio.jpg" alt="Eleonora Cappuccio"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Eleonora<br/>Cappuccio</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0">University of Pisa - Bari</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>3 ▪ 4</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Malizia.jpg" alt="Alessio Malizia"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Alessio<br/>Malizia</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Associate Professor</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 3 ▪ 4</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
          </div>
        </div>
      </div>
    </article>
    <!-- Footer-->
    <footer class="site-footer">
      <div class="footer-widgets">
        <div class="container">
          <div class="row gx-lg-5">
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-1">
                <h4 class="text-yellow mb-3">Principal Investigator</h4>
                <div class="text-white">
                  <p class="mb-0">Fosca Giannotti</p>
                  <p class="mb-0">Scuola Normale Superiore</p><br>
                  <p class="mb-0">Piazza dei Cavalieri, 7</p>
                  <p class="mb-0">56126 Pisa, Italy</p><br>
                  <p class="mb-0">Email: fosca.giannotti @ sns.it</p>
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-4">
                <div class="text-white">
                  <p>The XAI Project receives funding from the European Union's Horizon 2020 Excellent Science European Research Council (ERC) programme under grant agreement No. 834756</p>The views and opinions expressed in this website are the sole responsibility of the author and do not necessarily reflect the views of the European Commission.
                  <p></p><img class="mb-4" src="assets/images/logo-eu.jpg" alt="EU flag">
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-2">
                <ul>
                  <li><a href="index.html">Xai</a></li>
                  <li><a href="about.html">Project details</a></li>
                  <li><a href="research-lines.html">Research lines</a></li>
                  <li><a href="people.html">People</a></li>
                  <li><a href="resources.html">Resources</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="footer-bottom-area">
        <div class="container">
          <div class="row gx-lg-5 align-items-center">
            <div class="col-md-12"><span class="text-yellow strong">Webdesign: Daniele Fadda © 2022</span></div>
          </div>
        </div>
      </div>
    </footer>
    <!-- End Footer-->
    <!-- javascript files-->
    <!-- jquery-->
    <script src="assets/js/jquery.min.js"></script>
    <!-- lozad js-->
    <script src="assets/js/lozad.min.js"></script>
    <!-- Bootstrap js-->
    <script src="assets/js/bootstrap.bundle.min.js"></script>
    <!-- Aos js-->
    <script src="assets/js/aos.js"></script>
    <!-- Slick flickity js-->
    <script src="assets/js/flickity.pkgd.min.js"></script>
    <!-- Magnific popup js-->
    <script src="assets/js/jquery.magnific-popup.min.js"></script>
    <!-- Countdown js-->
    <script src="assets/js/jquery.countdown.js"></script>
    <!-- CountTo js-->
    <script src="assets/js/jquery.countTo.js"></script>
    <!-- Global - Main js-->
    <script src="assets/js/global.js"></script>
  </body>
</html>