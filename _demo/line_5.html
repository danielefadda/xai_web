<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- favicon-->
    <link rel="shortcut icon" href="assets/images/favicon.ico">
    <!-- Site Title-->
    <title>Xai - Website</title>
    <meta name="description" content="Science and technology for the eXplanation of AI decision making">
    <!-- Bootstrap CSS file-->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">
    <!-- Flickity CSS file-->
    <link href="assets/css/flickity.min.css" rel="stylesheet">
    <!-- Main CSS file-->
    <link href="assets/css/style.css" rel="stylesheet">
    <!-- Fontawesome 5 CSS file-->
    <link href="assets/css/fontawesome-all.min.css" rel="stylesheet">
    <!-- Magnific Popup CSS-->
    <link href="assets/css/magnific-popup.css" rel="stylesheet">
    <!-- Google Fonts-->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;700&amp;display=swap">
  </head>
  <body>
    <!-- Navbar-->
    <div class="site-header header-bottom-area">
      <nav class="navbar navbar-expand-lg navbar-light sticky">
        <div class="container"><a class="navbar-brand" href="index.html"><img class="site-logo" src="assets/images/logo/xai_logo_color.png" alt="Logo"></a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
          <div class="collapse navbar-collapse" id="navbarNavDropdown">
            <ul class="navbar-nav mx-auto">
              <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
              <li class="nav-item"><a class="nav-link" href="about.html">Project details</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="research-lines.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research Lines</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="line_1.html">Local to global</a><a class="dropdown-item" href="line_2.html">Casual reasoning</a><a class="dropdown-item" href="line_3.html">Platform and XUI</a><a class="dropdown-item" href="line_4.html">Case studies</a><a class="dropdown-item" href="line_5.html">Ethics and legal</a></div>
              </li>
              <li class="nav-item"><a class="nav-link" href="people.html">People</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="resources.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Publications and Resources</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="resources.html#publications">Publications</a><a class="dropdown-item" href="resources.html#thesis">Thesis</a></div>
              </li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="#" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">News</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="news.html">All News</a><a class="dropdown-item" href="dist-seminars.html">Distinguished seminars</a><a class="dropdown-item" href="internal-events.html">Internal Events</a></div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </div>
    <!-- End Navbar-->
    <article class="entry">
      <div class="entry-content">
        <div class="bg-yellow pt-6 pt-lg-8 pb-4 pb-lg-5">
          <div class="container">
            <div class="row">
              <div class="col-lg-8 offset-lg-2">
                <header class="entry-header text-center">
                  <h2 class="entry-title display-5 font-weight-bold">Ethical/legal framework for explanation</h2>
                </header>
              </div>
            </div>
          </div>
        </div>
        <!-- image-->
        <div class="bg-half">
          <div class="container">
            <div class="row justify-content-lg-center">
              <div class="col-lg-4">
                <div class="bg-black">
                  <div class="py-lg-7 px-lg-6 py-md-6 px-md-5 py-5 px-4">
                    <div class="text-white pr-lg-4 text-center">
                      <h1 class="display-1 mb-1 font-weight-bolder">5</h1>
                      <h5>LINE</h5>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="container mt-6">
          <div class="row justify-content-lg-center mt-6">
            <div class="col-lg-8">
              <!--h4 Abstract-->
              <p class="lead">Explainability is one of the most important ethical and legal values identified by EU regulations (GDPR, AI act). However, when we design a trustworthy AI System it is important to take into consideration also the other ethical and legal values such as privacy, fairness, safety, robustness, etc. This requires analyzing the interplay among the different values and understanding whether they are in contrast or not.</p>In this direction, the work of Line 5 has started the investigation of the interplay between explainability and privacy, and explainability and fairness under different viewpoints. In particular, the research of this line tries to answer the following questions:<br><br>
              <ol>
                <li>Can explanation methods, introducing a level of transparency in the whole decision process, might jeopardize individual privacy of people represented in the training data?</li>
                <li>Can explanation methods help in understanding the reason for possible ethical risks  associated with the use of AI systems (e.g., privacy violations and biased behaviors)?</li>
                <li>Can explanation methods be fundamental for discovering other ethical issues like unfair behavior of AI systems?</li>
              </ol>Starting from these questions, we have scientifically contributed with the following studies.
              Concerning the ability of explanation methods to explain some ethical risks such as privacy and biases, in [NPM2020,NPN2020] we propose EXPERT, an EXplainable Privacy ExposuRe predicTion framework. It is a tool that exploits Explainability as a tool for increasing privacy user awareness. We applied EXPERT on the privacy risk prediction and explanation of both tabular data [NPM2020] and sequential data [NPN2020]. In the first setting we considered the mobility context where for each user we have the historical movements (a spatio-temporal trajectory). In this context, EXPERT using the privacy risk exposure module extracts from human mobility data an individual mobility profile describing the mobility behavior of any user. Second, for each user it simulates a privacy attack and quantifies the associated privacy risk. Third, it uses the mobility profiles of the users with their associated privacy risks to train a ML model. For a new user, along with the prediction of risk, EXPERT also provides an explanation of the predicted risk generated by the risk explanation module. EXPERT exploits two state-of-the-art explanation techniques, i.e., SHAP [11] and LORE [GMG2019]. In the second setting  [NPN2020] the prediction phase is not based on a mobility profile but on the trajectory itself and given the absence of features we used only SHAP as an explanation method.
              In [PPP2021] we also present FairLens, a framework able to detect and explain potential bias issues in Clinical Decision Support Systems (DSS). FairLens allows testing the clinical DSS before its deployment, i.e., before handling it to final decision-makers such as physicians and nurses. FairLens takes bias analysis a step further by explaining the reasons behind the poor model performance on specific groups; in particular,  it uses GlocalX to explain which elements in the patients’ clinical histories are influencing the misclassification.<br><br>Concerning the use of explainability as a means for discovering unfair behaviors, in [MG2021], we propose FairShades, a model-agnostic approach for auditing the outcomes of abusive language detection systems. FairShades combines explainability and fairness evaluation within a proactive pipeline to identify unintended biases and sensitive categories toward which the black box model under assessment is most discriminative. It is a task-specific approach for abusive language detection: it can be used to test the fairness of any abusive language detection system working on any textual dataset. However, its ideal application is on sentences containing protected identities, i.e., expressions referring to nationality, gender, etc., as the primary scope is to uncover biases and not explain the reasons for the prediction.
            </div>
          </div>
        </div>
      </div>
      <div class="entry-content">
        <div class="bg-yellow pt-6 pt-lg-8 pb-4 pb-lg-5 mt-5">
          <div class="container">
            <div class="row"></div>
          </div>
        </div>
        <!-- image-->
        <div class="bg-half">
          <div class="container">
            <div class="row">
              <div class="col-lg-4">
                <div class="bg-black">
                  <div class="py-lg-5 px-lg-6 py-md-5 px-md-5 py-5 px-4">
                    <div class="text-white pr-lg-4 text-center">
                      <h3 class="mb-1 font-weight-bolder" id="publications">Publications</h3>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="container mb-6">
          <div class="row">
            <div class="row mt-5 justify-content-center" id="MG2022">
              <div class="col-lg-1 text-right">
                <h4>5.</h4><small>[MG2022]</small>
              </div>
              <div class="col-lg-8 bg-yellow p-3">
                <div class="accordion" id="accordion-four"></div><strong>Investigating Debiasing Effects on Classification and Explainability</strong><br><em>Marta Marchiori Manerba, Guidotti Riccardo</em> (2022) - Conference on AI, Ethics, and Society (AIES 2022). In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES'22)
                <div class="collapse" id="collapse-four" aria-labelledby="heading-four" data-parent="#accordion-four">
                  <div class="bg-yellow">
                    <hr>
                    <p class="small"><strong>Abstract</strong></p>
                    <p class="small">During each stage of a dataset creation and development process, harmful biases can be accidentally introduced, leading to models that perpetuates marginalization and discrimination of minorities, as the role of the data used during the training is critical. We propose an evaluation framework that investigates the impact on classification and explainability of bias mitigation preprocessing techniques used to assess data imbalances concerning minorities' representativeness and mitigate the skewed distributions discovered. Our evaluation focuses on assessing fairness, explainability and performance metrics. We analyze the behavior of local model-agnostic explainers on the original and mitigated datasets to examine whether the proxy models learned by the explainability techniques to mimic the black-boxes disproportionately rely on sensitive attributes, demonstrating biases rooted in the explainers. We conduct several experiments about known biased datasets to demonstrate our proposal’s novelty and effectiveness for evaluation and bias detection purposes.</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-2 pl-3">
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-four" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
                <p class="my-1"><small>Research Line <strong>1▪5</strong></small></p>
              </div>
              <div class="row mt-5 justify-content-center" id="CDF2021"></div>
              <div class="col-lg-1 text-right">
                <h4>11.</h4><small>[CDF2021]</small>
              </div>
              <div class="col-lg-8 bg-yellow p-3">
                <div class="accordion" id="accordion-ten"></div><strong>Trustworthy AI</strong><br><em>Chatila Raja, Dignum Virginia, Fisher Michael, Giannotti Fosca, Morik Katharina, Russell Stuart, Yeung Karen</em> (2022) - Reflections on Artificial Intelligence for Humanity. In Lecture Notes in Computer Science,
                <div class="collapse" id="collapse-ten" aria-labelledby="heading-ten" data-parent="#accordion-ten">
                  <div class="bg-yellow">
                    <hr>
                    <p class="small"><strong>Abstract</strong></p>
                    <p class="small">Modern AI systems have become of widespread use in almost all sectors with a strong impact on our society. However, the very methods on which they rely, based on Machine Learning techniques for processing data to predict outcomes and to make decisions, are opaque, prone to bias and may produce wrong answers. Objective functions optimized in learning systems are not guaranteed to align with the values that motivated their definition. Properties such as transparency, verifiability, explainability, security, technical robustness and safety, are key to build operational governance frameworks, so that to make AI systems justifiably trustworthy and to align their development and use with human rights and values.</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-2 pl-3">
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-ten" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="http://dx.doi.org/10.1007/978-3-030-69128-8_2" target="_blank">External Link</a></p>
                <p class="my-1"><small>Research Line <strong>5</strong></small></p>
              </div>
              <div class="row mt-5 justify-content-center" id="MG2021"></div>
              <div class="col-lg-1 text-right">
                <h4>13.</h4><small>[MG2021]</small>
              </div>
              <div class="col-lg-8 bg-yellow p-3">
                <div class="accordion" id="accordion-twelve"></div><strong>FairShades: Fairness Auditing via Explainability in Abusive Language Detection Systems</strong><br><em>Marchiori Manerba Marta, Guidotti Riccardo</em> (2021) - Third Conference on Cognitive Machine Intelligence (COGMI) 2021. In 2021 IEEE Third International Conference on Cognitive Machine Intelligence (CogMI)
                <div class="collapse" id="collapse-twelve" aria-labelledby="heading-twelve" data-parent="#accordion-twelve">
                  <div class="bg-yellow">
                    <hr>
                    <p class="small"><strong>Abstract</strong></p>
                    <p class="small">At every stage of a supervised learning process, harmful biases can arise and be inadvertently introduced, ultimately leading to marginalization, discrimination, and abuse towards minorities. This phenomenon becomes particularly impactful in the sensitive real-world context of abusive language detection systems, where non-discrimination is difficult to assess. In addition, given the opaqueness of their internal behavior, the dynamics leading a model to a certain decision are often not clear nor accountable, and significant problems of trust could emerge. A robust value-oriented evaluation of models' fairness is therefore necessary. In this paper, we present FairShades, a model-agnostic approach for auditing the outcomes of abusive language detection systems.  Combining explainability and fairness evaluation, FairShades can identify unintended biases and sensitive categories towards which models are most discriminative. This objective is pursued through the auditing of meaningful counterfactuals generated within CheckList framework. We conduct several experiments on BERT-based models to demonstrate our proposal's novelty and effectiveness for unmasking biases. </p>
                  </div>
                </div>
              </div>
              <div class="col-lg-2 pl-3">
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-twelve" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://ieeexplore.ieee.org/document/9750356" target="_blank">External Link</a></p>
                <p class="my-1"><small>Research Line <strong>1▪5</strong></small></p>
              </div>
              <div class="row mt-5 justify-content-center" id="GMP2021"></div>
              <div class="col-lg-1 text-right">
                <h4>15.</h4><small>[GMP2021]</small>
              </div>
              <div class="col-lg-2 pl-0"><img class="mr-3 border border-secondary bwc-image" src="assets/images/publications/springer_book_explain.jpg " alt="immagine" style="width:100%;" data-toggle="modal" data-target="#modal-fourteen" type="button">
                <div class="modal fade" id="modal-fourteen" tabindex="-1" role="dialog" aria-labelledby="#modal-fourteen-Title" aria-hidden="true">
                  <div class="modal-dialog modal-dialog-centered" role="document">
                    <div class="modal-content">
                      <div class="modal-header">
                        <p class="small">Explainable AI Within the Digital Transformation and Cyber Physical Systems: XAI Methods and Applications</p>
                        <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                      </div>
                      <div class="modal-body"><img src="assets/images/publications/springer_book_explain.jpg " alt="immagine"></div>
                    </div>
                  </div>
                </div>
              </div>
              <div class="col-lg-6 bg-yellow p-3">
                <div class="accordion" id="accordion-fourteen"></div><strong>Explainable AI Within the Digital Transformation and Cyber Physical Systems: XAI Methods and Applications</strong><br><em>Guidotti Riccardo, Monreale Anna, Pedreschi Dino, Giannotti Fosca</em> (2021) - Explainable AI Within the Digital Transformation and Cyber Physical Systems (pp. 9-31)
                <div class="collapse" id="collapse-fourteen" aria-labelledby="heading-fourteen" data-parent="#accordion-fourteen">
                  <div class="bg-yellow">
                    <hr>
                    <p class="small"><strong>Abstract</strong></p>
                    <p class="small">This book presents Explainable Artificial Intelligence (XAI), which aims at producing explainable models that enable human users to understand and appropriately trust the obtained results. The authors discuss the challenges involved in making machine learning-based AI explainable. Firstly, that the explanations must be adapted to different stakeholders (end-users, policy makers, industries, utilities etc.) with different levels of technical knowledge (managers, engineers, technicians, etc.) in different application domains. Secondly, that it is important to develop an evaluation framework and standards in order to measure the effectiveness of the provided explanations at the human and the technical levels. This book gathers research contributions aiming at the development and/or the use of XAI techniques in order to address the aforementioned challenges in different applications such as healthcare, finance, cybersecurity, and document summarization. It allows highlighting the benefits and requirements of using explainable models in different application domains in order to provide guidance to readers to select the most adapted models to their specified problem and conditions. Includes recent developments of the use of Explainable Artificial Intelligence (XAI) in order to address the challenges of digital transition and cyber-physical systems; Provides a textual scientific description of the use of XAI in order to address the challenges of digital transition and cyber-physical systems; Presents examples and case studies in order to increase transparency and understanding of the methodological concepts.</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-2 pl-3">
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-fourteen" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://doi.org/10.1007/978-3-030-76409-8" target="_blank">External Link</a></p>
                <p class="my-1"><small>Research Line <strong>1▪5</strong></small></p>
              </div>
              <div class="row mt-5 justify-content-center" id="M2020"></div>
              <div class="col-lg-1 text-right">
                <h4>41.</h4><small>[M2020]</small>
              </div>
              <div class="col-lg-8 bg-yellow p-3">
                <div class="accordion" id="accordion-forty"></div><strong>Rischi etico-legali dell’Intelligenza Artificiale</strong><br><em>Monreale Anna</em> (2020) - DPCE Online, [S.l.], v. 44, n. 3. In DPCE Online, [S.l.], v. 44, n. 3, oct. 2020. ISSN 2037-6677
                <div class="collapse" id="collapse-forty" aria-labelledby="heading-forty" data-parent="#accordion-forty">
                  <div class="bg-yellow">
                    <hr>
                    <p class="small"><strong>Abstract</strong></p>
                    <p class="small">nan</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-2 pl-3">
                <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="http://www.dpceonline.it/index.php/dpceonline/article/view/1083" target="_blank">External Link</a></p>
                <p class="my-1"><small>Research Line <strong>5</strong></small></p>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="entry-content mt-0">
        <div class="container mb-10">
          <div class="row gx-lg-3 gy-3 mt-lg-4 mt-md-2 mt-2 mb-5">
            <h3>Researchers working on this line</h3>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Guidotti.jpg" alt="Riccardo Guidotti"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Riccardo<br/>Guidotti</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Assitant Professor</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 3 ▪ 4 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Turini.jpg" alt="Franco Turini"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Franco<br/>Turini</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Full Professor</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 2 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Rinzivillo.jpg" alt="Salvo Rinzivillo"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Salvo<br/>Rinzivillo</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Researcher</span></div>
                  <p class="mb-0">ISTI - CNR Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 3 ▪ 4 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Beretta.jpg" alt="Andrea Beretta"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Andrea<br/>Beretta</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Researcher</span></div>
                  <p class="mb-0">ISTI - CNR Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 4 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Monreale.jpg" alt="Anna Monreale"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Anna<br/>Monreale</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Associate Professor</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 4 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Panigutti.jpg" alt="Cecilia Panigutti"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Cecilia<br/>Panigutti</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0">Scuola Normale</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 4 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Pellungrini.jpg" alt="Roberto Pellungrini"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Roberto<br/>Pellungrini</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Researcher</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Naretto.jpg" alt="Francesca Naretto"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Francesca<br/>Naretto</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0">Scuola Normale</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 3 ▪ 4 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Pratesi.jpg" alt="Francesca Pratesi"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Francesca<br/>Pratesi</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Researcher</span></div>
                  <p class="mb-0">ISTI - CNR Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6">
              <div class="member-image"><img class="card-img" src="assets/images/p_Marchiori Manerba.jpg" alt="Marta Marchiori Manerba"/></div>
              <div class="member-content bg-yellow">
                <div class="member-text px-3 py-3">
                  <h5 class="member-name">Marta<br/>Marchiori Manerba</h5>
                  <hr/>
                  <div class="member-tag"><span class="member-role">Phd Student</span></div>
                  <p class="mb-0">University of Pisa</p>
                  <hr/>
                  <p class="text-uppercase">R. line <strong>1 ▪ 2 ▪ 5</strong></p>
                </div>
              </div>
              <!-- End People Card-->
            </div>
          </div>
        </div>
      </div>
    </article>
    <!-- Footer-->
    <footer class="site-footer">
      <div class="footer-widgets">
        <div class="container">
          <div class="row gx-lg-5">
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-1">
                <h4 class="text-yellow mb-3">Principal Investigator</h4>
                <div class="text-white">
                  <p class="mb-0">Fosca Giannotti</p>
                  <p class="mb-0">Scuola Normale Superiore</p><br>
                  <p class="mb-0">Piazza dei Cavalieri, 7</p>
                  <p class="mb-0">56126 Pisa, Italy</p><br>
                  <p class="mb-0">Email: fosca.giannotti @ sns.it</p>
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-4">
                <div class="text-white">
                  <p>The XAI Project receives funding from the European Union's Horizon 2020 Excellent Science European Research Council (ERC) programme under grant agreement No. 834756</p>The views and opinions expressed in this website are the sole responsibility of the author and do not necessarily reflect the views of the European Commission.
                  <p></p><img class="mb-4" src="assets/images/logo-eu.jpg" alt="EU flag">
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-2">
                <ul>
                  <li><a href="index.html">Xai</a></li>
                  <li><a href="about.html">Project details</a></li>
                  <li><a href="research-lines.html">Research lines</a></li>
                  <li><a href="people.html">People</a></li>
                  <li><a href="resources.html">Resources</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="footer-bottom-area">
        <div class="container">
          <div class="row gx-lg-5 align-items-center">
            <div class="col-md-12"><span class="text-yellow strong">Webdesign: Daniele Fadda © 2022</span></div>
          </div>
        </div>
      </div>
    </footer>
    <!-- End Footer-->
    <!-- javascript files-->
    <!-- jquery-->
    <script src="assets/js/jquery.min.js"></script>
    <!-- lozad js-->
    <script src="assets/js/lozad.min.js"></script>
    <!-- Bootstrap js-->
    <script src="assets/js/bootstrap.bundle.min.js"></script>
    <!-- Aos js-->
    <script src="assets/js/aos.js"></script>
    <!-- Slick flickity js-->
    <script src="assets/js/flickity.pkgd.min.js"></script>
    <!-- Magnific popup js-->
    <script src="assets/js/jquery.magnific-popup.min.js"></script>
    <!-- Countdown js-->
    <script src="assets/js/jquery.countdown.js"></script>
    <!-- CountTo js-->
    <script src="assets/js/jquery.countTo.js"></script>
    <!-- Global - Main js-->
    <script src="assets/js/global.js"></script>
  </body>
</html>