<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- favicon-->
    <link rel="shortcut icon" href="assets/images/favicon.ico">
    <!-- Site Title-->
    <title>Xai - Website</title>
    <meta name="description" content="Science and technology for the eXplanation of AI decision making">
    <!-- Bootstrap CSS file-->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">
    <!-- Flickity CSS file-->
    <link href="assets/css/flickity.min.css" rel="stylesheet">
    <!-- Main CSS file-->
    <link href="assets/css/style.css" rel="stylesheet">
    <!-- Fontawesome 5 CSS file-->
    <link href="assets/css/fontawesome-all.min.css" rel="stylesheet">
    <!-- Magnific Popup CSS-->
    <link href="assets/css/magnific-popup.css" rel="stylesheet">
    <!-- Google Fonts-->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;700&amp;display=swap">
    <script type="text/javascript">
      // Matomo Code
      var _paq = window._paq = window._paq || [];
      /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
      _paq.push(['trackPageView']);
      _paq.push(['enableLinkTracking']);
      (function () {
      var u="//piwikdd.isti.cnr.it/";
      _paq.push(['setTrackerUrl', u+'piwik.php']);
      _paq.push(['setSiteId', '12']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
      })
      ();
    </script>
  </head>
  <body>
    <!-- Navbar-->
    <div class="site-header header-bottom-area">
      <nav class="navbar navbar-expand-lg navbar-light sticky">
        <div class="container"><a class="navbar-brand" href="index.html"><img class="site-logo" src="assets/images/logo/xai_logo_color.png" alt="Logo"></a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
          <div class="collapse navbar-collapse" id="navbarNavDropdown">
            <ul class="navbar-nav mx-auto">
              <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
              <li class="nav-item"><a class="nav-link" href="about.html">Project details</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="research-lines.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research Lines</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="line_1.html">1. Local to global</a><a class="dropdown-item" href="line_2.html">2. Casual reasoning</a><a class="dropdown-item" href="line_3.html">3. Platform and XUI</a><a class="dropdown-item" href="line_4.html">4. Case studies</a><a class="dropdown-item" href="line_5.html">5. Ethics and legal</a></div>
              </li>
              <li class="nav-item"><a class="nav-link" href="people.html">People</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="resources.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Publications and Resources</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="resources.html#publications">Publications</a><a class="dropdown-item" href="resources.html#thesis">Thesis</a><a class="dropdown-item" href="dissemination.html">Dissemination tools</a></div>
              </li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="#" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">News</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="news.html">All News</a><a class="dropdown-item" href="dist-seminars.html">Distinguished seminars</a><a class="dropdown-item" href="internal-events.html">Internal Events</a></div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </div>
    <!-- End Navbar-->
    <!-- Cookies-->
    <div class="cookie-banner" style="display: none">
      <p class="mx-2">We use cookies on this site to enhance your user experience. By clicking any link on this page you are giving your consent for us to set cookies. 
        <u><a href="privacy.html" link’="privacy.html">No, give me more info.</a></u>
      </p>
      <button class="close">&times;</button>
    </div>
    <!-- End Cookies-->
    <article class="entry">
      <div class="entry-content">
        <!-- Hero-->
        <div class="bg-yellow">
          <div class="container py-lg-8 py-md-7 py-5">
            <div class="row">
              <div class="col-lg-6">
                <h2 class="my-3">Distinguished seminars on Explainable AI</h2>
                <p class="lead mb-3">The Distinguished seminars on Explainable AI last for 90 minutes, the first 45 are dedicated to the seminar and the rest to a round table, we will allow some other guests to be able to ask questions to deepen the topic or opening our minds. Our goal is to bring together bright minds to give talks that are focused on various aspects that can affect Explainability and Artificial Intelligence to foster learning and inspirations that matter.</p>
              </div>
            </div>
          </div>
        </div>
        <!-- calendar-->
        <div class="container mt-lg-5 mt-3 mb-lg-5 mb-md-5 mb-3">
          <div class="row mb-5">
            <div class="col-lg-2 mb-2 mb-lg-0"><a href="#">
                <div class="bg-yellow h-100">
                  <div class="text-center align-items-center">
                    <div class="px-lg-4 py-lg-2 px-4 py-2">
                      <div class="mt-lg-4 mt-5">
                        <h1 class="display-1 text">></h1>
                        <h3 class="text-uppercase">dates</h3>
                      </div>
                      <div class="px-lg-2 mt-lg-4 px-2 mt-3">
                        <p>our guests</p>
                      </div>
                    </div>
                  </div>
                </div></a></div>
            <div class="col-lg-2 mb-2 mb-lg-0"><a href="#cynthia">
                <div class="bg-gray-500 text-white h-100">
                  <div class="text-center align-items-center">
                    <div class="px-lg-4 py-lg-2 px-4 py-2">
                      <div class="mt-lg-4 mt-5">
                        <h1 class="display-1">20</h1>
                        <h3 class="text-uppercase">April</h3>
                      </div>
                      <div class="px-lg-2 mt-lg-4 px-2 mt-3">
                        <p>Cynthia Rudin</p>
                      </div>
                    </div>
                  </div>
                </div></a></div>
            <div class="col-lg-2 mb-2 mb-lg-0"><a href="#biecek">
                <div class="bg-gray-500 text-white h-100">
                  <div class="text-center align-items-center">
                    <div class="px-lg-4 py-lg-2 px-4 py-2">
                      <div class="mt-lg-4 mt-5">
                        <h1 class="display-1">25</h1>
                        <h3 class="text-uppercase">May</h3>
                      </div>
                      <div class="px-lg-2 mt-lg-4 px-2 mt-3">
                        <p>Przemek Biecek</p>
                      </div>
                    </div>
                  </div>
                </div></a></div>
            <div class="col-lg-2 mb-2 mb-lg-0"><a href="#byrne">
                <div class="bg-gray-500 text-white h-100">
                  <div class="text-center align-items-center">
                    <div class="px-lg-4 py-lg-2 px-4 py-2">
                      <div class="mt-lg-4 mt-5">
                        <h1 class="display-1">15</h1>
                        <h3 class="text-uppercase">June</h3>
                      </div>
                      <div class="px-lg-2 mt-lg-4 px-2 mt-3">
                        <p>Ruth Byrne</p>
                      </div>
                    </div>
                  </div>
                </div></a></div>
            <div class="col-lg-2 mb-2 mb-lg-0"><a href="#lecue">
                <div class="bg-gray-500 text-white h-100">
                  <div class="text-center align-items-center">
                    <div class="px-lg-4 py-lg-2 px-4 py-2">
                      <div class="mt-lg-4 mt-5">
                        <h1 class="display-1">13</h1>
                        <h3 class="text-uppercase">July</h3>
                      </div>
                      <div class="px-lg-2 mt-lg-4 px-2 mt-3">
                        <p>Freddy Lecue</p>
                      </div>
                    </div>
                  </div>
                </div></a></div>
            <div class="col-lg-2 d-none d-lg-block">
              <div class="bg-grayphite h-100"></div>
            </div>
          </div>
        </div>
        <div class="container mt-lg-5 mt-md-6 mt-5">
          <!-- RUDIN SECTION //-->
          <hr id="cynthia">
          <div class="row pt-9">
            <div class="col-lg-8"><img class="img-fluid mb-lg-5 mb-md-5 mb-4" src="assets/images/seminars/seminar_01_rudin.png" alt="Cynthia Rudin">
              <div class="accordion" id="accordionCynthia">
                <div class="card border-0">
                  <div class="card-header bg-yellow" id="headingOne"><a class="h5 mb-0 py-lg-4 px-lg-4 py-md-4 px-md-4 py-2 px-2 d-block" href="#" data-toggle="collapse" data-target="#collapseOneCynthia" aria-expanded="false" aria-controls="collapseOne">More on this talk</a></div>
                  <div class="collapse" id="collapseOneCynthia" aria-labelledby="headingOne" data-parent="#accordionCynthia">
                    <div class="py-lg-2 px-lg-2 bg-grayphite">
                      <div class="card-body mt-2">
                        <p>Let us consider a difficult computer vision challenge. Would you want an algorithm to determine whether you should get a biopsy, based on an xray? That's usually a decision made by a radiologist, based on years of training. We know that algorithms haven't worked perfectly for a multitude of other computer vision applications, and biopsy decisions are harder than just about any other application of computer vision that we typically consider. The interesting question is whether it is possible that an algorithm could be a true partner to a physician, rather than making the decision on its own. To do this, at the very least, we would need an interpretable neural network that is as accurate as its black box counterparts.</p>
                        <p>This talk will discuss two approaches to interpretable neural networks: (1) case-based reasoning, where parts of images are compared to other parts of prototypical images for each class, and (2) neural disentanglement, using a technique called concept whitening. The case-based reasoning technique is strictly better than saliency maps, and the concept whitening technique provides a strict advantage over the posthoc use of concept vectors.</p>
                      </div>
                    </div>
                  </div>
                </div>
                <div class="card border-0 mt-lg-5 mt-4">
                  <div class="card-header bg-yellow" id="headingTwoCynthia"><a class="h5 mb-0 py-lg-4 px-lg-4 py-md-4 px-md-4 py-2 px-2 d-block" href="#" data-toggle="collapse" data-target="#collapseTwoCynthia" aria-expanded="false" aria-controls="collapseTwo">Cynthia Rudin - short bio</a></div>
                  <div class="collapse" id="collapseTwoCynthia" aria-labelledby="headingTwoCynthia" data-parent="#accordionCynthia">
                    <div class="py-lg-2 px-lg-2 bg-grayphite">
                      <div class="card-body mt-2">
                        <p>Cynthia Rudin is a professor of computer science, electrical and computer engineering, and statistical science at Duke University, and directs the Prediction Analysis Lab, whose main focus is in interpretable machine learning. She is also an associate director of the Statistical and Applied Mathematical Sciences Institute (SAMSI). Previously, Prof. Rudin held positions at MIT, Columbia, and NYU. She holds an undergraduate degree from the University at Buffalo, and a PhD from Princeton University.</p>
                      </div>
                    </div>
                  </div>
                </div>
                <div class="card border-0 mt-lg-5 mt-4"></div>
              </div>
            </div>
            <div class="col-lg-4">
              <h2>Cynthia Rudin</h2>
              <p class="text-gray-500">Apr 20, 5.00pm - 6.30pm CEST</p>
              <h5>Interpretable Neural Networks for Computer Vision: Clinical Decisions that are Computer-Aided, not Automated</h5>
              <hr>
              <p>The talk will face the topic of clinical decision-making and interpretable deep neural networks. The main question is whether it is possible that an algorithm could be a true partner to a physician, rather than making the decision on its own. Two approaches will be discussed 1) case-based reasoning and 2) neural disentanglement, covering the advantages of a technique called concept whitening.</p>
              <hr>
              <ul class="list-unstyled">
                <li><strong>Chair</strong> -  Fosca Giannotti</li>
                <li><strong>Discussants</strong>  - Riccardo Guidotti, Luca Pappalardo, Cecilia Panigutti</li>
              </ul>
              <hr><a href="https://twitter.com/cynthiarudin" target="_blank"><i class="m-2 fab fa-2x fa-twitter"></i>follow on twitter</a>
            </div>
          </div>
          <!-- BIECEK SECTION-->
          <div id="biecek"></div>
          <div class="row pt-9 pb-sm-10">
            <div class="col-lg-8"><img class="img-fluid mb-lg-5 mb-md-5 mb-4" src="assets/images/seminars/seminar_02_prez.png" alt="Przemek Biecek">
              <div class="accordion" id="accordionExample">
                <div class="card border-0">
                  <div class="card-header bg-yellow" id="headingOne"><a class="h5 mb-0 py-lg-4 px-lg-4 py-md-4 px-md-4 py-2 px-2 d-block" href="#" data-toggle="collapse" data-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne">More on this talk</a></div>
                  <div class="collapse" id="collapseOne" aria-labelledby="headingOne" data-parent="#accordionExample">
                    <div class="py-lg-2 px-lg-2 bg-grayphite">
                      <div class="card-body mt-2">
                        <p>Explanatory Model Analysis Explore, Explain and Examine Predictive Models is a set of methods and tools designed to build better predictive models and to monitor their behaviour in a changing environment. Today, the true bottleneck in predictive modelling is neither the lack of data, nor the lack of computational power, nor inadequate algorithms, nor the lack of flexible models. It is the lack of tools for model exploration (extraction of relationships learned by the model), model explanation (understanding the key factors influencing model decisions) and model examination (identification of model weaknesses and evaluation of model's performance). This book presents a collection of model agnostic methods that may be used for any black-box model together with real-world applications to classification and regression problems.</p>
                      </div>
                    </div>
                  </div>
                </div>
                <div class="card border-0 mt-lg-5 mt-4">
                  <div class="card-header bg-yellow" id="headingTwo"><a class="h5 mb-0 py-lg-4 px-lg-4 py-md-4 px-md-4 py-2 px-2 d-block" href="#" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">Przemyslaw Biecek - short bio</a></div>
                  <div class="collapse" id="collapseTwo" aria-labelledby="headingTwo" data-parent="#accordionExample">
                    <div class="py-lg-2 px-lg-2 bg-grayphite">
                      <div class="card-body mt-2">
                        <p>Associate professor at Warsaw University of Technology and the University of Warsaw. Interested in model visualisation, explanatory model analysis, predictive modelling and applications in healthcare. Graduated in software engineering and mathematical statistics. In 2016, he formed the research group MI2DataLab which develops methods and tools for predictive model analysis. Member of the ResponsibleAI group in the GPAI initiative.</p>
                      </div>
                    </div>
                  </div>
                </div>
                <div class="card border-0 mt-lg-5 mt-4"></div>
              </div>
            </div>
            <div class="col-lg-4">
              <h2>Przemyslaw Biecek</h2>
              <p class="text-gray-500">May 25, 5.00pm - 6.30pm CEST</p>
              <h5>Trust, but verify. How explainable artificial intelligence can be used to validate predictive models.</h5>
              <hr>
              <p>The talk will have three parts. In the first I will show how vulnerable XAI methods are to attacks, and why we should approach explanations with a great deal of scepticism. In the second I will show that many of the XAI methods can be used effectively for model exploration, I will talk about Explanatory Model Analysis and the Rashomon perspective. In the third, I will talk about the grammar for interactive model explanation and the advantages from a fast feedback loop in human-model interaction.</p>
              <hr>
              <ul class="list-unstyled">
                <li><strong>Chair</strong> -  Fosca Giannotti</li>
                <li><strong>Discussants</strong>  - Salvo Rinzivillo, Anna Monreale, Francesca Pratesi</li>
              </ul>
              <hr><a href="https://twitter.com/smarterpoland?s=20" target="_blank"><i class="m-2 fab fa-2x fa-twitter"></i>follow on twitter</a>
            </div>
          </div>
          <!-- Byrne SECTION-->
          <div id="byrne"></div>
          <div class="row pt-9 pb-sm-10">
            <div class="col-lg-8"><img class="img-fluid mb-lg-5 mb-md-5 mb-4" src="assets/images/seminars/seminar_03_Ruth.png" alt="Ruth Byrne">
              <div class="accordion" id="accordionExample">
                <div class="card border-0">
                  <div class="card-header bg-yellow" id="headingTwo"><a class="h5 mb-0 py-lg-4 px-lg-4 py-md-4 px-md-4 py-2 px-2 d-block" href="#" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">Ruth Byrne - short bio</a></div>
                  <div class="collapse" id="collapseTwo" aria-labelledby="headingTwo" data-parent="#accordionExample">
                    <div class="py-lg-2 px-lg-2 bg-grayphite">
                      <div class="card-body mt-2">
                        <p>"Ruth Byrne is the Professor of Cognitive Science at Trinity College Dublin, University of Dublin, in the School of Psychology and the Institute of Neuroscience, a Chair created for her by the University in 2005.</p>
                        <p>Her research expertise is in the cognitive science of human thinking, including experimental and computational investigations of reasoning and imaginative thought. Her most recent book is a co-edited volume with Kinga Morsanyi on 'Thinking, Reasoning, and Decision-making in Autism' (2019, Routledge). She has also written 'The Rational Imagination: How People Create Alternatives to Reality' published in 2005 by MIT press (and selected for open peer commentary by the Behavioral and Brain Sciences journal in 2007), and 'Deduction', co-authored with Phil Johnson-Laird, published in 1991 by Erlbaum Associates. She has published over 100 articles in journals such as Annual Review of Psychology, Cognition, Cognitive Psychology, Cognitive Science, Current Directions in Psychological Science, Psychological Review, and Trends in Cognitive Sciences."</p>
                      </div>
                    </div>
                  </div>
                </div>
                <div class="card border-0 mt-lg-5 mt-4"></div>
              </div>
            </div>
            <div class="col-lg-4">
              <h2>Ruth Byrne</h2>
              <p class="text-gray-500">June 15, 5.00pm - 6.30pm CEST</p>
              <h5>The psychology of counterfactual explanations in XAI</h5>
              <hr>
              <p>The use of counterfactuals in Explainable Artificial Intelligence (XAI) can benefit from experimental discoveries in psychology on how people create counterfactual alternatives to reality and how they reason from counterfactual conditionals. I discuss the cognitive processes that people rely on when they engage in counterfactual thought, compared to causal thought. I illustrate some of the similarities and differences between counterfactual and causal thought with evidence from our recent eye-tracking studies on how people comprehend counterfactual conditionals and causal assertions. I demonstrate the relevance of this evidence to XAI and describe our recent experiments on the effects of counterfactual and causal explanations on how people understand the decisions of AI systems. I outline potential future directions for the refinement of the use of counterfactuals in XAI.</p>
            </div>
          </div>
          <!-- Lecue SECTION //-->
          <div id="lecue"></div>
          <div class="row pt-9 pb-sm-10">
            <div class="col-lg-8"><img class="img-fluid mb-lg-5 mb-md-5 mb-4" src="assets/images/seminars/seminar_02_Lecue.png" alt="Freddy Lecue">
              <div class="accordion" id="accordionExample">
                <div class="card border-0">
                  <div class="card-header bg-yellow" id="headingOne"><a class="h5 mb-0 py-lg-4 px-lg-4 py-md-4 px-md-4 py-2 px-2 d-block" href="#" data-toggle="collapse" data-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne">More on this talk</a></div>
                  <div class="collapse" id="collapseOne" aria-labelledby="headingOne" data-parent="#accordionExample">
                    <div class="py-lg-2 px-lg-2 bg-grayphite">
                      <div class="card-body mt-2">
                        <p>As artificial intelligence has become tightly intervened in the society having tangible consequences and influence, calls for explainability and interpretability of these systems has also become increasingly prevalent. Explainable AI (XAI) attempts to alleviate concerns of transparency, trust and ethics in AI by making them accountable, interpretable and explainable to humans. This workshop aims to encapsulate these concepts under the umbrella of Explainable Agency and bring together researchers and practitioners working in different facets of explainable AI from diverse backgrounds to share challenges, new directions and recent research in the field. We especially welcome research from fields including but not limited to artificial intelligence, human-computer interaction, human-robot interaction, cognitive science, human factors and philosophy.</p>
                      </div>
                    </div>
                  </div>
                </div>
                <div class="card border-0 mt-lg-5 mt-4">
                  <div class="card-header bg-yellow" id="headingTwo"><a class="h5 mb-0 py-lg-4 px-lg-4 py-md-4 px-md-4 py-2 px-2 d-block" href="#" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">Freddy Lecue - short bio</a></div>
                  <div class="collapse" id="collapseTwo" aria-labelledby="headingTwo" data-parent="#accordionExample">
                    <div class="py-lg-2 px-lg-2 bg-grayphite">
                      <div class="card-body mt-2">
                        <p>Dr. Freddy Lecue is the Chief Artificial Intelligence (AI) Scientist at CortAIx (Centre of Research & Technology in Artificial Intelligence eXpertise) at Thales in Montreal - Canada. He is also a research associate at INRIA, in WIMMICS, Sophia Antipolis - France. Before joining the new R&T lab of Thales dedicated to AI, he was AI R&D Lead at Accenture Labs in Ireland from 2016 to 2018. Prior joining Accenture he was a research scientist, lead investigator in large scale reasoning systems at IBM Research from 2011 to 2016, a research fellow at The University of Manchester from 2008 to 2011 and research engineer at Orange Labs from 2005 to 2008.</p>
                      </div>
                    </div>
                  </div>
                </div>
                <div class="card border-0 mt-lg-5 mt-4"></div>
              </div>
            </div>
            <div class="col-lg-4">
              <h2>Freddy Lecue</h2>
              <p class="text-gray-500">July 13, 5.00pm - 6.30pm CEST</p>
              <h5>Explanation in AI: Watch the Semantic Gap!</h5>
              <hr>
              <p>The term XAI refers to a set of tools for explaining AI systems of any kind, beyond Machine Learning. Even though these tools aim at addressing explanation in the broader sense, they are not designed for all users, tasks, contexts and applications. This presentation will describe recent progress to date on XAI, with a focus on Machine Learning and its needs of semantics, by reviewing its approaches, motivation, industrial applications, and limitations.</p>
              <hr>
              <ul class="list-unstyled">
                <li><strong>Chair</strong> -  Fosca Giannotti</li>
                <li><strong>Discussants</strong>  - Mattia Setzu, Cecilia Panigutti</li>
              </ul>
              <hr><a href="https://twitter.com/freddylecue" target="_blank"><i class="m-2 fab fa-2x fa-twitter"></i>follow on twitter</a>
            </div>
          </div>
        </div>
      </div>
    </article>
    <!-- Footer-->
    <footer class="site-footer">
      <div class="footer-widgets">
        <div class="container">
          <div class="row gx-lg-5">
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-1">
                <h4 class="text-yellow mb-3">Principal Investigator</h4>
                <div class="text-white">
                  <p class="mb-0">Fosca Giannotti</p>
                  <p class="mb-0">Scuola Normale Superiore</p><br>
                  <p class="mb-0">Piazza dei Cavalieri, 7</p>
                  <p class="mb-0">56126 Pisa, Italy</p><br>
                  <p class="mb-0">Email: fosca.giannotti @ sns.it</p>
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-4">
                <div class="text-white">
                  <p>The XAI Project receives funding from the European Union's Horizon 2020 Excellent Science European Research Council (ERC) programme under grant agreement No. 834756</p>The views and opinions expressed in this website are the sole responsibility of the author and do not necessarily reflect the views of the European Commission.
                  <p></p><img class="mb-4" src="assets/images/logo-eu.jpg" alt="EU flag">
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-2">
                <ul>
                  <li><a href="index.html">Xai</a></li>
                  <li><a href="about.html">Project details</a></li>
                  <li><a href="research-lines.html">Research lines</a></li>
                  <li><a href="people.html">People</a></li>
                  <li><a href="resources.html">Resources</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="footer-bottom-area">
        <div class="container">
          <div class="row gx-lg-5 align-items-center">
            <div class="col-md-12"><span class="text-yellow strong">Webdesign: Daniele Fadda © 2023</span></div>
          </div>
        </div>
      </div>
    </footer>
    <!-- End Footer-->
    <!-- javascript files-->
    <!-- jquery-->
    <script src="assets/js/jquery.min.js"></script>
    <!-- lozad js-->
    <script src="assets/js/lozad.min.js"></script>
    <!-- Bootstrap js-->
    <script src="assets/js/bootstrap.bundle.min.js"></script>
    <!-- Aos js-->
    <script src="assets/js/aos.js"></script>
    <!-- Slick flickity js-->
    <script src="assets/js/flickity.pkgd.min.js"></script>
    <!-- Magnific popup js-->
    <script src="assets/js/jquery.magnific-popup.min.js"></script>
    <!-- Countdown js-->
    <script src="assets/js/jquery.countdown.js"></script>
    <!-- CountTo js-->
    <script src="assets/js/jquery.countTo.js"></script>
    <!-- Global - Main js-->
    <script src="assets/js/global.js"></script>
    <!-- Global - Main js-->
    <script src="assets/js/cookies.js"></script>
  </body>
</html>