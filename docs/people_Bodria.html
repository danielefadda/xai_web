<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- favicon-->
    <link rel="shortcut icon" href="assets/images/favicon.ico">
    <!-- Site Title-->
    <title>Xai - Website</title>
    <meta name="description" content="Science and technology for the eXplanation of AI decision making">
    <!-- Bootstrap CSS file-->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">
    <!-- Flickity CSS file-->
    <link href="assets/css/flickity.min.css" rel="stylesheet">
    <!-- Main CSS file-->
    <link href="assets/css/style.css" rel="stylesheet">
    <!-- Fontawesome 5 CSS file-->
    <link href="assets/css/fontawesome-all.min.css" rel="stylesheet">
    <!-- Magnific Popup CSS-->
    <link href="assets/css/magnific-popup.css" rel="stylesheet">
    <!-- Google Fonts-->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;700&amp;display=swap">
    <script type="text/javascript">
      // Matomo Code
      var _paq = window._paq = window._paq || [];
      /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
      _paq.push(['trackPageView']);
      _paq.push(['enableLinkTracking']);
      (function () {
      var u="//piwikdd.isti.cnr.it/";
      _paq.push(['setTrackerUrl', u+'piwik.php']);
      _paq.push(['setSiteId', '12']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
      })
      ();
    </script>
  </head>
  <body>
    <!-- Navbar-->
    <div class="site-header header-bottom-area">
      <nav class="navbar navbar-expand-lg navbar-light sticky">
        <div class="container"><a class="navbar-brand" href="index.html"><img class="site-logo" src="assets/images/logo/xai_logo_color.png" alt="Logo"></a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
          <div class="collapse navbar-collapse" id="navbarNavDropdown">
            <ul class="navbar-nav mx-auto">
              <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
              <li class="nav-item"><a class="nav-link" href="about.html">Project details</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="research-lines.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research Lines</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="line_1.html">1. Local to global</a><a class="dropdown-item" href="line_2.html">2. Casual reasoning</a><a class="dropdown-item" href="line_3.html">3. Platform and XUI</a><a class="dropdown-item" href="line_4.html">4. Case studies</a><a class="dropdown-item" href="line_5.html">5. Ethics and legal</a></div>
              </li>
              <li class="nav-item"><a class="nav-link" href="people.html">People</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="resources.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Publications and Resources</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="resources.html#publications">Publications</a>
                  <!-- a.dropdown-item(href='reports.html') Reports--><a class="dropdown-item" href="resources.html#thesis">Thesis</a><a class="dropdown-item" href="dissemination.html">Dissemination tools</a>
                </div>
              </li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="#" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Seminars</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="seminars.html">All Seminars</a><a class="dropdown-item" href="dist-seminars.html">Distinguished seminars</a>
                  <!--a.dropdown-item(href='internal-events.html') Internal Events-->
                </div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </div>
    <!-- End Navbar-->
    <!-- Cookies-->
    <div class="cookie-banner" style="display: none">
      <p class="mx-2">We use cookies on this site to enhance your user experience. By clicking any link on this page you are giving your consent for us to set cookies. 
        <u><a href="privacy.html" link’="privacy.html">No, give me more info.</a></u>
      </p>
      <button class="close">&times;</button>
    </div>
    <!-- End Cookies-->
    <article class="entry"></article>
    <div class="entry-content">
      <div class="bg-yellow pt-6 pt-lg-8 pb-4 pb-lg-5">
        <div class="bg-half">
          <div class="container">
            <div class="row">
              <div class="col-lg-4 offset-lg-4">
                <h1 class="text-center">Francesco Bodria</h1><img class="card-img" src="assets/images/p_Bodria.jpg" alt="Francesco Bodria"/>
                <div class="member-content">
                  <div class="member-text px-0 py-3">
                    <p class="text-uppercase">Involved in the research line <strong>1 ▪ 3</strong></p>
                    <p>Role: Phd Student</p>
                    <p class="mb-0">Affiliation: Scuola Normale</p>
                    <hr/>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="container mt-6">
        <div class="row justify-content-lg-center">
          <div class="col-lg-8"></div>
        </div>
      </div>
      <div class="container mb-6">
        <div class="row">
          <div class="row mt-5 justify-content-center" id="BGG2023">
            <div class="col-lg-1 text-right">
              <h4>5.</h4><small>[BGG2023]</small>
            </div>
            <div class="col-lg-8 bg-yellow p-3">
              <div class="accordion" id="accordion-four"></div><strong>Benchmarking and survey of explanation methods for black box models</strong><br><em>Francesco Bodria, Fosca Giannotti, Riccardo Guidotti, Francesca Naretto, Dino Pedreschi, Salvatore Rinzivillo</em> (2023) - Springer Science+Business Media, LLC, part of Springer Nature. In Data Mining and Knowledge Discovery
              <div class="collapse" id="collapse-four" aria-labelledby="heading-four" data-parent="#accordion-four">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">The rise of sophisticated black-box machine learning models in Artificial Intelligence systems has prompted the need for explanation methods that reveal how these models work in an understandable way to users and decision makers. Unsurprisingly, the state-of-the-art exhibits currently a plethora of explainers providing many different types of explanations. With the aim of providing a compass for researchers and practitioners, this paper proposes a categorization of explanation methods from the perspective of the type of explanation they return, also considering the different input data formats. The paper accounts for the most representative explainers to date, also discussing similarities and discrepancies of returned explanations through their visual appearance. A companion website to the paper is provided as a continuous update to new explainers as they appear. Moreover, a subset of the most robust and widely adopted explainers, are benchmarked with respect to a repertoire of quantitative metrics.</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-four" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://doi.org/10.1007/s10618-023-00933-9" target="_blank">External Link</a></p>
              <p class="my-1"><small>Research Line <strong>1▪3</strong></small></p>
            </div>
            <div class="row mt-5 justify-content-center" id="BGG2023c"></div>
            <div class="col-lg-1 text-right">
              <h4>12.</h4><small>[BGG2023c]</small>
            </div>
            <div class="col-lg-8 bg-yellow p-3">
              <div class="accordion" id="accordion-eleven"></div><strong>Interpretable Latent Space to Enable Counterfactual Explanations</strong><br><em>Francesco Bodria, Riccardo Guidotti, Fosca Giannotti & Dino Pedreschi </em> (2022) - Proceedings of the 25th international conference on Discovery Science (DS), 2022, Montpellier. In Lecture Notes in Computer Science()
              <div class="collapse" id="collapse-eleven" aria-labelledby="heading-eleven" data-parent="#accordion-eleven">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">Many dimensionality reduction methods have been introduced to map a data space into one with fewer features and enhance machine learning models’ capabilities. This reduced space, called latent space, holds properties that allow researchers to understand the data better and produce better models. This work proposes an interpretable latent space that preserves the similarity of data points and supports a new way of learning a classification model that allows prediction and explanation through counterfactual examples. We demonstrate with extensive experiments the effectiveness of the latent space with respect to different metrics in comparison with several competitors, as well as the quality of the achieved counterfactual explanations.</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-eleven" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://doi.org/10.1007/978-3-031-18840-4_37" target="_blank">External Link</a></p>
              <p class="my-1"><small>Research Line <strong>1</strong></small></p>
            </div>
            <div class="row mt-5 justify-content-center" id="BGG2023b"></div>
            <div class="col-lg-1 text-right">
              <h4>13.</h4><small>[BGG2023b]</small>
            </div>
            <div class="col-lg-8 bg-yellow p-3">
              <div class="accordion" id="accordion-twelve"></div><strong>Transparent Latent Space Counterfactual Explanations for Tabular Data</strong><br><em>Bodria Francesco, Riccardo Guidotti, Fosca Giannotti, Dino Pedreschi</em> (2022) - Proceedings of Data Science and Advanced Analytics (DSAA), 2022 IEEE 9th International Conference. In Proceedings of the 9th IEEE International Conference on Data Science and Advanced, Analytics (DSAA)
              <div class="collapse" id="collapse-twelve" aria-labelledby="heading-twelve" data-parent="#accordion-twelve">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">Artificial Intelligence decision-making systems have dramatically increased their predictive performance in recent years, beating humans in many different specific tasks. However, with increased performance has come an increase in the complexity of the black-box models adopted by the AI systems, making them entirely obscure for the decision process adopted. Explainable AI is a field that seeks to make AI decisions more transparent by producing explanations. In this paper, we propose T-LACE, an approach able to retrieve post-hoc counterfactual explanations for a given pre-trained black-box model. T-LACE exploits the similarity and linearity proprieties of a custom-created transparent latent space to build reliable counterfactual explanations. We tested T-LACE on several tabular datasets and provided qualitative evaluations of the generated explanations in terms of similarity, robustness, and diversity. Comparative analysis against various state-of-the-art counterfactual explanation methods shows the higher effectiveness of our approach.</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-twelve" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://ieeexplore.ieee.org/document/10032407" target="_blank">External Link</a></p>
              <p class="my-1"><small>Research Line <strong>1</strong></small></p>
            </div>
            <div class="row mt-5 justify-content-center" id="BRF2022"></div>
            <div class="col-lg-1 text-right">
              <h4>23.</h4><small>[BRF2022]</small>
            </div>
            <div class="col-lg-2 pl-0"><img class="mr-3 border border-secondary bwc-image" src="assets/images/publications/latent-space-exploration.png " alt="immagine" style="width:100%;" data-toggle="modal" data-target="#modal-twenty-two" type="button">
              <div class="modal fade" id="modal-twenty-two" tabindex="-1" role="dialog" aria-labelledby="#modal-twenty-two-Title" aria-hidden="true">
                <div class="modal-dialog modal-lg modal-dialog-centered" role="document">
                  <div class="modal-content">
                    <div class="modal-header">
                      <p class="small">Explaining Black Box with visual exploration of Latent Space</p>
                      <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                    </div>
                    <div class="modal-body"><img src="assets/images/publications/latent-space-exploration.png " alt="immagine"></div>
                  </div>
                </div>
              </div>
            </div>
            <div class="col-lg-6 bg-yellow p-3">
              <div class="accordion" id="accordion-twenty-two"></div><strong>Explaining Black Box with visual exploration of Latent Space</strong><br><em>Bodria Francesco, Rinzivillo Salvatore, Fadda Daniele, Guidotti Riccardo, Fosca Giannotti, Pedreschi Dino</em> (2022) - EUROVIS 2022. In Proceedings of the 2022 Conference Eurovis 2022
              <div class="collapse" id="collapse-twenty-two" aria-labelledby="heading-twenty-two" data-parent="#accordion-twenty-two">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">Autoencoders are a powerful yet opaque feature reduction technique, on top of which we propose a novel way for the joint visual exploration of both latent and real space. By interactively exploiting the mapping between latent and real features, it is possible to unveil the meaning of latent features while providing deeper insight into the original variables. To achieve this goal, we exploit and re-adapt existing approaches from eXplainable Artificial Intelligence (XAI) to understand the relationships between the input and latent features. The uncovered relationships between input features and latent ones allow the user to understand the data structure concerning external variables such as the predictions of a classification model. We developed an interactive framework that visually explores the latent space and allows the user to understand the relationships of the input features with model prediction.</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-twenty-two" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://diglib.eg.org/handle/10.2312/evs20221098" target="_blank">External Link</a></p>
              <p class="my-1"><small>Research Line <strong>3</strong></small></p>
            </div>
            <div class="row mt-5 justify-content-center" id="BPP2020"></div>
            <div class="col-lg-1 text-right">
              <h4>57.</h4><small>[BPP2020]</small>
            </div>
            <div class="col-lg-8 bg-yellow p-3">
              <div class="accordion" id="accordion-fifty-six"></div><strong>Explainability Methods for Natural Language Processing: Applications to Sentiment Analysis</strong><br><em>Bodria Francesco, Panisson André , Perotti Alan, Piaggesi Simone </em> (2020) - Discussion Paper
              <div class="collapse" id="collapse-fifty-six" aria-labelledby="heading-fifty-six" data-parent="#accordion-fifty-six">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">nan</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="http://ceur-ws.org/Vol-2646/18-paper.pdf" target="_blank">External Link</a></p>
              <p class="my-1"><small>Research Line <strong>1</strong></small></p>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- Footer-->
    <footer class="site-footer">
      <div class="footer-widgets">
        <div class="container">
          <div class="row gx-lg-5">
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-1">
                <h4 class="text-yellow mb-3">Principal Investigator</h4>
                <div class="text-white">
                  <p class="mb-0">Fosca Giannotti</p>
                  <p class="mb-0">Scuola Normale Superiore</p><br>
                  <p class="mb-0">Piazza dei Cavalieri, 7</p>
                  <p class="mb-0">56126 Pisa, Italy</p><br>
                  <p class="mb-0">Email: fosca.giannotti @ sns.it</p>
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-4">
                <div class="text-white">
                  <p>The XAI Project receives funding from the European Union's Horizon 2020 Excellent Science European Research Council (ERC) programme under grant agreement No. 834756</p>The views and opinions expressed in this website are the sole responsibility of the author and do not necessarily reflect the views of the European Commission.
                  <p></p><img class="mb-4" src="assets/images/logo-eu.jpg" alt="EU flag">
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-2">
                <ul>
                  <li><a href="index.html">Xai</a></li>
                  <li><a href="about.html">Project details</a></li>
                  <li><a href="research-lines.html">Research lines</a></li>
                  <li><a href="people.html">People</a></li>
                  <li><a href="resources.html">Resources</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="footer-bottom-area">
        <div class="container">
          <div class="row gx-lg-5 align-items-center">
            <div class="col-md-12"><span class="text-yellow strong">Webdesign: Daniele Fadda © 2023</span></div>
          </div>
        </div>
      </div>
    </footer>
    <!-- End Footer-->
    <!-- javascript files-->
    <!-- jquery-->
    <script src="assets/js/jquery.min.js"></script>
    <!-- lozad js-->
    <script src="assets/js/lozad.min.js"></script>
    <!-- Bootstrap js-->
    <script src="assets/js/bootstrap.bundle.min.js"></script>
    <!-- Aos js-->
    <script src="assets/js/aos.js"></script>
    <!-- Slick flickity js-->
    <script src="assets/js/flickity.pkgd.min.js"></script>
    <!-- Magnific popup js-->
    <script src="assets/js/jquery.magnific-popup.min.js"></script>
    <!-- Countdown js-->
    <script src="assets/js/jquery.countdown.js"></script>
    <!-- CountTo js-->
    <script src="assets/js/jquery.countTo.js"></script>
    <!-- Global - Main js-->
    <script src="assets/js/global.js"></script>
    <!-- Global - Main js-->
    <script src="assets/js/cookies.js"></script>
  </body>
</html>