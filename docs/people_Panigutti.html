<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- favicon-->
    <link rel="shortcut icon" href="assets/images/favicon.ico">
    <!-- Site Title-->
    <title>Xai - Website</title>
    <meta name="description" content="Science and technology for the eXplanation of AI decision making">
    <!-- Bootstrap CSS file-->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">
    <!-- Flickity CSS file-->
    <link href="assets/css/flickity.min.css" rel="stylesheet">
    <!-- Main CSS file-->
    <link href="assets/css/style.css" rel="stylesheet">
    <!-- Fontawesome 5 CSS file-->
    <link href="assets/css/fontawesome-all.min.css" rel="stylesheet">
    <!-- Magnific Popup CSS-->
    <link href="assets/css/magnific-popup.css" rel="stylesheet">
    <!-- Google Fonts-->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;700&amp;display=swap">
    <script type="text/javascript">
      // Matomo Code
      var _paq = window._paq = window._paq || [];
      /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
      _paq.push(['trackPageView']);
      _paq.push(['enableLinkTracking']);
      (function () {
      var u="//piwikdd.isti.cnr.it/";
      _paq.push(['setTrackerUrl', u+'piwik.php']);
      _paq.push(['setSiteId', '12']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
      })
      ();
    </script>
  </head>
  <body>
    <!-- Navbar-->
    <div class="site-header header-bottom-area">
      <nav class="navbar navbar-expand-lg navbar-light sticky">
        <div class="container"><a class="navbar-brand" href="index.html"><img class="site-logo" src="assets/images/logo/xai_logo_color.png" alt="Logo"></a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
          <div class="collapse navbar-collapse" id="navbarNavDropdown">
            <ul class="navbar-nav mx-auto">
              <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
              <li class="nav-item"><a class="nav-link" href="about.html">Project details</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="research-lines.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research Lines</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="line_1.html">1. Local to global</a><a class="dropdown-item" href="line_2.html">2. Casual reasoning</a><a class="dropdown-item" href="line_3.html">3. Platform and XUI</a><a class="dropdown-item" href="line_4.html">4. Case studies</a><a class="dropdown-item" href="line_5.html">5. Ethics and legal</a></div>
              </li>
              <li class="nav-item"><a class="nav-link" href="people.html">People</a></li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="resources.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Publications and Resources</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="resources.html#publications">Publications</a>
                  <!-- a.dropdown-item(href='reports.html') Reports--><a class="dropdown-item" href="resources.html#thesis">Thesis</a><a class="dropdown-item" href="dissemination.html">Dissemination tools</a>
                </div>
              </li>
              <li class="nav-item dropdown"><a class="dropdown-toggle nav-link" href="#" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Seminars</a>
                <div class="dropdown-menu"><a class="dropdown-item" href="seminars.html">All Seminars</a><a class="dropdown-item" href="dist-seminars.html">Distinguished seminars</a>
                  <!--a.dropdown-item(href='internal-events.html') Internal Events-->
                </div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </div>
    <!-- End Navbar-->
    <!-- Cookies-->
    <div class="cookie-banner" style="display: none">
      <p class="mx-2">We use cookies on this site to enhance your user experience. By clicking any link on this page you are giving your consent for us to set cookies. 
        <u><a href="privacy.html" link’="privacy.html">No, give me more info.</a></u>
      </p>
      <button class="close">&times;</button>
    </div>
    <!-- End Cookies-->
    <article class="entry"></article>
    <div class="entry-content">
      <div class="bg-yellow pt-6 pt-lg-8 pb-4 pb-lg-5">
        <div class="bg-half">
          <div class="container">
            <div class="row">
              <div class="col-lg-4 offset-lg-4">
                <h1 class="text-center">Cecilia Panigutti</h1><img class="card-img" src="assets/images/p_Panigutti.jpg" alt="Cecilia Panigutti"/>
                <div class="member-content">
                  <div class="member-text px-0 py-3">
                    <p class="text-uppercase">Involved in the research line <strong>1 ▪ 4 ▪ 5</strong></p>
                    <p>Role: Phd Student</p>
                    <p class="mb-0">Affiliation: Scuola Normale</p>
                    <hr/>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="container mt-6">
        <div class="row justify-content-lg-center">
          <div class="col-lg-8"></div>
        </div>
      </div>
      <div class="container mb-6">
        <div class="row">
          <div class="row mt-5 justify-content-center" id="PBF2022">
            <div class="col-lg-1 text-right">
              <h4>24.</h4><small>[PBF2022]</small>
            </div>
            <div class="col-lg-8 bg-yellow p-3">
              <div class="accordion" id="accordion-twenty-three"></div><strong>Co-design of human-centered, explainable AI for clinical decision support</strong><br><em>Panigutti Cecilia, Beretta Andrea, Fadda Daniele , Giannotti Fosca, Pedreschi Dino, Perotti Alan, Rinzivillo Salvatore</em> (2022). In ACM Transactions on Interactive Intelligent Systems
              <div class="collapse" id="collapse-twenty-three" aria-labelledby="heading-twenty-three" data-parent="#accordion-twenty-three">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">eXplainable AI (XAI) involves two intertwined but separate challenges: the development of techniques to extract explanations from black-box AI models, and the way such explanations are presented to users, i.e., the explanation user interface. Despite its importance, the second aspect has received limited attention so far in the literature. Effective AI explanation interfaces are fundamental for allowing human decision-makers to take advantage and oversee high-risk AI systems effectively. Following an iterative design approach, we present the first cycle of prototyping-testing-redesigning of an explainable AI technique, and its explanation user interface for clinical Decision Support Systems (DSS). We first present an XAI technique that meets the technical requirements of the healthcare domain: sequential, ontology-linked patient data, and multi-label classification tasks. We demonstrate its applicability to explain a clinical DSS, and we design a first prototype of an explanation user interface. Next, we test such a prototype with healthcare providers and collect their feedback, with a two-fold outcome: first, we obtain evidence that explanations increase users' trust in the XAI system, and second, we obtain useful insights on the perceived deficiencies of their interaction with the system, so that we can re-design a better, more human-centered explanation interface.</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-twenty-three" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><small>Research Line <strong>1▪3▪4</strong></small></p>
            </div>
            <div class="row mt-5 justify-content-center" id="PBP2022"></div>
            <div class="col-lg-1 text-right">
              <h4>25.</h4><small>[PBP2022]</small>
            </div>
            <div class="col-lg-8 bg-yellow p-3">
              <div class="accordion" id="accordion-twenty-four"></div><strong>Understanding the impact of explanations on advice-taking: a user study for AI-based clinical Decision Support Systems</strong><br><em>Panigutti Cecilia, Beretta Andrea, Pedreschi Dino, Giannotti Fosca</em> (2022) - 2022 Conference on Human Factors in Computing Systems. In Proceedings of the 2022 Conference on Human Factors in Computing Systems
              <div class="collapse" id="collapse-twenty-four" aria-labelledby="heading-twenty-four" data-parent="#accordion-twenty-four">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">The field of eXplainable Artificial Intelligence (XAI) focuses on providing explanations for AI systems' decisions. XAI applications to AI-based Clinical Decision Support Systems (DSS) should increase trust in the DSS by allowing clinicians to investigate the reasons behind its suggestions. In this paper, we present the results of a user study on the impact of advice from a clinical DSS on healthcare providers' judgment in two different cases: the case where the clinical DSS explains its suggestion and the case it does not. We examined the weight of advice, the behavioral intention to use the system, and the perceptions with quantitative and qualitative measures. Our results indicate a more significant impact of advice when an explanation for the DSS decision is provided. Additionally, through the open-ended questions, we provide some insights on how to improve the explanations in the diagnosis forecasts for healthcare assistants, nurses, and doctors.</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-twenty-four" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><small>Research Line <strong>4</strong></small></p>
            </div>
            <div class="row mt-5 justify-content-center" id="PMC2022"></div>
            <div class="col-lg-1 text-right">
              <h4>29.</h4><small>[PMC2022]</small>
            </div>
            <div class="col-lg-2 pl-0"><img class="mr-3 border border-secondary bwc-image" src="assets/images/publications/Ethical Societal and Legal.jpg " alt="immagine" style="width:100%;" data-toggle="modal" data-target="#modal-twenty-eight" type="button">
              <div class="modal fade" id="modal-twenty-eight" tabindex="-1" role="dialog" aria-labelledby="#modal-twenty-eight-Title" aria-hidden="true">
                <div class="modal-dialog modal-dialog-centered" role="document">
                  <div class="modal-content">
                    <div class="modal-header">
                      <p class="small">Ethical, societal and legal issues in deep learning for healthcare</p>
                      <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                    </div>
                    <div class="modal-body"><img src="assets/images/publications/Ethical Societal and Legal.jpg " alt="immagine"></div>
                  </div>
                </div>
              </div>
            </div>
            <div class="col-lg-6 bg-yellow p-3">
              <div class="accordion" id="accordion-twenty-eight"></div><strong>Ethical, societal and legal issues in deep learning for healthcare</strong><br><em>Panigutti Cecilia, Monreale Anna, Comandè Giovanni, Pedreschi Dino</em> (2022) - Deep Learning in Biology and Medicine. In Deep Learning in Biology and Medicine
              <div class="collapse" id="collapse-twenty-eight" aria-labelledby="heading-twenty-eight" data-parent="#accordion-twenty-eight">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">Biology, medicine and biochemistry have become data-centric fields for which Deep Learning methods are delivering groundbreaking results. Addressing high impact challenges, Deep Learning in Biology and Medicine provides an accessible and organic collection of Deep Learning essays on bioinformatics and medicine. It caters for a wide readership, ranging from machine learning practitioners and data scientists seeking methodological knowledge to address biomedical applications, to life science specialists in search of a gentle reference for advanced data analytics.With contributions from internationally renowned experts, the book covers foundational methodologies in a wide spectrum of life sciences applications, including electronic health record processing, diagnostic imaging, text processing, as well as omics-data processing. This survey of consolidated problems is complemented by a selection of advanced applications, including cheminformatics and biomedical interaction network analysis. A modern and mindful approach to the use of data-driven methodologies in the life sciences also requires careful consideration of the associated societal, ethical, legal and transparency challenges, which are covered in the concluding chapters of this book.</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-twenty-eight" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://www.worldscientific.com/worldscibooks/10.1142/q0322" target="_blank">External Link</a></p>
              <p class="my-1"><small>Research Line <strong>4</strong></small></p>
            </div>
            <div class="row mt-5 justify-content-center" id="PPB2021"></div>
            <div class="col-lg-1 text-right">
              <h4>42.</h4><small>[PPB2021]</small>
            </div>
            <div class="col-lg-2 pl-0"><img class="mr-3 border border-secondary bwc-image" src="assets/images/publications/FairLens.png " alt="immagine" style="width:100%;" data-toggle="modal" data-target="#modal-forty-one" type="button">
              <div class="modal fade" id="modal-forty-one" tabindex="-1" role="dialog" aria-labelledby="#modal-forty-one-Title" aria-hidden="true">
                <div class="modal-dialog modal-lg modal-dialog-centered" role="document">
                  <div class="modal-content">
                    <div class="modal-header">
                      <p class="small">FairLens: Auditing black-box clinical decision support systems</p>
                      <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                    </div>
                    <div class="modal-body"><img src="assets/images/publications/FairLens.png " alt="immagine"></div>
                  </div>
                </div>
              </div>
            </div>
            <div class="col-lg-6 bg-yellow p-3">
              <div class="accordion" id="accordion-forty-one"></div><strong>FairLens: Auditing black-box clinical decision support systems</strong><br><em>Panigutti Cecilia, Perotti Alan, Panisson André, Bajardi Paolo, Pedreschi Dino</em> (2021) - Information Processing & Management. In Journal of Information Processing and Management
              <div class="collapse" id="collapse-forty-one" aria-labelledby="heading-forty-one" data-parent="#accordion-forty-one">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">Highlights: We present a pipeline to detect and explain potential fairness issues in Clinical DSS. We study and compare different multi-label classification disparity measures. We explore ICD9 bias in MIMIC-IV, an openly available ICU benchmark dataset</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-forty-one" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="http://dx.doi.org/10.1016/j.ipm.2021.102657" target="_blank">External Link</a></p>
              <p class="my-1"><small>Research Line <strong>1▪4</strong></small></p>
            </div>
            <div class="row mt-5 justify-content-center" id="PGM2019"></div>
            <div class="col-lg-1 text-right">
              <h4>51.</h4><small>[PGM2019]</small>
            </div>
            <div class="col-lg-2 pl-0"><img class="mr-3 border border-secondary bwc-image" src="assets/images/publications/Explaining Multi-label Black-Box Classifiers for Health Applications.png " alt="immagine" style="width:100%;" data-toggle="modal" data-target="#modal-fifty" type="button">
              <div class="modal fade" id="modal-fifty" tabindex="-1" role="dialog" aria-labelledby="#modal-fifty-Title" aria-hidden="true">
                <div class="modal-dialog modal-dialog-centered" role="document">
                  <div class="modal-content">
                    <div class="modal-header">
                      <p class="small">Explaining Multi-label Black-Box Classifiers for Health Applications</p>
                      <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                    </div>
                    <div class="modal-body"><img src="assets/images/publications/Explaining Multi-label Black-Box Classifiers for Health Applications.png " alt="immagine"></div>
                  </div>
                </div>
              </div>
            </div>
            <div class="col-lg-6 bg-yellow p-3">
              <div class="accordion" id="accordion-fifty"></div><strong>Explaining Multi-label Black-Box Classifiers for Health Applications</strong><br><em>Panigutti Cecilia, Guidotti Riccardo, Monreale Anna, Pedreschi Dino</em> (2021) - Precision Health and Medicine. In International Workshop on Health Intelligence (pp. 97-110). Springer, Cham.
              <div class="collapse" id="collapse-fifty" aria-labelledby="heading-fifty" data-parent="#accordion-fifty">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">Today the state-of-the-art performance in classification is achieved by the so-called “black boxes”, i.e. decision-making systems whose internal logic is obscure. Such models could revolutionize the health-care system, however their deployment in real-world diagnosis decision support systems is subject to several risks and limitations due to the lack of transparency. The typical classification problem in health-care requires a multi-label approach since the possible labels are not mutually exclusive, e.g. diagnoses. We propose MARLENA, a model-agnostic method which explains multi-label black box decisions. MARLENA explains an individual decision in three steps. First, it generates a synthetic neighborhood around the instance to be explained using a strategy suitable for multi-label decisions. It then learns a decision tree on such neighborhood and finally derives from it a decision rule that explains the black box decision. Our experiments show that MARLENA performs well in terms of mimicking the black box behavior while gaining at the same time a notable amount of interpretability through compact decision rules, i.e. rules with limited length.</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-fifty" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="http://dx.doi.org/10.1007/978-3-030-24409-5_9" target="_blank">External Link</a></p>
              <p class="my-1"><small>Research Line <strong>1▪4</strong></small></p>
            </div>
            <div class="row mt-5 justify-content-center" id="PPP2020"></div>
            <div class="col-lg-1 text-right">
              <h4>54.</h4><small>[PPP2020]</small>
            </div>
            <div class="col-lg-2 pl-0"><img class="mr-3 border border-secondary bwc-image" src="assets/images/publications/Doctor XAI.jpg " alt="immagine" style="width:100%;" data-toggle="modal" data-target="#modal-fifty-three" type="button">
              <div class="modal fade" id="modal-fifty-three" tabindex="-1" role="dialog" aria-labelledby="#modal-fifty-three-Title" aria-hidden="true">
                <div class="modal-dialog modal-dialog-centered" role="document">
                  <div class="modal-content">
                    <div class="modal-header">
                      <p class="small">Doctor XAI: an ontology-based approach to black-box sequential data classification explanations</p>
                      <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                    </div>
                    <div class="modal-body"><img src="assets/images/publications/Doctor XAI.jpg " alt="immagine"></div>
                  </div>
                </div>
              </div>
            </div>
            <div class="col-lg-6 bg-yellow p-3">
              <div class="accordion" id="accordion-fifty-three"></div><strong>Doctor XAI: an ontology-based approach to black-box sequential data classification explanations</strong><br><em>Panigutti Cecilia, Perotti Alan, Pedreschi Dino</em> (2020) - FAT* '20: Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. In FAT* '20: Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency
              <div class="collapse" id="collapse-fifty-three" aria-labelledby="heading-fifty-three" data-parent="#accordion-fifty-three">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">Several recent advancements in Machine Learning involve blackbox models: algorithms that do not provide human-understandable explanations in support of their decisions. This limitation hampers the fairness, accountability and transparency of these models; the field of eXplainable Artificial Intelligence (XAI) tries to solve this problem providing human-understandable explanations for black-box models. However, healthcare datasets (and the related learning tasks) often present peculiar features, such as sequential data, multi-label predictions, and links to structured background knowledge. In this paper, we introduce Doctor XAI, a model-agnostic explainability technique able to deal with multi-labeled, sequential, ontology-linked data. We focus on explaining Doctor AI, a multilabel classifier which takes as input the clinical history of a patient in order to predict the next visit. Furthermore, we show how exploiting the temporal dimension in the data and the domain knowledge encoded in the medical ontology improves the quality of the mined explanations.</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-fifty-three" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://dl.acm.org/doi/10.1145/3351095.3372855" target="_blank">External Link</a></p>
              <p class="my-1"><small>Research Line <strong>1▪3▪4</strong></small></p>
            </div>
            <div class="row mt-5 justify-content-center" id="GPP2019"></div>
            <div class="col-lg-1 text-right">
              <h4>59.</h4><small>[GPP2019]</small>
            </div>
            <div class="col-lg-2 pl-0"><img class="mr-3 border border-secondary bwc-image" src="assets/images/publications/mulino_pandemia.jpg " alt="immagine" style="width:100%;" data-toggle="modal" data-target="#modal-fifty-eight" type="button">
              <div class="modal fade" id="modal-fifty-eight" tabindex="-1" role="dialog" aria-labelledby="#modal-fifty-eight-Title" aria-hidden="true">
                <div class="modal-dialog modal-dialog-centered" role="document">
                  <div class="modal-content">
                    <div class="modal-header">
                      <p class="small">I.A. comprensibile per il supporto alle decisioni: doctor XAI</p>
                      <button class="close" type="button" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
                    </div>
                    <div class="modal-body"><img src="assets/images/publications/mulino_pandemia.jpg " alt="immagine"></div>
                  </div>
                </div>
              </div>
            </div>
            <div class="col-lg-6 bg-yellow p-3">
              <div class="accordion" id="accordion-fifty-eight"></div><strong>I.A. comprensibile per il supporto alle decisioni: doctor XAI</strong><br><em>Giannotti Fosca, Pedreschi Dino, Panigutti Cecilia</em> (2019) - Biopolitica, Pandemia e democrazia. Rule of law nella società digitale. In BIOPOLITICA, PANDEMIA E DEMOCRAZIA Rule of law nella società digitale
              <div class="collapse" id="collapse-fifty-eight" aria-labelledby="heading-fifty-eight" data-parent="#accordion-fifty-eight">
                <div class="bg-yellow">
                  <hr>
                  <p class="small"><strong>Abstract</strong></p>
                  <p class="small">La crisi sanitaria ha trasformato le relazioni tra Stato e cittadini, conducendo a limitazioni temporanee dei diritti fondamentali e facendo emergere conflitti tra le due dimensioni della salute, come diritto della persona e come diritto della comunità, e tra il diritto alla salute e le esigenze del sistema economico. Per far fronte all’emergenza, si è modificato il tradizionale equilibrio tra i poteri dello Stato, in una prospettiva in cui il tempo dell’emergenza sembra proiettarsi ancora a lungo sul futuro. La pandemia ha inoltre potenziato la centralità del digitale, dall’utilizzo di software di intelligenza artificiale per il tracciamento del contagio alla nuova connettività del lavoro remoto, passando per la telemedicina. Le nuove tecnologie svolgono un ruolo di prevenzione e controllo, ma pongono anche delicate questioni costituzionali: come tutelare la privacy individuale di fronte al Panopticon digitale? Come inquadrare lo statuto delle piattaforme digitali, veri e propri poteri tecnologici privati, all’interno dei nostri ordinamenti? La ricerca presentata in questo volume e nei due volumi collegati propone le riflessioni su questi temi di studiosi afferenti a una moltitudine di aree disciplinari: medici, giuristi, ingegneri, esperti di robotica e di IA analizzano gli effetti dell’emergenza sanitaria sulla tenuta del modello democratico occidentale, con l’obiettivo di aprire una riflessione sulle linee guida per la ricostruzione del Paese, oltre la pandemia. In particolare, questo terzo volume affronta gli aspetti legati all’impatto della tecnologia digitale e dell’IA sui processi, sulla scuola e sulla medicina, con una riflessione su temi quali l’organizzazione della giustizia, le responsabilità, le carenze organizzative degli enti.</p>
                </div>
              </div>
            </div>
            <div class="col-lg-2 pl-3">
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="#" data-toggle="collapse" data-target="#collapse-fifty-eight" aria-expanded="true" aria-controls="collapseAbs">More information</a></p>
              <p class="my-1"><a class="btn-mini px-2 btn-secondary small" href="https://www.mulino.it/isbn/9788815293060#" target="_blank">External Link</a></p>
              <p class="my-1"><small>Research Line <strong>4</strong></small></p>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- Footer-->
    <footer class="site-footer">
      <div class="footer-widgets">
        <div class="container">
          <div class="row gx-lg-5">
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-1">
                <h4 class="text-yellow mb-3">Principal Investigator</h4>
                <div class="text-white">
                  <p class="mb-0">Fosca Giannotti</p>
                  <p class="mb-0">Scuola Normale Superiore</p><br>
                  <p class="mb-0">Piazza dei Cavalieri, 7</p>
                  <p class="mb-0">56126 Pisa, Italy</p><br>
                  <p class="mb-0">Email: fosca.giannotti @ sns.it</p>
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-4">
                <div class="text-white">
                  <p>The XAI Project receives funding from the European Union's Horizon 2020 Excellent Science European Research Council (ERC) programme under grant agreement No. 834756</p>The views and opinions expressed in this website are the sole responsibility of the author and do not necessarily reflect the views of the European Commission.
                  <p></p><img class="mb-4" src="assets/images/logo-eu.jpg" alt="EU flag">
                </div>
              </div>
            </div>
            <div class="col-lg-4">
              <div class="footer-widget footer-widget-2">
                <ul>
                  <li><a href="index.html">Xai</a></li>
                  <li><a href="about.html">Project details</a></li>
                  <li><a href="research-lines.html">Research lines</a></li>
                  <li><a href="people.html">People</a></li>
                  <li><a href="resources.html">Resources</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="footer-bottom-area">
        <div class="container">
          <div class="row gx-lg-5 align-items-center">
            <div class="col-md-12"><span class="text-yellow strong">Webdesign: Daniele Fadda © 2023</span></div>
          </div>
        </div>
      </div>
    </footer>
    <!-- End Footer-->
    <!-- javascript files-->
    <!-- jquery-->
    <script src="assets/js/jquery.min.js"></script>
    <!-- lozad js-->
    <script src="assets/js/lozad.min.js"></script>
    <!-- Bootstrap js-->
    <script src="assets/js/bootstrap.bundle.min.js"></script>
    <!-- Aos js-->
    <script src="assets/js/aos.js"></script>
    <!-- Slick flickity js-->
    <script src="assets/js/flickity.pkgd.min.js"></script>
    <!-- Magnific popup js-->
    <script src="assets/js/jquery.magnific-popup.min.js"></script>
    <!-- Countdown js-->
    <script src="assets/js/jquery.countdown.js"></script>
    <!-- CountTo js-->
    <script src="assets/js/jquery.countTo.js"></script>
    <!-- Global - Main js-->
    <script src="assets/js/global.js"></script>
    <!-- Global - Main js-->
    <script src="assets/js/cookies.js"></script>
  </body>
</html>