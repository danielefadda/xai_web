.row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4#PR2023.anchor 8.
        small [PR2023]
    .col-lg-8.bg-yellow.p-3
        #accordion-seven.accordion
        | #[strong AUC-based Selective Classification]
        br
        | #[em Pugnana Andrea, Ruggieri Salvatore] (2023) - Proceedings of Machine Learning Research. In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics
        #collapse-seven.collapse(aria-labelledby='heading-seven' data-parent='#accordion-seven')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small Selective classification (or classification with a reject option) pairs a classifier with a selection function to determine whether or not a prediction should be accepted. This framework trades off coverage (probability of accepting a prediction) with predictive performance, typically measured by distributive loss functions. In many application scenarios, such as credit scoring, performance is instead measured by ranking metrics, such as the Area Under the ROC Curve (AUC). We propose a model-agnostic approach to associate a selection function to a given probabilistic binary classifier. The approach is specifically targeted at optimizing the AUC. We provide both theoretical justifications and a novel algorithm, called AUCROSS, to achieve such a goal. Experiments show that our method succeeds in trading-off coverage for AUC, improving over existing selective classification methods targeted at optimizing accuracy.
    .col-lg-2.pl-3
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-seven' aria-expanded='true' aria-controls='collapseAbs') More information
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='https://proceedings.mlr.press/v206/pugnana23a.html', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 2]
    .row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4#NPR2022.anchor 18.
        small [NPR2022]
    .col-lg-8.bg-yellow.p-3
        #accordion-seventeen.accordion
        | #[strong Methods and tools for causal discovery and causal inference]
        br
        | #[em Ana Rita Nogueira, Andrea Pugnana, Salvatore Ruggieri, Dino Pedreschi, João Gama] (2022) - Wires Data Mining and Knowledge Discovery. In Wires Data Mining and Knowledge Discovery
        #collapse-seventeen.collapse(aria-labelledby='heading-seventeen' data-parent='#accordion-seventeen')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small Causality is a complex concept, which roots its developments across several fields, such as statistics, economics, epidemiology, computer science, and philosophy. In recent years, the study of causal relationships has become a crucial part of the Artificial Intelligence community, as causality can be a key tool for overcoming some limitations of correlation-based Machine Learning systems. Causality research can generally be divided into two main branches, that is, causal discovery and causal inference. The former focuses on obtaining causal knowledge directly from observational data. The latter aims to estimate the impact deriving from a change of a certain variable over an outcome of interest. This article aims at covering several methodologies that have been developed for both tasks. This survey does not only focus on theoretical aspects. But also provides a practical toolkit for interested researchers and practitioners, including software, datasets, and running examples.
    .col-lg-2.pl-3
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-seventeen' aria-expanded='true' aria-controls='collapseAbs') More information
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href=' https://doi.org/10.1002/widm.1449', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 2]
    .row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4#SMM2022.anchor 26.
        small [SMM2022]
    .col-lg-8.bg-yellow.p-3
        #accordion-twenty-five.accordion
        | #[strong TriplEx: Triple Extraction for Explanation]
        br
        | #[em Setzu Mattia, Monreale Anna, Minervini Pasquale] (2022) - Third Conference on Cognitive Machine Intelligence (COGMI) 2021
        #collapse-twenty-five.collapse(aria-labelledby='heading-twenty-five' data-parent='#accordion-twenty-five')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small nan
    .col-lg-2.pl-3
        
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='10.1109/CogMI52975.2021.00015', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 1▪2]
    .row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4#BGM2021.anchor 39.
        small [BGM2021]
    .col-lg-8.bg-yellow.p-3
        #accordion-thirty-eight.accordion
        | #[strong Deriving a Single Interpretable Model by Merging Tree-Based Classifiers]
        br
        | #[em Bonsignori Valerio, Guidotti Riccardo, Monreale Anna] (2021) - Discovery Science
        #collapse-thirty-eight.collapse(aria-labelledby='heading-thirty-eight' data-parent='#accordion-thirty-eight')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small Decision tree classifiers have been proved to be among the most interpretable models due to their intuitive structure that illustrates decision processes in form of logical rules. Unfortunately, more complex tree-based classifiers such as oblique trees and random forests overcome the accuracy of decision trees at the cost of becoming non interpretable. In this paper, we propose a method that takes as input any tree-based classifier and returns a single decision tree able to approximate its behavior. Our proposal merges tree-based classifiers by an intensional and extensional approach and applies a post-hoc explanation strategy. Our experiments shows that the retrieved single decision tree is at least as accurate as the original tree-based model, faithful, and more interpretable.
    .col-lg-2.pl-3
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirty-eight' aria-expanded='true' aria-controls='collapseAbs') More information
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-88942-5_27', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 1▪2]
    .row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4#GMP2019.anchor 60.
        small [GMP2019]
    .col-lg-8.bg-yellow.p-3
        #accordion-fifty-nine.accordion
        | #[strong The AI black box explanation problem]
        br
        | #[em Guidotti Riccardo, Monreale Anna, Pedreschi Dino] (2019) - ERCIM News, 116, 12-13. In ERCIM News, 116, 12-13
        #collapse-fifty-nine.collapse(aria-labelledby='heading-fifty-nine' data-parent='#accordion-fifty-nine')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small nan
    .col-lg-2.pl-3
        
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='https://ercim-news.ercim.eu/images/stories/EN116/EN116-web.pdf#page=12', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 1▪2▪3]
    