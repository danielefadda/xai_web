
.row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4 7.
    .col-lg-8.bg-yellow.p-3
        #accordion-six.accordion
        | #[strong Trustworthy AI]
        br
        | #[em Chatila Raja, Dignum Virginia, Fisher Michael, Giannotti Fosca, Morik Katharina, Russell Stuart, Yeung Karen] (2022) - Reflections on Artificial Intelligence for Humanity. In Lecture Notes in Computer Science,
        #collapse-six.collapse(aria-labelledby='heading-six' data-parent='#accordion-six')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small Modern AI systems have become of widespread use in almost all sectors with a strong impact on our society. However, the very methods on which they rely, based on Machine Learning techniques for processing data to predict outcomes and to make decisions, are opaque, prone to bias and may produce wrong answers. Objective functions optimized in learning systems are not guaranteed to align with the values that motivated their definition. Properties such as transparency, verifiability, explainability, security, technical robustness and safety, are key to build operational governance frameworks, so that to make AI systems justifiably trustworthy and to align their development and use with human rights and values.
    .col-lg-2.pl-3
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-six' aria-expanded='true' aria-controls='collapseAbs') More information
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-69128-8_2', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 5]
    
.row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4 9.
    .col-lg-2.pl-0
        img(src='assets/images/publications/springer_book_explain.jpg ' alt="immagine" style='width:100%;' data-toggle='modal' data-target='#modal-eight' type='button').mr-3.border.border-secondary.bwc-image
        #modal-eight.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-eight-Title' aria-hidden='true')
            .modal-dialog.modal-dialog-centered(role='document')
                .modal-content
                    .modal-header
                        p.small Explainable AI Within the Digital Transformation and Cyber Physical Systems: XAI Methods and Applications
                        button.close(type='button' data-dismiss='modal' aria-label='Close')
                            span(aria-hidden='true') &times;
                    .modal-body
                        img(src='assets/images/publications/springer_book_explain.jpg ' alt="immagine" )
    .col-lg-6.bg-yellow.p-3
        #accordion-eight.accordion
        | #[strong Explainable AI Within the Digital Transformation and Cyber Physical Systems: XAI Methods and Applications]
        br
        | #[em Guidotti Riccardo, Monreale Anna, Pedreschi Dino, Giannotti Fosca] (2021) - Explainable AI Within the Digital Transformation and Cyber Physical Systems (pp. 9-31)
        #collapse-eight.collapse(aria-labelledby='heading-eight' data-parent='#accordion-eight')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small This book presents Explainable Artificial Intelligence (XAI), which aims at producing explainable models that enable human users to understand and appropriately trust the obtained results. The authors discuss the challenges involved in making machine learning-based AI explainable. Firstly, that the explanations must be adapted to different stakeholders (end-users, policy makers, industries, utilities etc.) with different levels of technical knowledge (managers, engineers, technicians, etc.) in different application domains. Secondly, that it is important to develop an evaluation framework and standards in order to measure the effectiveness of the provided explanations at the human and the technical levels. This book gathers research contributions aiming at the development and/or the use of XAI techniques in order to address the aforementioned challenges in different applications such as healthcare, finance, cybersecurity, and document summarization. It allows highlighting the benefits and requirements of using explainable models in different application domains in order to provide guidance to readers to select the most adapted models to their specified problem and conditions. Includes recent developments of the use of Explainable Artificial Intelligence (XAI) in order to address the challenges of digital transition and cyber-physical systems; Provides a textual scientific description of the use of XAI in order to address the challenges of digital transition and cyber-physical systems; Presents examples and case studies in order to increase transparency and understanding of the methodological concepts.
    .col-lg-2.pl-3
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-eight' aria-expanded='true' aria-controls='collapseAbs') More information
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='https://doi.org/10.1007/978-3-030-76409-8', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 1▪5]
    
.row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4 35.
    .col-lg-8.bg-yellow.p-3
        #accordion-thirty-four.accordion
        | #[strong Rischi etico-legali dell’Intelligenza Artificiale]
        br
        | #[em Anna Monreale] (2020) - DPCE Online, [S.l.], v. 44, n. 3. In DPCE Online, [S.l.], v. 44, n. 3, oct. 2020. ISSN 2037-6677
        #collapse-thirty-four.collapse(aria-labelledby='heading-thirty-four' data-parent='#accordion-thirty-four')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small nan
    .col-lg-2.pl-3
        
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='http://www.dpceonline.it/index.php/dpceonline/article/view/1083', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 5]
    