#PBP2022.row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4 9.
        small [PBP2022]
    .col-lg-8.bg-yellow.p-3
        #accordion-eight.accordion
        | #[strong Understanding the impact of explanations on advice-taking: a user study for AI-based clinical Decision Support Systems]
        br
        | #[em Panigutti Cecilia, Beretta Andrea, Pedreschi Dino, Giannotti Fosca] (2022) - 2022 Conference on Human Factors in Computing Systems. In Proceedings of the 2022 Conference on Human Factors in Computing Systems
        #collapse-eight.collapse(aria-labelledby='heading-eight' data-parent='#accordion-eight')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small The field of eXplainable Artificial Intelligence (XAI) focuses on providing explanations for AI systems' decisions. XAI applications to AI-based Clinical Decision Support Systems (DSS) should increase trust in the DSS by allowing clinicians to investigate the reasons behind its suggestions. In this paper, we present the results of a user study on the impact of advice from a clinical DSS on healthcare providers' judgment in two different cases: the case where the clinical DSS explains its suggestion and the case it does not. We examined the weight of advice, the behavioral intention to use the system, and the perceptions with quantitative and qualitative measures. Our results indicate a more significant impact of advice when an explanation for the DSS decision is provided. Additionally, through the open-ended questions, we provide some insights on how to improve the explanations in the diagnosis forecasts for healthcare assistants, nurses, and doctors.
    .col-lg-2.pl-3
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-eight' aria-expanded='true' aria-controls='collapseAbs') More information
        
        p.my-1
                    small Research Line #[strong 4]
    