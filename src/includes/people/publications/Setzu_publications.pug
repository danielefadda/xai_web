#SGM2021.row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4 3.
        small [SGM2021]
    .col-lg-2.pl-0
        img(src='assets/images/publications/02_glocalX.jpg ' alt="immagine" style='width:100%;' data-toggle='modal' data-target='#modal-two' type='button').mr-3.border.border-secondary.bwc-image
        #modal-two.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-two-Title' aria-hidden='true')
            .modal-dialog.modal-lg.modal-dialog-centered(role='document')
                .modal-content
                    .modal-header
                        p.small GLocalX - From Local to Global Explanations of Black Box AI Models
                        button.close(type='button' data-dismiss='modal' aria-label='Close')
                            span(aria-hidden='true') &times;
                    .modal-body
                        img(src='assets/images/publications/02_glocalX.jpg ' alt="immagine" )
    .col-lg-6.bg-yellow.p-3
        #accordion-two.accordion
        | #[strong GLocalX - From Local to Global Explanations of Black Box AI Models]
        br
        | #[em Setzu Mattia, Guidotti Riccardo, Monreale Anna, Turini Franco, Pedreschi Dino, Giannotti Fosca] (2021) - Artificial Intelligence. In Artificial Intelligence
        #collapse-two.collapse(aria-labelledby='heading-two' data-parent='#accordion-two')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small Artificial Intelligence (AI) has come to prominence as one of the major components of our society, with applications in most aspects of our lives. In this field, complex and highly nonlinear machine learning models such as ensemble models, deep neural networks, and Support Vector Machines have consistently shown remarkable accuracy in solving complex tasks. Although accurate, AI models often are “black boxes” which we are not able to understand. Relying on these models has a multifaceted impact and raises significant concerns about their transparency. Applications in sensitive and critical domains are a strong motivational factor in trying to understand the behavior of black boxes. We propose to address this issue by providing an interpretable layer on top of black box models by aggregating “local” explanations. We present GLocalX, a “local-first” model agnostic explanation method. Starting from local explanations expressed in form of local decision rules, GLocalX iteratively generalizes them into global explanations by hierarchically aggregating them. Our goal is to learn accurate yet simple interpretable models to emulate the given black box, and, if possible, replace it entirely. We validate GLocalX in a set of experiments in standard and constrained settings with limited or no access to either data or local explanations. Experiments show that GLocalX is able to accurately emulate several models with simple and small models, reaching state-of-the-art performance against natively global solutions. Our findings show how it is often possible to achieve a high level of both accuracy and comprehensibility of classification models, even in complex domains with high-dimensional data, without necessarily trading one property for the other. This is a key requirement for a trustworthy AI, necessary for adoption in high-stakes decision making applications.
    .col-lg-2.pl-3
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-two' aria-expanded='true' aria-controls='collapseAbs') More information
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1016/j.artint.2021.103457', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 1▪4]
    #SMM2022.row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4 10.
        small [SMM2022]
    .col-lg-8.bg-yellow.p-3
        #accordion-nine.accordion
        | #[strong TriplEx: Triple Extraction for Explanation]
        br
        | #[em Setzu Mattia, Monreale Anna, Minervini Pasquale] (2022) - Third Conference on Cognitive Machine Intelligence (COGMI) 2021
        #collapse-nine.collapse(aria-labelledby='heading-nine' data-parent='#accordion-nine')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small nan
    .col-lg-2.pl-3
        
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='10.1109/CogMI52975.2021.00015', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 1]
    #SGM2019.row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4 29.
        small [SGM2019]
    .col-lg-8.bg-yellow.p-3
        #accordion-twenty-eight.accordion
        | #[strong Global Explanations with Local Scoring]
        br
        | #[em Setzu Mattia, Guidotti Riccardo, Monreale Anna, Turini Franco] (2021) - Machine Learning and Knowledge Discovery in Databases. In ECML PKDD 2019: Machine Learning and Knowledge Discovery in Databases
        #collapse-twenty-eight.collapse(aria-labelledby='heading-twenty-eight' data-parent='#accordion-twenty-eight')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small Artificial Intelligence systems often adopt machine learning models encoding complex algorithms with potentially unknown behavior. As the application of these “black box” models grows, it is our responsibility to understand their inner working and formulate them in human-understandable explanations. To this end, we propose a rule-based model-agnostic explanation method that follows a local-to-global schema: it generalizes a global explanation summarizing the decision logic of a black box starting from the local explanations of single predicted instances. We define a scoring system based on a rule relevance score to extract global explanations from a set of local explanations in the form of decision rules. Experiments on several datasets and black boxes show the stability, and low complexity of the global explanations provided by the proposed solution in comparison with baselines and state-of-the-art global explainers.
    .col-lg-2.pl-3
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twenty-eight' aria-expanded='true' aria-controls='collapseAbs') More information
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-43823-4_14', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 1]
    