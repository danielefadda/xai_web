#GMS2020.row.mt-5.justify-content-center
    .col-lg-1.text-right
        h4 37.
        small [GMS2020]
    .col-lg-2.pl-0
        img(src='assets/images/publications/ex_time_series_calssifier.png ' alt="immagine" style='width:100%;' data-toggle='modal' data-target='#modal-thirty-six' type='button').mr-3.border.border-secondary.bwc-image
        #modal-thirty-six.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-thirty-six-Title' aria-hidden='true')
            .modal-dialog.modal-lg.modal-dialog-centered(role='document')
                .modal-content
                    .modal-header
                        p.small Explaining Any Time Series Classifier
                        button.close(type='button' data-dismiss='modal' aria-label='Close')
                            span(aria-hidden='true') &times;
                    .modal-body
                        img(src='assets/images/publications/ex_time_series_calssifier.png ' alt="immagine" )
    .col-lg-6.bg-yellow.p-3
        #accordion-thirty-six.accordion
        | #[strong Explaining Any Time Series Classifier]
        br
        | #[em Guidotti Riccardo, Monreale Anna, Spinnato Francesco, Pedreschi Dino, Giannotti Fosca] (2020) - 2020 IEEE Second International Conference on Cognitive Machine Intelligence (CogMI)
        #collapse-thirty-six.collapse(aria-labelledby='heading-thirty-six' data-parent='#accordion-thirty-six')
            div.bg-yellow
                hr
                p.small #[strong Abstract]
                p.small We present a method to explain the decisions of black box models for time series classification. The explanation consists of factual and counterfactual shapelet-based rules revealing the reasons for the classification, and of a set of exemplars and counter-exemplars highlighting similarities and differences with the time series under analysis. The proposed method first generates exemplar and counter-exemplar time series in the latent feature space and learns a local latent decision tree classifier. Then, it selects and decodes those respecting the decision rules explaining the decision. Finally, it learns on them a shapelet-tree that reveals the parts of the time series that must, and must not, be contained for getting the returned outcome from the black box. A wide experimentation shows that the proposed method provides faithful, meaningful and interpretable explanations.
    .col-lg-2.pl-3
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirty-six' aria-expanded='true' aria-controls='collapseAbs') More information
        p.my-1
                a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1109/cogmi50398.2020.00029', target="_blank") External Link
        p.my-1
                    small Research Line #[strong 1]
    