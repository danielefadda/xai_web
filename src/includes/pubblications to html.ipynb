{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ninety-nine'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "p.number_to_words(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_id = '1VaF5jAauYYYKo1WH40kLlsQ0-azIX5eMZoFYv5JrVr0'\n",
    "sheet_names = ['papers','dataset','algorithms','masterThesis','phdThesis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_html(string,filename='filename',extension='pug'):\n",
    "    Html_file= open(f\"{filename}.{extension}\",\"w\")\n",
    "    Html_file.write(string)\n",
    "    Html_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name= sheet_names[0]\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Inside EU portal', 'Id in EU', 'id', 'Id di Riccardo',\n",
       "       'Title of the scientific publication', 'doi link', 'DOI',\n",
       "       'Year of publication', 'Type of scientific publication', 'container',\n",
       "       'Publisher', 'ISSN or eSSN', 'Authors', 'abstract', 'DOI_exists',\n",
       "       'Title of the journal or equivalent', 'Number, date',\n",
       "       'Place of publication', 'Pubblication status', 'Relevant pages',\n",
       "       'Joint Public / Private publication', 'Peer-review',\n",
       "       'Is/will open access provided to this publication', 'Research line',\n",
       "       'List of dataset used in the paper', 'Issue', 'visible on website',\n",
       "       '_merge', 'summary image', 'image size', 'image file', 'featured'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = pd.read_csv(url,header=0)\n",
    "papers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eccolo\n"
     ]
    }
   ],
   "source": [
    "if '1' in (papers['Research line'][0]).split(','):\n",
    "    print('eccolo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [*range(1,6,1)]\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inside EU portal</th>\n",
       "      <th>Id in EU</th>\n",
       "      <th>id</th>\n",
       "      <th>Id di Riccardo</th>\n",
       "      <th>Title of the scientific publication</th>\n",
       "      <th>doi link</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Year of publication</th>\n",
       "      <th>Type of scientific publication</th>\n",
       "      <th>container</th>\n",
       "      <th>...</th>\n",
       "      <th>Is/will open access provided to this publication</th>\n",
       "      <th>Research line</th>\n",
       "      <th>List of dataset used in the paper</th>\n",
       "      <th>Issue</th>\n",
       "      <th>visible on website</th>\n",
       "      <th>_merge</th>\n",
       "      <th>summary image</th>\n",
       "      <th>image size</th>\n",
       "      <th>image file</th>\n",
       "      <th>featured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>GMR2018a</td>\n",
       "      <td>Local Rule-Based Explanations of Black Box Dec...</td>\n",
       "      <td>https://arxiv.org/abs/1805.10820</td>\n",
       "      <td>1805.10820</td>\n",
       "      <td>2018</td>\n",
       "      <td>Arxive pre-print</td>\n",
       "      <td>Arxive preprint</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-XAI</td>\n",
       "      <td>YES</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>PGG2018</td>\n",
       "      <td>Open the Black Box Data-Driven Explanation of ...</td>\n",
       "      <td>https://arxiv.org/abs/1806.09936</td>\n",
       "      <td>1806.09936</td>\n",
       "      <td>2018</td>\n",
       "      <td>Arxive pre-print</td>\n",
       "      <td>Arxive preprint</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-XAI</td>\n",
       "      <td>YES</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>GMP2019</td>\n",
       "      <td>The AI black box explanation problem</td>\n",
       "      <td>https://ercim-news.ercim.eu/images/stories/EN1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>book-chapter</td>\n",
       "      <td>ERCIM News, 116, 12-13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,2,3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>BPP2020</td>\n",
       "      <td>Explainability Methods for Natural Language Pr...</td>\n",
       "      <td>http://ceur-ws.org/Vol-2646/18-paper.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>discussion paper</td>\n",
       "      <td>Discussion Paper</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yes</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>GM2020</td>\n",
       "      <td>Data-Agnostic Local Neighborhood Generation</td>\n",
       "      <td>https://ieeexplore.ieee.org/document/9338395</td>\n",
       "      <td>10.1109/ICDM50108.2020.00122</td>\n",
       "      <td>2020</td>\n",
       "      <td>conference proceedings</td>\n",
       "      <td>2020 IEEE International Conference on Data Min...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>RGG2020</td>\n",
       "      <td>Opening the black box: a primer for anti-discr...</td>\n",
       "      <td>http://hdl.handle.net/11568/1088440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>GMC2019</td>\n",
       "      <td>Investigating Neighborhood Generation Methods ...</td>\n",
       "      <td>http://dx.doi.org/10.1007/978-3-030-16148-4_5</td>\n",
       "      <td>10.1007/978-3-030-16148-4_5</td>\n",
       "      <td>2021</td>\n",
       "      <td>book-chapter</td>\n",
       "      <td>Advances in Knowledge Discovery and Data Mining</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No ack / No open access</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>LGR2020</td>\n",
       "      <td>Explaining Sentiment Classification with Synth...</td>\n",
       "      <td>http://dx.doi.org/10.1007/978-3-030-61527-7_24</td>\n",
       "      <td>10.1007/978-3-030-61527-7_24</td>\n",
       "      <td>2021</td>\n",
       "      <td>book-chapter</td>\n",
       "      <td>Discovery Science</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>G2021</td>\n",
       "      <td>Evaluating local explanation methods on ground...</td>\n",
       "      <td>http://dx.doi.org/10.1016/j.artint.2020.103428</td>\n",
       "      <td>10.1016/j.artint.2020.103428</td>\n",
       "      <td>2021</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>PGG2019</td>\n",
       "      <td>Meaningful Explanations of Black Box AI Decisi...</td>\n",
       "      <td>http://dx.doi.org/10.1609/aaai.v33i01.33019780</td>\n",
       "      <td>10.1609/aaai.v33i01.33019780</td>\n",
       "      <td>2021</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Proceedings of the AAAI Conference on Artifici...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before 2019 / no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>GMM2019</td>\n",
       "      <td>Black Box Explanation by Learning Image Exempl...</td>\n",
       "      <td>http://dx.doi.org/10.1007/978-3-030-46150-8_12</td>\n",
       "      <td>10.1007/978-3-030-46150-8_12</td>\n",
       "      <td>2021</td>\n",
       "      <td>book-chapter</td>\n",
       "      <td>Machine Learning and Knowledge Discovery in Da...</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>1,4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>SGM2019</td>\n",
       "      <td>Global Explanations with Local Scoring</td>\n",
       "      <td>http://dx.doi.org/10.1007/978-3-030-43823-4_14</td>\n",
       "      <td>10.1007/978-3-030-43823-4_14</td>\n",
       "      <td>2021</td>\n",
       "      <td>book-chapter</td>\n",
       "      <td>Machine Learning and Knowledge Discovery in Da...</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No open access / No ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "      <td>SGM2021</td>\n",
       "      <td>GLocalX - From Local to Global Explanations of...</td>\n",
       "      <td>http://dx.doi.org/10.1016/j.artint.2021.103457</td>\n",
       "      <td>10.1016/j.artint.2021.103457</td>\n",
       "      <td>2021</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>...</td>\n",
       "      <td>YES - Gold</td>\n",
       "      <td>1,4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>YES</td>\n",
       "      <td>big</td>\n",
       "      <td>02_glocalX.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Yes</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26</td>\n",
       "      <td>BGM2021</td>\n",
       "      <td>Deriving a Single Interpretable Model by Mergi...</td>\n",
       "      <td>http://dx.doi.org/10.1007/978-3-030-88942-5_27</td>\n",
       "      <td>10.1007/978-3-030-88942-5_27</td>\n",
       "      <td>2021</td>\n",
       "      <td>book-chapter</td>\n",
       "      <td>Discovery Science</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no open access</td>\n",
       "      <td>YES</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>MBG2021</td>\n",
       "      <td>Explainable Deep Image Classifiers for Skin Le...</td>\n",
       "      <td>https://arxiv.org/abs/2111.11863</td>\n",
       "      <td>2111.11863v1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Arxive pre-print</td>\n",
       "      <td>Arxive preprint</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submitted not published</td>\n",
       "      <td>NO</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>GR2021</td>\n",
       "      <td>Ensemble of Counterfactual Explainers</td>\n",
       "      <td>http://pages.di.unipi.it/ruggieri/Papers/ds202...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>MGY2021</td>\n",
       "      <td>Exemplars and Counterexemplars Explanations fo...</td>\n",
       "      <td>http://dx.doi.org/10.1109/iscc53001.2021.9631485</td>\n",
       "      <td>10.1109/ISCC53001.2021.9631485</td>\n",
       "      <td>2021</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>2021 IEEE Symposium on Computers and Communica...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>GM2021</td>\n",
       "      <td>Designing Shapelets for Interpretable Data-Agn...</td>\n",
       "      <td>https://doi.org/10.1145/3461702.3462553</td>\n",
       "      <td>10.1145/3461702.3462553</td>\n",
       "      <td>2021</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>Proceedings of the 2021 AAAI/ACM Conference on...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>GSN2021</td>\n",
       "      <td>Helping Your Docker Images to Spread Based on ...</td>\n",
       "      <td>http://dx.doi.org/10.1007/978-3-030-10997-4_13</td>\n",
       "      <td>10.1007/978-3-030-10997-4_13</td>\n",
       "      <td>2021</td>\n",
       "      <td>book-chapter</td>\n",
       "      <td>Machine Learning and Knowledge Discovery in Da...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before 2019</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>GD2021</td>\n",
       "      <td>Matrix Profile-Based Interpretable Time Series...</td>\n",
       "      <td>http://dx.doi.org/10.3389/frai.2021.699448</td>\n",
       "      <td>10.3389/frai.2021.699448</td>\n",
       "      <td>2021</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>Frontiers in Artificial Intelligence</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>left_only</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>GMR2018</td>\n",
       "      <td>A Survey of Methods for Explaining Black Box M...</td>\n",
       "      <td>http://dx.doi.org/10.1145/3236009</td>\n",
       "      <td>10.1145/3236009</td>\n",
       "      <td>2022</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>ACM Computing Surveys</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before 2019, no ack</td>\n",
       "      <td>YES</td>\n",
       "      <td>both</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01_survey_bb.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>GMS2020</td>\n",
       "      <td>Explaining Any Time Series Classifier</td>\n",
       "      <td>http://dx.doi.org/10.1109/cogmi50398.2020.00029</td>\n",
       "      <td>10.1109/CogMI50398.2020.00029</td>\n",
       "      <td>2020</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>2020 IEEE Second International Conference on C...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>big</td>\n",
       "      <td>ex_time_series_calssifier.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Yes</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36</td>\n",
       "      <td>GMP2021</td>\n",
       "      <td>Explainable AI Within the Digital Transformati...</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-76409-8</td>\n",
       "      <td>10.1007/978-3-030-76409-8</td>\n",
       "      <td>2021</td>\n",
       "      <td>book-chapter</td>\n",
       "      <td>Explainable AI Within the Digital Transformati...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No open access</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>springer_book_explain.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38</td>\n",
       "      <td>SMM2022</td>\n",
       "      <td>TriplEx: Triple Extraction for Explanation</td>\n",
       "      <td>10.1109/CogMI52975.2021.00015</td>\n",
       "      <td>10.1109/CogMI52975.2021.00015</td>\n",
       "      <td>2022</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>Third Conference on Cognitive Machine Intellig...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>BGG2021</td>\n",
       "      <td>Benchmarking and survey of explanation methods...</td>\n",
       "      <td>https://arxiv.org/abs/2102.13076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no doi / only in arxiv</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>PBF2022</td>\n",
       "      <td>Co-design of human-centered, explainable AI fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>1,4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submitted not published</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>No</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42</td>\n",
       "      <td>MG2021</td>\n",
       "      <td>FairShades: Fairness Auditing via Explainabili...</td>\n",
       "      <td>https://ieeexplore.ieee.org/document/9750356</td>\n",
       "      <td>10.1109/CogMI52975.2021.00014</td>\n",
       "      <td>2021</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>Third Conference on Cognitive Machine Intellig...</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>1,5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investigating Debiasing Effects on Classificat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1145/3514094.3534170</td>\n",
       "      <td>2022</td>\n",
       "      <td>proceedings-article</td>\n",
       "      <td>Conference on AI, Ethics, and Society (AIES 2022)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No open access</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Inside EU portal  Id in EU  id Id di Riccardo  \\\n",
       "0                No       NaN   1       GMR2018a   \n",
       "1                No       NaN   2        PGG2018   \n",
       "2                No       NaN   3        GMP2019   \n",
       "4                No       NaN   5        BPP2020   \n",
       "5               Yes       9.0   6         GM2020   \n",
       "6               Yes      10.0   7        RGG2020   \n",
       "8                No       NaN   9        GMC2019   \n",
       "10               No       NaN  11        LGR2020   \n",
       "11               No       NaN  12          G2021   \n",
       "12               No       NaN  13        PGG2019   \n",
       "13               No       NaN  14        GMM2019   \n",
       "15               No       NaN  16        SGM2019   \n",
       "22              Yes       2.0  23        SGM2021   \n",
       "25              Yes      17.0  26        BGM2021   \n",
       "26               No       NaN  27        MBG2021   \n",
       "27               No       NaN  28         GR2021   \n",
       "28               No       NaN  29        MGY2021   \n",
       "29               No       NaN  30         GM2021   \n",
       "30               No       NaN  31        GSN2021   \n",
       "31               No       NaN  32         GD2021   \n",
       "33               No       NaN  34        GMR2018   \n",
       "34              Yes       3.0  35        GMS2020   \n",
       "35              Yes      13.0  36        GMP2021   \n",
       "37              Yes      11.0  38        SMM2022   \n",
       "38               No       NaN  39        BGG2021   \n",
       "40               No       NaN  41        PBF2022   \n",
       "41               No      20.0  42         MG2021   \n",
       "43               No       NaN  44            NaN   \n",
       "\n",
       "                  Title of the scientific publication  \\\n",
       "0   Local Rule-Based Explanations of Black Box Dec...   \n",
       "1   Open the Black Box Data-Driven Explanation of ...   \n",
       "2                The AI black box explanation problem   \n",
       "4   Explainability Methods for Natural Language Pr...   \n",
       "5         Data-Agnostic Local Neighborhood Generation   \n",
       "6   Opening the black box: a primer for anti-discr...   \n",
       "8   Investigating Neighborhood Generation Methods ...   \n",
       "10  Explaining Sentiment Classification with Synth...   \n",
       "11  Evaluating local explanation methods on ground...   \n",
       "12  Meaningful Explanations of Black Box AI Decisi...   \n",
       "13  Black Box Explanation by Learning Image Exempl...   \n",
       "15             Global Explanations with Local Scoring   \n",
       "22  GLocalX - From Local to Global Explanations of...   \n",
       "25  Deriving a Single Interpretable Model by Mergi...   \n",
       "26  Explainable Deep Image Classifiers for Skin Le...   \n",
       "27              Ensemble of Counterfactual Explainers   \n",
       "28  Exemplars and Counterexemplars Explanations fo...   \n",
       "29  Designing Shapelets for Interpretable Data-Agn...   \n",
       "30  Helping Your Docker Images to Spread Based on ...   \n",
       "31  Matrix Profile-Based Interpretable Time Series...   \n",
       "33  A Survey of Methods for Explaining Black Box M...   \n",
       "34              Explaining Any Time Series Classifier   \n",
       "35  Explainable AI Within the Digital Transformati...   \n",
       "37         TriplEx: Triple Extraction for Explanation   \n",
       "38  Benchmarking and survey of explanation methods...   \n",
       "40  Co-design of human-centered, explainable AI fo...   \n",
       "41  FairShades: Fairness Auditing via Explainabili...   \n",
       "43  Investigating Debiasing Effects on Classificat...   \n",
       "\n",
       "                                             doi link  \\\n",
       "0                    https://arxiv.org/abs/1805.10820   \n",
       "1                    https://arxiv.org/abs/1806.09936   \n",
       "2   https://ercim-news.ercim.eu/images/stories/EN1...   \n",
       "4            http://ceur-ws.org/Vol-2646/18-paper.pdf   \n",
       "5        https://ieeexplore.ieee.org/document/9338395   \n",
       "6                 http://hdl.handle.net/11568/1088440   \n",
       "8       http://dx.doi.org/10.1007/978-3-030-16148-4_5   \n",
       "10     http://dx.doi.org/10.1007/978-3-030-61527-7_24   \n",
       "11     http://dx.doi.org/10.1016/j.artint.2020.103428   \n",
       "12     http://dx.doi.org/10.1609/aaai.v33i01.33019780   \n",
       "13     http://dx.doi.org/10.1007/978-3-030-46150-8_12   \n",
       "15     http://dx.doi.org/10.1007/978-3-030-43823-4_14   \n",
       "22     http://dx.doi.org/10.1016/j.artint.2021.103457   \n",
       "25     http://dx.doi.org/10.1007/978-3-030-88942-5_27   \n",
       "26                   https://arxiv.org/abs/2111.11863   \n",
       "27  http://pages.di.unipi.it/ruggieri/Papers/ds202...   \n",
       "28   http://dx.doi.org/10.1109/iscc53001.2021.9631485   \n",
       "29            https://doi.org/10.1145/3461702.3462553   \n",
       "30     http://dx.doi.org/10.1007/978-3-030-10997-4_13   \n",
       "31         http://dx.doi.org/10.3389/frai.2021.699448   \n",
       "33                  http://dx.doi.org/10.1145/3236009   \n",
       "34    http://dx.doi.org/10.1109/cogmi50398.2020.00029   \n",
       "35          https://doi.org/10.1007/978-3-030-76409-8   \n",
       "37                      10.1109/CogMI52975.2021.00015   \n",
       "38                   https://arxiv.org/abs/2102.13076   \n",
       "40                                                NaN   \n",
       "41       https://ieeexplore.ieee.org/document/9750356   \n",
       "43                                                NaN   \n",
       "\n",
       "                               DOI  Year of publication  \\\n",
       "0                       1805.10820                 2018   \n",
       "1                       1806.09936                 2018   \n",
       "2                              NaN                 2019   \n",
       "4                              NaN                 2020   \n",
       "5     10.1109/ICDM50108.2020.00122                 2020   \n",
       "6                              NaN                 2020   \n",
       "8      10.1007/978-3-030-16148-4_5                 2021   \n",
       "10    10.1007/978-3-030-61527-7_24                 2021   \n",
       "11    10.1016/j.artint.2020.103428                 2021   \n",
       "12    10.1609/aaai.v33i01.33019780                 2021   \n",
       "13    10.1007/978-3-030-46150-8_12                 2021   \n",
       "15    10.1007/978-3-030-43823-4_14                 2021   \n",
       "22    10.1016/j.artint.2021.103457                 2021   \n",
       "25    10.1007/978-3-030-88942-5_27                 2021   \n",
       "26                    2111.11863v1                 2021   \n",
       "27                             NaN                 2021   \n",
       "28  10.1109/ISCC53001.2021.9631485                 2021   \n",
       "29         10.1145/3461702.3462553                 2021   \n",
       "30    10.1007/978-3-030-10997-4_13                 2021   \n",
       "31        10.3389/frai.2021.699448                 2021   \n",
       "33                 10.1145/3236009                 2022   \n",
       "34   10.1109/CogMI50398.2020.00029                 2020   \n",
       "35       10.1007/978-3-030-76409-8                 2021   \n",
       "37   10.1109/CogMI52975.2021.00015                 2022   \n",
       "38                             NaN                 2021   \n",
       "40                             NaN                 2022   \n",
       "41   10.1109/CogMI52975.2021.00014                 2021   \n",
       "43         10.1145/3514094.3534170                 2022   \n",
       "\n",
       "   Type of scientific publication  \\\n",
       "0                Arxive pre-print   \n",
       "1                Arxive pre-print   \n",
       "2                    book-chapter   \n",
       "4                discussion paper   \n",
       "5          conference proceedings   \n",
       "6                 journal-article   \n",
       "8                    book-chapter   \n",
       "10                   book-chapter   \n",
       "11                journal-article   \n",
       "12                journal-article   \n",
       "13                   book-chapter   \n",
       "15                   book-chapter   \n",
       "22                journal-article   \n",
       "25                   book-chapter   \n",
       "26               Arxive pre-print   \n",
       "27                            NaN   \n",
       "28            proceedings-article   \n",
       "29            proceedings-article   \n",
       "30                   book-chapter   \n",
       "31                journal-article   \n",
       "33                journal-article   \n",
       "34            proceedings-article   \n",
       "35                   book-chapter   \n",
       "37            proceedings-article   \n",
       "38                          arxiv   \n",
       "40                journal-article   \n",
       "41            proceedings-article   \n",
       "43            proceedings-article   \n",
       "\n",
       "                                            container  ...  \\\n",
       "0                                     Arxive preprint  ...   \n",
       "1                                     Arxive preprint  ...   \n",
       "2                              ERCIM News, 116, 12-13  ...   \n",
       "4                                    Discussion Paper  ...   \n",
       "5   2020 IEEE International Conference on Data Min...  ...   \n",
       "6                                                 NaN  ...   \n",
       "8     Advances in Knowledge Discovery and Data Mining  ...   \n",
       "10                                  Discovery Science  ...   \n",
       "11                            Artificial Intelligence  ...   \n",
       "12  Proceedings of the AAAI Conference on Artifici...  ...   \n",
       "13  Machine Learning and Knowledge Discovery in Da...  ...   \n",
       "15  Machine Learning and Knowledge Discovery in Da...  ...   \n",
       "22                            Artificial Intelligence  ...   \n",
       "25                                  Discovery Science  ...   \n",
       "26                                    Arxive preprint  ...   \n",
       "27                                                NaN  ...   \n",
       "28  2021 IEEE Symposium on Computers and Communica...  ...   \n",
       "29  Proceedings of the 2021 AAAI/ACM Conference on...  ...   \n",
       "30  Machine Learning and Knowledge Discovery in Da...  ...   \n",
       "31               Frontiers in Artificial Intelligence  ...   \n",
       "33                              ACM Computing Surveys  ...   \n",
       "34  2020 IEEE Second International Conference on C...  ...   \n",
       "35  Explainable AI Within the Digital Transformati...  ...   \n",
       "37  Third Conference on Cognitive Machine Intellig...  ...   \n",
       "38                                                NaN  ...   \n",
       "40                                                NaN  ...   \n",
       "41  Third Conference on Cognitive Machine Intellig...  ...   \n",
       "43  Conference on AI, Ethics, and Society (AIES 2022)  ...   \n",
       "\n",
       "   Is/will open access provided to this publication Research line  \\\n",
       "0                                               NaN             1   \n",
       "1                                               NaN             1   \n",
       "2                                               NaN         1,2,3   \n",
       "4                                               NaN             1   \n",
       "5                                               NaN             1   \n",
       "6                                               NaN             1   \n",
       "8                                               NaN             1   \n",
       "10                                              NaN             1   \n",
       "11                                              NaN             1   \n",
       "12                                              NaN             1   \n",
       "13                                               NO           1,4   \n",
       "15                                               NO             1   \n",
       "22                                       YES - Gold           1,4   \n",
       "25                                              NaN           1,2   \n",
       "26                                              NaN           1,4   \n",
       "27                                              NaN             1   \n",
       "28                                              NaN             1   \n",
       "29                                              NaN             1   \n",
       "30                                              NaN             1   \n",
       "31                                              NaN             1   \n",
       "33                                              NaN           1,3   \n",
       "34                                              NaN             1   \n",
       "35                                              NaN           1,5   \n",
       "37                                              NaN             1   \n",
       "38                                              NaN             1   \n",
       "40                                              YES           1,4   \n",
       "41                                              YES           1,5   \n",
       "43                                              NaN           1,5   \n",
       "\n",
       "   List of dataset used in the paper                    Issue  \\\n",
       "0                                NaN                  Pre-XAI   \n",
       "1                                NaN                  Pre-XAI   \n",
       "2                                NaN                   no ack   \n",
       "4                                NaN                   no ack   \n",
       "5                                NaN                      NaN   \n",
       "6                                NaN                      NaN   \n",
       "8                                NaN  No ack / No open access   \n",
       "10                               NaN                   no ack   \n",
       "11                               NaN                   no ack   \n",
       "12                               NaN     before 2019 / no ack   \n",
       "13                               NaN                   no ack   \n",
       "15                               NaN  No open access / No ack   \n",
       "22                               NaN                      NaN   \n",
       "25                               NaN           no open access   \n",
       "26                               NaN  submitted not published   \n",
       "27                               NaN                   no ack   \n",
       "28                               NaN                   no ack   \n",
       "29                               NaN                   no ack   \n",
       "30                               NaN              before 2019   \n",
       "31                               NaN                   no ack   \n",
       "33                               NaN      before 2019, no ack   \n",
       "34                               NaN                      NaN   \n",
       "35                               NaN           No open access   \n",
       "37                               NaN                      NaN   \n",
       "38                               NaN   no doi / only in arxiv   \n",
       "40                               NaN  submitted not published   \n",
       "41                               NaN                      NaN   \n",
       "43                               NaN           No open access   \n",
       "\n",
       "   visible on website     _merge  summary image image size  \\\n",
       "0                 YES  left_only             NO        NaN   \n",
       "1                 YES  left_only             NO        NaN   \n",
       "2                 YES       both             NO        NaN   \n",
       "4                 YES       both             NO        NaN   \n",
       "5                 YES       both             NO        NaN   \n",
       "6                 YES       both             NO        NaN   \n",
       "8                 YES       both             NO        NaN   \n",
       "10                YES       both             NO        NaN   \n",
       "11                YES       both             NO        NaN   \n",
       "12                YES       both             NO        NaN   \n",
       "13                YES       both             NO        NaN   \n",
       "15                YES       both             NO        NaN   \n",
       "22                YES       both            YES        big   \n",
       "25                YES  left_only             NO        NaN   \n",
       "26                 NO  left_only             NO        NaN   \n",
       "27                YES  left_only             NO        NaN   \n",
       "28                YES  left_only             NO        NaN   \n",
       "29                YES  left_only             NO        NaN   \n",
       "30                YES       both             NO        NaN   \n",
       "31                YES  left_only             NO        NaN   \n",
       "33                YES       both             NO        NaN   \n",
       "34                YES        NaN            YES        big   \n",
       "35                YES        NaN            YES        NaN   \n",
       "37                YES        NaN             NO        NaN   \n",
       "38                YES        NaN             NO        NaN   \n",
       "40                 NO        NaN             NO        NaN   \n",
       "41                YES        NaN             NO        NaN   \n",
       "43                YES        NaN             NO        NaN   \n",
       "\n",
       "                       image file featured  \n",
       "0                             NaN        1  \n",
       "1                             NaN        0  \n",
       "2                             NaN        0  \n",
       "4                             NaN        0  \n",
       "5                             NaN        0  \n",
       "6                             NaN        0  \n",
       "8                             NaN        0  \n",
       "10                            NaN        0  \n",
       "11                            NaN        0  \n",
       "12                            NaN        0  \n",
       "13                            NaN        0  \n",
       "15                            NaN        0  \n",
       "22                 02_glocalX.jpg        1  \n",
       "25                            NaN        0  \n",
       "26                            NaN        0  \n",
       "27                            NaN        0  \n",
       "28                            NaN        0  \n",
       "29                            NaN        0  \n",
       "30                            NaN        0  \n",
       "31                            NaN        0  \n",
       "33               01_survey_bb.jpg        1  \n",
       "34  ex_time_series_calssifier.png        0  \n",
       "35      springer_book_explain.jpg        0  \n",
       "37                            NaN        0  \n",
       "38                            NaN        0  \n",
       "40                            NaN        0  \n",
       "41                            NaN        0  \n",
       "43                            NaN        0  \n",
       "\n",
       "[28 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[papers['Research line'].str.contains('1', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization order of the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers=papers.sort_values(by=['featured','Year of publication'], ascending = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul><li><strong><a href='https://doi.org/10.1145/3236009' target='_blank'>A Survey of Methods for Explaining Black Box Models</a></strong> - 2022 - Guidotti Riccardo, Monreale Anna, Ruggieri Salvatore, Turini Franco, Giannotti Fosca, Pedreschi Dino , ACM computing surveys (CSUR), 51(5), 1-42..</li><li><strong><a href='https://doi.org/10.1016/j.artint.2021.103457' target='_blank'>GLocalX - From Local to Global Explanations of Black Box AI Models</a></strong> - 2021 - Setzu Mattia, Guidotti Riccardo, Monreale Anna, Turini Franco, Pedreschi Dino, Giannotti Fosca , Artificial Intelligence.</li><li><strong><a href='https://doi.org/10.1109/MIS.2019.2957223' target='_blank'>Factual and Counterfactual Explanations for Black Box Decision Making</a></strong> - 2021 - Guidotti Riccardo, Monreale Anna, Giannotti Fosca, Pedreschi Dino, Ruggieri Salvatore, Turini Franco , IEEE Intelligent Systems.</li><li><strong><a href='https://doi.org/1805.10820' target='_blank'>Local Rule-Based Explanations of Black Box Decision Systems</a></strong> - 2018 - Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi, Franco Turini, Fosca Giannotti .</li><li><strong><a href='https://doi.org/10.1142/q0322' target='_blank'>Ethical, societal and legal issues in deep learning for healthcare</a></strong> - 2022 - Panigutti Cecilia, Monreale Anna, Comandè Giovanni, Pedreschi Dino , Deep Learning in Biology and Medicine.</li><li><strong><a href='https://doi.org/10.1007/978-3-030-69128-8_2' target='_blank'>Trustworthy AI</a></strong> - 2022 - Chatila Raja, Dignum Virginia, Fisher Michael, Giannotti Fosca, Morik Katharina, Russell Stuart, Yeung Karen , Lecture Notes in Computer Science,.</li><li><strong><a href='https://doi.org/10.1140/epjds/s13688-022-00315-z' target='_blank'>Understanding peace through the world news</a></strong> - 2022 - Voukelatou Vasiliki, Miliou Ioanna, Giannotti Fosca, Pappalardo Luca , EPJ Data Science.</li><li><strong><a href='https://doi.org/10.1109/CogMI52975.2021.00015' target='_blank'>TriplEx: Triple Extraction for Explanation</a></strong> - 2022 - Mattia Setzu, Anna Monreale, Pasquale Minervini .</li><li><strong><a href='https://doi.org/10.1145/3491102.3502104' target='_blank'>Understanding the impact of explanations on advice-taking: a user study for AI-based clinical Decision Support Systems</a></strong> - 2022 - Cecilia Panigutti, Andrea Beretta, Dino Pedreschi, Fosca Giannotti , Proceedings of the 2022 Conference on Human Factors in Computing Systems.</li><li><strong><a href='https://doi.org/nan' target='_blank'>Explaining Black Box with visual exploration of Latent Space</a></strong> - 2022 - Francesco Bodria, Salvatore Rinzivillo, Daniele Fadda, Riccardo Guidotti, Fosca Giannotti, Dino Pedreschi .</li><li><strong><a href='https://doi.org/10.1145/3514094.3534170' target='_blank'>Investigating Debiasing Effects on Classification and Explainability</a></strong> - 2022 - Marta Marchiori Manerba, Riccardo Guidotti , Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES'22).</li><li><strong><a href='https://doi.org/10.1007/978-3-030-16148-4_5' target='_blank'>Investigating Neighborhood Generation Methods for Explanations of Obscure Image Classifiers</a></strong> - 2021 - Guidotti Riccardo, Monreale Anna, Cariaggi Leonardo , In Pacific-Asia Conference on Knowledge Discovery and Data Mining (pp. 55-68). Springer, Cham..</li><li><strong><a href='https://doi.org/10.1007/978-3-030-24409-5_9' target='_blank'>Explaining Multi-label Black-Box Classifiers for Health Applications</a></strong> - 2021 - Panigutti Cecilia, Guidotti Riccardo, Monreale Anna, Pedreschi Dino , International Workshop on Health Intelligence (pp. 97-110). Springer, Cham..</li><li><strong><a href='https://doi.org/10.1007/978-3-030-61527-7_24' target='_blank'>Explaining Sentiment Classification with Synthetic Exemplars and Counter-Exemplars</a></strong> - 2021 - Lampridis Orestis, Guidotti Riccardo, Ruggieri Salvatore , In International Conference on Discovery Science (pp. 357-373). Springer, Cham..</li><li><strong><a href='https://doi.org/10.1016/j.artint.2020.103428' target='_blank'>Evaluating local explanation methods on ground truth</a></strong> - 2021 - Riccardo Guidotti , Artificial Intelligence, 103428.</li><li><strong><a href='https://doi.org/10.1609/aaai.v33i01.33019780' target='_blank'>Meaningful Explanations of Black Box AI Decision Systems</a></strong> - 2021 - Pedreschi Dino, Giannotti Fosca, Guidotti Riccardo, Monreale Anna, Ruggieri Salvatore, Turini Franco , Proceedings of the AAAI Conference on Artificial Intelligence.</li><li><strong><a href='https://doi.org/10.1007/978-3-030-46150-8_12' target='_blank'>Black Box Explanation by Learning Image Exemplars in the Latent Feature Space</a></strong> - 2021 - Guidotti Riccardo, Monreale Anna, Matwin Stan, Pedreschi Dino , Black Box Explanation by Learning Image Exemplars in the Latent Feature Space..</li><li><strong><a href='https://doi.org/10.1609/aaai.v34i09.7116' target='_blank'>Explaining Image Classifiers Generating Exemplars and Counter-Exemplars from Latent Representations</a></strong> - 2021 - Guidotti Riccardo, Monreale Anna, Matwin Stan, Pedreschi Dino .</li><li><strong><a href='https://doi.org/10.1007/978-3-030-43823-4_14' target='_blank'>Global Explanations with Local Scoring</a></strong> - 2021 - Setzu Mattia, Guidotti Riccardo, Monreale Anna, Turini Franco , ECML PKDD 2019: Machine Learning and Knowledge Discovery in Databases.</li><li><strong><a href='https://doi.org/10.1007/978-3-030-61527-7_27' target='_blank'>Predicting and Explaining Privacy Risk Exposure in Mobility Data</a></strong> - 2021 - Naretto Francesca, Pellungrini Roberto, Monreale Anna, Nardini Franco Maria, Musolesi Mirco , Discovery Science Conference.</li><li><strong><a href='https://doi.org/10.1007/978-3-030-65965-3_34' target='_blank'>Prediction and Explanation of Privacy Risk on Mobility Data with Neural Networks</a></strong> - 2021 - Naretto Francesca, Pellungrini Roberto, Nardini Franco Maria, Giannotti Fosca , ECML PKDD 2020 Workshops.</li><li><strong><a href='https://doi.org/10.1016/j.ipm.2021.102657' target='_blank'>FairLens: Auditing black-box clinical decision support systems</a></strong> - 2021 - Panigutti Cecilia, Perotti Alan, Panisson André, Bajardi Paolo, Pedreschi Dino , Journal of Information Processing and Management.</li><li><strong><a href='https://doi.org/10.30682/ildia2101f' target='_blank'>Intelligenza artificiale in ambito diabetologico: prospettive, dalla ricerca di base alle applicazioni cliniche</a></strong> - 2021 - Panigutti Cecilia, Bosi Emanuele , Il Diabete.</li><li><strong><a href='https://doi.org/10.3390/e23081064' target='_blank'>Occlusion-Based Explanations in Deep Recurrent Models for Biomedical Signals</a></strong> - 2021 - Resta Michele, Monreale Anna, Bacciu Davide , Entropy.</li><li><strong><a href='https://doi.org/10.1007/978-3-030-88942-5_27' target='_blank'>Deriving a Single Interpretable Model by Merging Tree-Based Classifiers</a></strong> - 2021 - Bonsignori Valerio, Guidotti Riccardo, Monreale Anna .</li><li><strong><a href='https://doi.org/nan' target='_blank'>Ensemble of Counterfactual Explainers</a></strong> - 2021 - Riccardo Guidotti, Ruggieri Salvatore .</li><li><strong><a href='https://doi.org/10.1109/ISCC53001.2021.9631485' target='_blank'>Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling</a></strong> - 2021 - Metta Carlo, Guidotti Riccardo, Yin Yuan, Gallinari Patrick, Rinzivillo Salvatore , 2021 IEEE Symposium on Computers and Communications (ISCC).</li><li><strong><a href='https://doi.org/10.1145/3461702.3462553' target='_blank'>Designing Shapelets for Interpretable Data-Agnostic Classification</a></strong> - 2021 - Guidotti Riccardo, Monreale Anna .</li><li><strong><a href='https://doi.org/10.1007/978-3-030-10997-4_13' target='_blank'>Helping Your Docker Images to Spread Based on Explainable Models</a></strong> - 2021 - Guidotti Riccardo, Soldani Jacopo, Neri Davide, Brogi Antonio, Pedreschi Dino , In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 205-221). Springer, Cham..</li><li><strong><a href='https://doi.org/10.3389/frai.2021.699448' target='_blank'>Matrix Profile-Based Interpretable Time Series Classifier</a></strong> - 2021 - Guidotti Riccardo, D’Onofrio Matteo .</li><li><strong><a href='https://doi.org/10.1007/978-3-030-76409-8' target='_blank'>Explainable AI Within the Digital Transformation and Cyber Physical Systems: XAI Methods and Applications</a></strong> - 2021 - Guidotti Riccardo, Monreale Anna, Pedreschi Dino, Giannotti Fosca .</li><li><strong><a href='https://doi.org/nan' target='_blank'>Benchmarking and survey of explanation methods for black box models</a></strong> - 2021 - Francesco Bodria, Fosca Giannotti, Riccardo Guidotti, Francesca Naretto, Dino Pedreschi, Salvatore Rinzivillo .</li><li><strong><a href='https://doi.org/10.1109/CogMI52975.2021.00014' target='_blank'>FairShades: Fairness Auditing via Explainability in Abusive Language Detection Systems</a></strong> - 2021 - Marta Marchiori Manerba, Riccardo Guidotti , 2021 IEEE Third International Conference on Cognitive Machine Intelligence (CogMI).</li><li><strong><a href='https://doi.org/nan' target='_blank'>Rischi etico-legali dell’Intelligenza Artificiale</a></strong> - 2020 - Anna Monreale , DPCE Online, [S.l.], v. 44, n. 3, oct. 2020. ISSN 2037-6677.</li><li><strong><a href='https://doi.org/nan' target='_blank'>Explainability Methods for Natural Language Processing: Applications to Sentiment Analysis</a></strong> - 2020 - Francesco Bodria , André Panisson , Alan Perotti , Simone Piaggesi .</li><li><strong><a href='https://doi.org/10.1109/ICDM50108.2020.00122' target='_blank'>Data-Agnostic Local Neighborhood Generation</a></strong> - 2020 - Riccardo Guidotti, Anna Monreale , 2020 IEEE International Conference on Data Mining (ICDM).</li><li><strong><a href='https://doi.org/nan' target='_blank'>Opening the black box: a primer for anti-discrimination</a></strong> - 2020 - Ruggieri Salvatore, Giannotti Fosca, Guidotti Riccardo; Monreale Anna, Pedreschi Dino, Turini Franco , ANNUARIO DI DIRITTO COMPARATO E DI STUDI LEGISLATIVI.</li><li><strong><a href='https://doi.org/10.1145/3351095.3372855' target='_blank'>Doctor XAI: an ontology-based approach to black-box sequential data classification explanations</a></strong> - 2020 - Panigutti Cecilia, Perrotti Alan, Pedreschi Dino , FAT* '20: Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency.</li><li><strong><a href='https://doi.org/10.1109/CogMI50398.2020.00029' target='_blank'>Explaining Any Time Series Classifier</a></strong> - 2020 - Guidotti Riccardo, Monreale Anna, Spinnato Francesco, Pedreschi Dino, Giannotti Fosca .</li><li><strong><a href='https://doi.org/nan' target='_blank'>The AI black box explanation problem</a></strong> - 2019 - Guidotti Riccardo, Monreale Anna, Pedreschi Dino , ERCIM News, 116, 12-13.</li><li><strong><a href='https://doi.org/nan' target='_blank'>I.A. comprensibile per il supporto alle decisioni: doctor XAI</a></strong> - 2019 - Giannotti Fosca, Pedreschi Dino, Panigutti Cecilia , BIOPOLITICA, PANDEMIA E DEMOCRAZIA Rule of law nella società digitale.</li><li><strong><a href='https://doi.org/1806.09936' target='_blank'>Open the Black Box Data-Driven Explanation of Black Box Decision Systems</a></strong> - 2018 - Dino Pedreschi, Fosca Giannotti, Riccardo Guidotti, Anna Monreale, Luca Pappalardo, Salvatore Ruggieri, Franco Turini .</li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bullets='<ul>'\n",
    "for i, row in papers.iterrows():\n",
    "    authors= row['Authors']\n",
    "#     pubblicationYear = int(row['Year of publication'])\n",
    "    pubYearString = row['Year of publication']\n",
    "    pubblicationYear =  '.' if pubYearString!=pubYearString else ' - '+str(int(pubYearString))+' -'\n",
    "    title=row['Title of the scientific publication'].strip('.')\n",
    "    \n",
    "    journalString=row['Title of the journal or equivalent']\n",
    "    journal='.' if journalString!=journalString else ', '+journalString.strip()+'.'\n",
    "    DOI=row['DOI']\n",
    "    \n",
    "    bullet=f\"<li><strong><a href='https://doi.org/{DOI}' target='_blank'>{title}</a></strong>{pubblicationYear} {authors} {journal}</li>\"\n",
    "    if row['visible on website'] == 'YES':\n",
    "        bullets+=bullet\n",
    "bullets+='</ul>'\n",
    "display(HTML(bullets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOI TO BibTex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@incollection{Guidotti_2019,\n",
      "\tdoi = {10.1007/978-3-030-10997-4_13},\n",
      "\turl = {https://doi.org/10.1007%2F978-3-030-10997-4_13},\n",
      "\tyear = 2019,\n",
      "\tpublisher = {Springer International Publishing},\n",
      "\tpages = {205--221},\n",
      "\tauthor = {Riccardo Guidotti and Jacopo Soldani and Davide Neri and Antonio Brogi and Dino Pedreschi},\n",
      "\ttitle = {Helping Your Docker Images to Spread Based on Explainable Models},\n",
      "\tbooktitle = {Machine Learning and Knowledge Discovery in Databases}\n",
      "}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "doi='10.1007/978-3-030-10997-4_13'\n",
    "BASE_URL = 'http://dx.doi.org/'\n",
    "url = BASE_URL + doi\n",
    "req = urllib.request.Request(url)\n",
    "req.add_header('Accept', 'application/x-bibtex')\n",
    "try:\n",
    "    with urllib.request.urlopen(req) as f:\n",
    "        bibtex = f.read().decode()\n",
    "    print(bibtex)\n",
    "except HTTPError as e:\n",
    "    if e.code == 404:\n",
    "        print('DOI not found.')\n",
    "    else:\n",
    "        print('Service unavailable.')\n",
    "    sys.exit(1)\n",
    "\n",
    "print(type(bibtex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bullets=''\n",
    "for i, row in papers.iterrows():\n",
    "    authors= row['Authors']\n",
    "#     pubblicationYear = int(row['Year of publication'])\n",
    "    pubYearString = row['Year of publication']\n",
    "    pubblicationYear =  '.' if pubYearString!=pubYearString else str(int(pubYearString))\n",
    "    \n",
    "    title=row['Title of the scientific publication'].strip('.')\n",
    "    \n",
    "    journalString=row['Title of the journal or equivalent']\n",
    "    journal='.' if journalString!=journalString else ', '+journalString.strip()+'.'\n",
    "    DOI=row['DOI']\n",
    "    \n",
    "    bullet=f'''li\n",
    "    div.mb-3\n",
    "        a(href='https://doi.org/{DOI}', target=\"_blank\")\n",
    "            | {authors} ({pubblicationYear}). #[strong {title}]\n",
    "'''\n",
    "    if row['visible on website'] == 'YES':\n",
    "        bullets+=bullet\n",
    "# display(HTML(bullets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1145/3236009', target=\"_blank\")\n",
       "            | Guidotti Riccardo, Monreale Anna, Ruggieri Salvatore, Turini Franco, Giannotti Fosca, Pedreschi Dino (2022). #[strong A Survey of Methods for Explaining Black Box Models]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1016/j.artint.2021.103457', target=\"_blank\")\n",
       "            | Setzu Mattia, Guidotti Riccardo, Monreale Anna, Turini Franco, Pedreschi Dino, Giannotti Fosca (2021). #[strong GLocalX - From Local to Global Explanations of Black Box AI Models]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1109/MIS.2019.2957223', target=\"_blank\")\n",
       "            | Guidotti Riccardo, Monreale Anna, Giannotti Fosca, Pedreschi Dino, Ruggieri Salvatore, Turini Franco (2021). #[strong Factual and Counterfactual Explanations for Black Box Decision Making]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/1805.10820', target=\"_blank\")\n",
       "            | Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi, Franco Turini, Fosca Giannotti (2018). #[strong Local Rule-Based Explanations of Black Box Decision Systems]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1142/q0322', target=\"_blank\")\n",
       "            | Panigutti Cecilia, Monreale Anna, Comandè Giovanni, Pedreschi Dino (2022). #[strong Ethical, societal and legal issues in deep learning for healthcare]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-69128-8_2', target=\"_blank\")\n",
       "            | Chatila Raja, Dignum Virginia, Fisher Michael, Giannotti Fosca, Morik Katharina, Russell Stuart, Yeung Karen (2022). #[strong Trustworthy AI]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1140/epjds/s13688-022-00315-z', target=\"_blank\")\n",
       "            | Voukelatou Vasiliki, Miliou Ioanna, Giannotti Fosca, Pappalardo Luca (2022). #[strong Understanding peace through the world news]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1109/CogMI52975.2021.00015', target=\"_blank\")\n",
       "            | Mattia Setzu, Anna Monreale, Pasquale Minervini (2022). #[strong TriplEx: Triple Extraction for Explanation]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1145/3491102.3502104', target=\"_blank\")\n",
       "            | Cecilia Panigutti, Andrea Beretta, Dino Pedreschi, Fosca Giannotti (2022). #[strong Understanding the impact of explanations on advice-taking: a user study for AI-based clinical Decision Support Systems]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/nan', target=\"_blank\")\n",
       "            | Francesco Bodria, Salvatore Rinzivillo, Daniele Fadda, Riccardo Guidotti, Fosca Giannotti, Dino Pedreschi (2022). #[strong Explaining Black Box with visual exploration of Latent Space]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1145/3514094.3534170', target=\"_blank\")\n",
       "            | Marta Marchiori Manerba, Riccardo Guidotti (2022). #[strong Investigating Debiasing Effects on Classification and Explainability]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-16148-4_5', target=\"_blank\")\n",
       "            | Guidotti Riccardo, Monreale Anna, Cariaggi Leonardo (2021). #[strong Investigating Neighborhood Generation Methods for Explanations of Obscure Image Classifiers]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-24409-5_9', target=\"_blank\")\n",
       "            | Panigutti Cecilia, Guidotti Riccardo, Monreale Anna, Pedreschi Dino (2021). #[strong Explaining Multi-label Black-Box Classifiers for Health Applications]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-61527-7_24', target=\"_blank\")\n",
       "            | Lampridis Orestis, Guidotti Riccardo, Ruggieri Salvatore (2021). #[strong Explaining Sentiment Classification with Synthetic Exemplars and Counter-Exemplars]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1016/j.artint.2020.103428', target=\"_blank\")\n",
       "            | Riccardo Guidotti (2021). #[strong Evaluating local explanation methods on ground truth]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1609/aaai.v33i01.33019780', target=\"_blank\")\n",
       "            | Pedreschi Dino, Giannotti Fosca, Guidotti Riccardo, Monreale Anna, Ruggieri Salvatore, Turini Franco (2021). #[strong Meaningful Explanations of Black Box AI Decision Systems]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-46150-8_12', target=\"_blank\")\n",
       "            | Guidotti Riccardo, Monreale Anna, Matwin Stan, Pedreschi Dino (2021). #[strong Black Box Explanation by Learning Image Exemplars in the Latent Feature Space]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1609/aaai.v34i09.7116', target=\"_blank\")\n",
       "            | Guidotti Riccardo, Monreale Anna, Matwin Stan, Pedreschi Dino (2021). #[strong Explaining Image Classifiers Generating Exemplars and Counter-Exemplars from Latent Representations]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-43823-4_14', target=\"_blank\")\n",
       "            | Setzu Mattia, Guidotti Riccardo, Monreale Anna, Turini Franco (2021). #[strong Global Explanations with Local Scoring]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-61527-7_27', target=\"_blank\")\n",
       "            | Naretto Francesca, Pellungrini Roberto, Monreale Anna, Nardini Franco Maria, Musolesi Mirco (2021). #[strong Predicting and Explaining Privacy Risk Exposure in Mobility Data]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-65965-3_34', target=\"_blank\")\n",
       "            | Naretto Francesca, Pellungrini Roberto, Nardini Franco Maria, Giannotti Fosca (2021). #[strong Prediction and Explanation of Privacy Risk on Mobility Data with Neural Networks]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1016/j.ipm.2021.102657', target=\"_blank\")\n",
       "            | Panigutti Cecilia, Perotti Alan, Panisson André, Bajardi Paolo, Pedreschi Dino (2021). #[strong FairLens: Auditing black-box clinical decision support systems]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.30682/ildia2101f', target=\"_blank\")\n",
       "            | Panigutti Cecilia, Bosi Emanuele (2021). #[strong Intelligenza artificiale in ambito diabetologico: prospettive, dalla ricerca di base alle applicazioni cliniche]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.3390/e23081064', target=\"_blank\")\n",
       "            | Resta Michele, Monreale Anna, Bacciu Davide (2021). #[strong Occlusion-Based Explanations in Deep Recurrent Models for Biomedical Signals]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-88942-5_27', target=\"_blank\")\n",
       "            | Bonsignori Valerio, Guidotti Riccardo, Monreale Anna (2021). #[strong Deriving a Single Interpretable Model by Merging Tree-Based Classifiers]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/nan', target=\"_blank\")\n",
       "            | Riccardo Guidotti, Ruggieri Salvatore (2021). #[strong Ensemble of Counterfactual Explainers]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1109/ISCC53001.2021.9631485', target=\"_blank\")\n",
       "            | Metta Carlo, Guidotti Riccardo, Yin Yuan, Gallinari Patrick, Rinzivillo Salvatore (2021). #[strong Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1145/3461702.3462553', target=\"_blank\")\n",
       "            | Guidotti Riccardo, Monreale Anna (2021). #[strong Designing Shapelets for Interpretable Data-Agnostic Classification]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-10997-4_13', target=\"_blank\")\n",
       "            | Guidotti Riccardo, Soldani Jacopo, Neri Davide, Brogi Antonio, Pedreschi Dino (2021). #[strong Helping Your Docker Images to Spread Based on Explainable Models]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.3389/frai.2021.699448', target=\"_blank\")\n",
       "            | Guidotti Riccardo, D’Onofrio Matteo (2021). #[strong Matrix Profile-Based Interpretable Time Series Classifier]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1007/978-3-030-76409-8', target=\"_blank\")\n",
       "            | Guidotti Riccardo, Monreale Anna, Pedreschi Dino, Giannotti Fosca (2021). #[strong Explainable AI Within the Digital Transformation and Cyber Physical Systems: XAI Methods and Applications]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/nan', target=\"_blank\")\n",
       "            | Francesco Bodria, Fosca Giannotti, Riccardo Guidotti, Francesca Naretto, Dino Pedreschi, Salvatore Rinzivillo (2021). #[strong Benchmarking and survey of explanation methods for black box models]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1109/CogMI52975.2021.00014', target=\"_blank\")\n",
       "            | Marta Marchiori Manerba, Riccardo Guidotti (2021). #[strong FairShades: Fairness Auditing via Explainability in Abusive Language Detection Systems]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/nan', target=\"_blank\")\n",
       "            | Anna Monreale (2020). #[strong Rischi etico-legali dell’Intelligenza Artificiale]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/nan', target=\"_blank\")\n",
       "            | Francesco Bodria , André Panisson , Alan Perotti , Simone Piaggesi (2020). #[strong Explainability Methods for Natural Language Processing: Applications to Sentiment Analysis]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1109/ICDM50108.2020.00122', target=\"_blank\")\n",
       "            | Riccardo Guidotti, Anna Monreale (2020). #[strong Data-Agnostic Local Neighborhood Generation]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/nan', target=\"_blank\")\n",
       "            | Ruggieri Salvatore, Giannotti Fosca, Guidotti Riccardo; Monreale Anna, Pedreschi Dino, Turini Franco (2020). #[strong Opening the black box: a primer for anti-discrimination]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1145/3351095.3372855', target=\"_blank\")\n",
       "            | Panigutti Cecilia, Perrotti Alan, Pedreschi Dino (2020). #[strong Doctor XAI: an ontology-based approach to black-box sequential data classification explanations]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/10.1109/CogMI50398.2020.00029', target=\"_blank\")\n",
       "            | Guidotti Riccardo, Monreale Anna, Spinnato Francesco, Pedreschi Dino, Giannotti Fosca (2020). #[strong Explaining Any Time Series Classifier]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/nan', target=\"_blank\")\n",
       "            | Guidotti Riccardo, Monreale Anna, Pedreschi Dino (2019). #[strong The AI black box explanation problem]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/nan', target=\"_blank\")\n",
       "            | Giannotti Fosca, Pedreschi Dino, Panigutti Cecilia (2019). #[strong I.A. comprensibile per il supporto alle decisioni: doctor XAI]\n",
       "li\n",
       "    div.mb-3\n",
       "        a(href='https://doi.org/1806.09936', target=\"_blank\")\n",
       "            | Dino Pedreschi, Fosca Giannotti, Riccardo Guidotti, Anna Monreale, Luca Pappalardo, Salvatore Ruggieri, Franco Turini (2018). #[strong Open the Black Box Data-Driven Explanation of Black Box Decision Systems]\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(bullets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_html(bullets, filename='paper-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cards=''\n",
    "for i, row in papers.iterrows():\n",
    "    authors= row['Authors']\n",
    "    abstract= row['abstract']\n",
    "    researchLine= row['Research line']\n",
    "    idAlpha = row['Id di Riccardo']\n",
    "    \n",
    "    if isinstance(researchLine, str):\n",
    "        researchLine=researchLine.replace(\",\", \"▪\")\n",
    "        rlString=f'''p.my-1\n",
    "                small Research Line #[strong {researchLine}]'''\n",
    "    else:\n",
    "        rlString=''\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    pubYearString = row['Year of publication']\n",
    "    pubblicationYear =  '.' if pubYearString!=pubYearString else str(int(pubYearString))\n",
    "    \n",
    "    title=row['Title of the scientific publication'].strip('.')\n",
    "    \n",
    "    container=row['container']\n",
    "    if not isinstance(container, str):\n",
    "        container=''\n",
    "    else:\n",
    "        container=f' - {container}'\n",
    "    \n",
    "#     journalString=row['Title of the journal or equivalent']\n",
    "#     journal='.' if journalString!=journalString else ', '+journalString.strip()+'.'\n",
    "    journal=row['Title of the journal or equivalent']\n",
    "    if not isinstance(journal, str):\n",
    "        journal=''\n",
    "    else:\n",
    "        journal=f'. In {journal}'\n",
    "        \n",
    "    DOI=row['DOI']\n",
    "    doiLink=row['doi link']\n",
    "    image= row['image file']\n",
    "    \n",
    "    if isinstance(DOI, str):\n",
    "        #Doi to bibtex\n",
    "        BASE_URL = 'http://dx.doi.org/'\n",
    "        url = BASE_URL + DOI\n",
    "        req = urllib.request.Request(url)\n",
    "        req.add_header('Accept', 'application/x-bibtex')\n",
    "        try:\n",
    "            with urllib.request.urlopen(req) as f:\n",
    "                bibtex = f.read().decode()\n",
    "                bibtex=bibtex.replace('\\t','                    ')\n",
    "                bibtex=bibtex[:-1] + \"                }\"\n",
    "#             print(bibtex)\n",
    "        except HTTPError as e:\n",
    "            if e.code == 404:\n",
    "                bibtex='BibTex not found'\n",
    "            else:\n",
    "                bibtex='BibTex not found.'# Service unavaillable\n",
    "#             sys.exit(1)\n",
    "    else:\n",
    "        bibtex='BibTex not found'\n",
    "    \n",
    "    #ADD BUTTONS IF:    \n",
    "        #More information\n",
    "    if (isinstance(abstract, str) or (bibtex not in['BibTex not found','BibTex not found.']) ):\n",
    "        if not (isinstance(abstract, str)):\n",
    "            abstract= 'ABSTRACT NOT FOUND'\n",
    "        \n",
    "        abstractButton= f'''p.my-1\n",
    "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-{p.number_to_words(i)}' aria-expanded='true' aria-controls='collapseAbs') More information'''\n",
    "    else:\n",
    "        abstractButton=''\n",
    "        \n",
    "        #External link\n",
    "    if (isinstance(doiLink, str)):\n",
    "        externalButton= f'''p.my-1\n",
    "            a.btn-mini.px-2.btn-secondary.small(href='{doiLink}', target=\"_blank\") External Link'''\n",
    "    else:\n",
    "        externalButton= ''\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ptOne=f'''#{idAlpha}.row.mt-4.justify-content-center\n",
    "    .col-lg-1.text-right\n",
    "        h4 {i+1}.\n",
    "        p [{idAlpha}]'''\n",
    "    # summary image?\n",
    "    if row['summary image']=='YES':\n",
    "        ptTwo=f'''\n",
    "    .col-lg-2.pl-0\n",
    "        img(src='assets/images/publication/{image} ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-{p.number_to_words(i)}' type='button').mr-3\n",
    "        #modal-{p.number_to_words(i)}.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-{p.number_to_words(i)}-Title' aria-hidden='true')\n",
    "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
    "                .modal-content\n",
    "                    .modal-header\n",
    "                        p.small {title}\n",
    "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
    "                            span(aria-hidden='true') &times;\n",
    "                    .modal-body\n",
    "                        img(src='assets/images/publication/{image} ' alt=\"immagine\" )\n",
    "    .col-lg-6.bg-yellow.p-3'''\n",
    "    else:\n",
    "        ptTwo=f'''\n",
    "    .col-lg-8.bg-yellow.p-3'''\n",
    "\n",
    "    ptThree=f'''\n",
    "        #accordion-{p.number_to_words(i)}.accordion\n",
    "        | #[strong {title}] \n",
    "        br\n",
    "        | #[em {authors}] ({pubblicationYear}){container}{journal}\n",
    "        #collapse-{p.number_to_words(i)}.collapse(aria-labelledby='heading-{p.number_to_words(i)}' data-parent='#accordion-{p.number_to_words(i)}')\n",
    "            div.bg-yellow\n",
    "                hr\n",
    "                p.small #[strong Abstract]\n",
    "                p.small {abstract}\n",
    "            p.small.pt-2 #[strong BibTex]\n",
    "            p.small.\n",
    "                {bibtex}\n",
    "    .col-lg-2.pl-3\n",
    "        {abstractButton}\n",
    "        {externalButton}\n",
    "        {rlString}\n",
    "'''\n",
    "    \n",
    "    card= ptOne+ptTwo+ptThree\n",
    "    if row['visible on website'] == 'YES':\n",
    "        cards+=card\n",
    "    \n",
    "# display(HTML(bullets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 1.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-zero.accordion\n",
       "        | #[strong A Survey of Methods for Explaining Black Box Models] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, Monreale Anna, Ruggieri Salvatore, Turini Franco, Giannotti Fosca, Pedreschi Dino] (2022) - ACM Computing Surveys. In ACM computing surveys (CSUR), 51(5), 1-42.\n",
       "        #collapse-zero.collapse(aria-labelledby='heading-zero' data-parent='#accordion-zero')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{Guidotti_2019,\n",
       "                    doi = {10.1145/3236009},\n",
       "                    url = {https://doi.org/10.1145%2F3236009},\n",
       "                    year = 2019,\n",
       "                    month = {sep},\n",
       "                    publisher = {Association for Computing Machinery ({ACM})},\n",
       "                    volume = {51},\n",
       "                    number = {5},\n",
       "                    pages = {1--42},\n",
       "                    author = {Riccardo Guidotti and Anna Monreale and Salvatore Ruggieri and Franco Turini and Fosca Giannotti and Dino Pedreschi},\n",
       "                    title = {A Survey of Methods for Explaining Black Box Models},\n",
       "                    journal = {{ACM} Computing Surveys}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-zero' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1145/3236009', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1▪3]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 2.\n",
       "    .col-lg-2.pl-0\n",
       "        img(src='assets/images/publication/02_glocalX.jpg ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-one' type='button').mr-3\n",
       "        #modal-one.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-one-Title' aria-hidden='true')\n",
       "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
       "                .modal-content\n",
       "                    .modal-header\n",
       "                        p.small GLocalX - From Local to Global Explanations of Black Box AI Models\n",
       "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
       "                            span(aria-hidden='true') &times;\n",
       "                    .modal-body\n",
       "                        img(src='assets/images/publication/02_glocalX.jpg ' alt=\"immagine\" )\n",
       "    .col-lg-6.bg-yellow.p-3\n",
       "        #accordion-one.accordion\n",
       "        | #[strong GLocalX - From Local to Global Explanations of Black Box AI Models] \n",
       "        br\n",
       "        | #[em Setzu Mattia, Guidotti Riccardo, Monreale Anna, Turini Franco, Pedreschi Dino, Giannotti Fosca] (2021) - Artificial Intelligence. In Artificial Intelligence\n",
       "        #collapse-one.collapse(aria-labelledby='heading-one' data-parent='#accordion-one')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Artificial Intelligence (AI) has come to prominence as one of the major components of our society, with applications in most aspects of our lives. In this field, complex and highly nonlinear machine learning models such as ensemble models, deep neural networks, and Support Vector Machines have consistently shown remarkable accuracy in solving complex tasks. Although accurate, AI models often are “black boxes” which we are not able to understand. Relying on these models has a multifaceted impact and raises significant concerns about their transparency. Applications in sensitive and critical domains are a strong motivational factor in trying to understand the behavior of black boxes. We propose to address this issue by providing an interpretable layer on top of black box models by aggregating “local” explanations. We present GLocalX, a “local-first” model agnostic explanation method. Starting from local explanations expressed in form of local decision rules, GLocalX iteratively generalizes them into global explanations by hierarchically aggregating them. Our goal is to learn accurate yet simple interpretable models to emulate the given black box, and, if possible, replace it entirely. We validate GLocalX in a set of experiments in standard and constrained settings with limited or no access to either data or local explanations. Experiments show that GLocalX is able to accurately emulate several models with simple and small models, reaching state-of-the-art performance against natively global solutions. Our findings show how it is often possible to achieve a high level of both accuracy and comprehensibility of classification models, even in complex domains with high-dimensional data, without necessarily trading one property for the other. This is a key requirement for a trustworthy AI, necessary for adoption in high-stakes decision making applications.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{Setzu_2021,\n",
       "                    doi = {10.1016/j.artint.2021.103457},\n",
       "                    url = {https://doi.org/10.1016%2Fj.artint.2021.103457},\n",
       "                    year = 2021,\n",
       "                    month = {may},\n",
       "                    publisher = {Elsevier {BV}},\n",
       "                    volume = {294},\n",
       "                    pages = {103457},\n",
       "                    author = {Mattia Setzu and Riccardo Guidotti and Anna Monreale and Franco Turini and Dino Pedreschi and Fosca Giannotti},\n",
       "                    title = {{GLocalX} - From Local to Global Explanations of Black Box {AI} Models},\n",
       "                    journal = {Artificial Intelligence}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-one' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1016/j.artint.2021.103457', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1▪4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 3.\n",
       "    .col-lg-2.pl-0\n",
       "        img(src='assets/images/publication/03_factual_and_counterfactual.jpg ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-two' type='button').mr-3\n",
       "        #modal-two.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-two-Title' aria-hidden='true')\n",
       "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
       "                .modal-content\n",
       "                    .modal-header\n",
       "                        p.small Factual and Counterfactual Explanations for Black Box Decision Making\n",
       "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
       "                            span(aria-hidden='true') &times;\n",
       "                    .modal-body\n",
       "                        img(src='assets/images/publication/03_factual_and_counterfactual.jpg ' alt=\"immagine\" )\n",
       "    .col-lg-6.bg-yellow.p-3\n",
       "        #accordion-two.accordion\n",
       "        | #[strong Factual and Counterfactual Explanations for Black Box Decision Making] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, Monreale Anna, Giannotti Fosca, Pedreschi Dino, Ruggieri Salvatore, Turini Franco] (2021) - IEEE Intelligent Systems. In IEEE Intelligent Systems\n",
       "        #collapse-two.collapse(aria-labelledby='heading-two' data-parent='#accordion-two')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small The rise of sophisticated machine learning models has brought accurate but obscure decision systems, which hide their logic, thus undermining transparency, trust, and the adoption of artificial intelligence (AI) in socially sensitive and safety-critical contexts. We introduce a local rule-based explanation method, providing faithful explanations of the decision made by a black box classifier on a specific instance. The proposed method first learns an interpretable, local classifier on a synthetic neighborhood of the instance under investigation, generated by a genetic algorithm. Then, it derives from the interpretable classifier an explanation consisting of a decision rule, explaining the factual reasons of the decision, and a set of counterfactuals, suggesting the changes in the instance features that would lead to a different outcome. Experimental results show that the proposed method outperforms existing approaches in terms of the quality of the explanations and of the accuracy in mimicking the black box.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{Guidotti_2019,\n",
       "                    doi = {10.1109/mis.2019.2957223},\n",
       "                    url = {https://doi.org/10.1109%2Fmis.2019.2957223},\n",
       "                    year = 2019,\n",
       "                    month = {nov},\n",
       "                    publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},\n",
       "                    volume = {34},\n",
       "                    number = {6},\n",
       "                    pages = {14--23},\n",
       "                    author = {Riccardo Guidotti and Anna Monreale and Fosca Giannotti and Dino Pedreschi and Salvatore Ruggieri and Franco Turini},\n",
       "                    title = {Factual and Counterfactual Explanations for Black Box Decision Making},\n",
       "                    journal = {{IEEE} Intelligent Systems}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-two' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1109/mis.2019.2957223', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 4.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-three.accordion\n",
       "        | #[strong Local Rule-Based Explanations of Black Box Decision Systems] \n",
       "        br\n",
       "        | #[em Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi, Franco Turini, Fosca Giannotti] (2018) - Arxive preprint\n",
       "        #collapse-three.collapse(aria-labelledby='heading-three' data-parent='#accordion-three')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small The recent years have witnessed the rise of accurate but obscure decision systems which hide the logic of their internal decision processes to the users. The lack of explanations for the decisions of black box systems is a key ethical issue, and a limitation to the adoption of achine learning components in socially sensitive and safety-critical contexts. Therefore, we need explanations that reveals the reasons why a predictor takes a certain decision. In this paper we focus on the problem of black box outcome explanation, i.e., explaining the reasons of the decision taken on a specific instance. We propose LORE, an agnostic method able to provide interpretable and faithful explanations. LORE first leans a local interpretable predictor on a synthetic neighborhood generated by a genetic algorithm. Then it derives from the logic of the local interpretable predictor a meaningful explanation consisting of: a decision rule, which explains the reasons of the decision; and a set of counterfactual rules, suggesting the changes in the instance's features that lead to a different outcome. Wide experiments show that LORE outperforms existing methods and baselines both in the quality of explanations and in the accuracy in mimicking the black box.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-three' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://arxiv.org/abs/1805.10820', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 5.\n",
       "    .col-lg-2.pl-0\n",
       "        img(src='assets/images/publication/Ethical Societal and Legal.jpg ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-four' type='button').mr-3\n",
       "        #modal-four.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-four-Title' aria-hidden='true')\n",
       "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
       "                .modal-content\n",
       "                    .modal-header\n",
       "                        p.small Ethical, societal and legal issues in deep learning for healthcare\n",
       "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
       "                            span(aria-hidden='true') &times;\n",
       "                    .modal-body\n",
       "                        img(src='assets/images/publication/Ethical Societal and Legal.jpg ' alt=\"immagine\" )\n",
       "    .col-lg-6.bg-yellow.p-3\n",
       "        #accordion-four.accordion\n",
       "        | #[strong Ethical, societal and legal issues in deep learning for healthcare] \n",
       "        br\n",
       "        | #[em Panigutti Cecilia, Monreale Anna, Comandè Giovanni, Pedreschi Dino] (2022) - Deep Learning in Biology and Medicine. In Deep Learning in Biology and Medicine\n",
       "        #collapse-four.collapse(aria-labelledby='heading-four' data-parent='#accordion-four')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Biology, medicine and biochemistry have become data-centric fields for which Deep Learning methods are delivering groundbreaking results. Addressing high impact challenges, Deep Learning in Biology and Medicine provides an accessible and organic collection of Deep Learning essays on bioinformatics and medicine. It caters for a wide readership, ranging from machine learning practitioners and data scientists seeking methodological knowledge to address biomedical applications, to life science specialists in search of a gentle reference for advanced data analytics.With contributions from internationally renowned experts, the book covers foundational methodologies in a wide spectrum of life sciences applications, including electronic health record processing, diagnostic imaging, text processing, as well as omics-data processing. This survey of consolidated problems is complemented by a selection of advanced applications, including cheminformatics and biomedical interaction network analysis. A modern and mindful approach to the use of data-driven methodologies in the life sciences also requires careful consideration of the associated societal, ethical, legal and transparency challenges, which are covered in the concluding chapters of this book.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @book{Bacciu_2022,\n",
       "                    doi = {10.1142/q0322},\n",
       "                    url = {https://doi.org/10.1142%2Fq0322},\n",
       "                    year = 2022,\n",
       "                    month = {feb},\n",
       "                    publisher = {{WORLD} {SCIENTIFIC} ({EUROPE})},\n",
       "                    author = {Davide Bacciu and Paulo J G Lisboa and Alfredo Vellido},\n",
       "                    title = {Deep Learning in Biology and Medicine}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-four' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://www.worldscientific.com/worldscibooks/10.1142/q0322', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 6.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-five.accordion\n",
       "        | #[strong Trustworthy AI] \n",
       "        br\n",
       "        | #[em Chatila Raja, Dignum Virginia, Fisher Michael, Giannotti Fosca, Morik Katharina, Russell Stuart, Yeung Karen] (2022) - Reflections on Artificial Intelligence for Humanity. In Lecture Notes in Computer Science,\n",
       "        #collapse-five.collapse(aria-labelledby='heading-five' data-parent='#accordion-five')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Modern AI systems have become of widespread use in almost all sectors with a strong impact on our society. However, the very methods on which they rely, based on Machine Learning techniques for processing data to predict outcomes and to make decisions, are opaque, prone to bias and may produce wrong answers. Objective functions optimized in learning systems are not guaranteed to align with the values that motivated their definition. Properties such as transparency, verifiability, explainability, security, technical robustness and safety, are key to build operational governance frameworks, so that to make AI systems justifiably trustworthy and to align their development and use with human rights and values.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @incollection{Chatila_2021,\n",
       "                    doi = {10.1007/978-3-030-69128-8_2},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-69128-8_2},\n",
       "                    year = 2021,\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    pages = {13--39},\n",
       "                    author = {Raja Chatila and Virginia Dignum and Michael Fisher and Fosca Giannotti and Katharina Morik and Stuart Russell and Karen Yeung},\n",
       "                    title = {Trustworthy {AI}},\n",
       "                    booktitle = {Reflections on Artificial Intelligence for Humanity}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-five' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-69128-8_2', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 5]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 7.\n",
       "    .col-lg-2.pl-0\n",
       "        img(src='assets/images/publication/understanding_peace.jpg ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-six' type='button').mr-3\n",
       "        #modal-six.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-six-Title' aria-hidden='true')\n",
       "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
       "                .modal-content\n",
       "                    .modal-header\n",
       "                        p.small Understanding peace through the world news\n",
       "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
       "                            span(aria-hidden='true') &times;\n",
       "                    .modal-body\n",
       "                        img(src='assets/images/publication/understanding_peace.jpg ' alt=\"immagine\" )\n",
       "    .col-lg-6.bg-yellow.p-3\n",
       "        #accordion-six.accordion\n",
       "        | #[strong Understanding peace through the world news] \n",
       "        br\n",
       "        | #[em Voukelatou Vasiliki, Miliou Ioanna, Giannotti Fosca, Pappalardo Luca] (2022) - EPJ Data Science. In EPJ Data Science\n",
       "        #collapse-six.collapse(aria-labelledby='heading-six' data-parent='#accordion-six')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Peace is a principal dimension of well-being and is the way out of inequity and violence. Thus, its measurement has drawn the attention of researchers, policymakers, and peacekeepers. During the last years, novel digital data streams have drastically changed the research in this field. The current study exploits information extracted from a new digital database called Global Data on Events, Location, and Tone (GDELT) to capture peace through the Global Peace Index (GPI). Applying predictive machine learning models, we demonstrate that news media attention from GDELT can be used as a proxy for measuring GPI at a monthly level. Additionally, we use explainable AI techniques to obtain the most important variables that drive the predictions. This analysis highlights each country’s profile and provides explanations for the predictions, and particularly for the errors and the events that drive these errors. We believe that digital data exploited by researchers, policymakers, and peacekeepers, with data science tools as powerful as machine learning, could contribute to maximizing the societal benefits and minimizing the risks to peace.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{Voukelatou_2022,\n",
       "                    doi = {10.1140/epjds/s13688-022-00315-z},\n",
       "                    url = {https://doi.org/10.1140%2Fepjds%2Fs13688-022-00315-z},\n",
       "                    year = 2022,\n",
       "                    month = {jan},\n",
       "                    publisher = {Springer Science and Business Media {LLC}},\n",
       "                    volume = {11},\n",
       "                    number = {1},\n",
       "                    author = {Vasiliki Voukelatou and Ioanna Miliou and Fosca Giannotti and Luca Pappalardo},\n",
       "                    title = {Understanding peace through the world news},\n",
       "                    journal = {{EPJ} Data Science}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-six' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1140/epjds/s13688-022-00315-z', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 8.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-seven.accordion\n",
       "        | #[strong TriplEx: Triple Extraction for Explanation] \n",
       "        br\n",
       "        | #[em Mattia Setzu, Anna Monreale, Pasquale Minervini] (2022) - Third Conference on Cognitive Machine Intelligence (COGMI) 2021\n",
       "        #collapse-seven.collapse(aria-labelledby='heading-seven' data-parent='#accordion-seven')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small ABSTRACT NOT FOUND\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @inproceedings{Setzu_2021,\n",
       "                    doi = {10.1109/cogmi52975.2021.00015},\n",
       "                    url = {https://doi.org/10.1109%2Fcogmi52975.2021.00015},\n",
       "                    year = 2021,\n",
       "                    month = {dec},\n",
       "                    publisher = {{IEEE}},\n",
       "                    author = {Mattia Setzu and Anna Monreale and Pasquale Minervini},\n",
       "                    title = {{TRIPLEx}: Triple Extraction for Explanation},\n",
       "                    booktitle = {2021 {IEEE} Third International Conference on Cognitive Machine Intelligence ({CogMI})}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-seven' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='10.1109/CogMI52975.2021.00015', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 9.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-eight.accordion\n",
       "        | #[strong Understanding the impact of explanations on advice-taking: a user study for AI-based clinical Decision Support Systems] \n",
       "        br\n",
       "        | #[em Cecilia Panigutti, Andrea Beretta, Dino Pedreschi, Fosca Giannotti] (2022) - 2022 Conference on Human Factors in Computing Systems. In Proceedings of the 2022 Conference on Human Factors in Computing Systems\n",
       "        #collapse-eight.collapse(aria-labelledby='heading-eight' data-parent='#accordion-eight')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small The field of eXplainable Artificial Intelligence (XAI) focuses on providing explanations for AI systems' decisions. XAI applications to AI-based Clinical Decision Support Systems (DSS) should increase trust in the DSS by allowing clinicians to investigate the reasons behind its suggestions. In this paper, we present the results of a user study on the impact of advice from a clinical DSS on healthcare providers' judgment in two different cases: the case where the clinical DSS explains its suggestion and the case it does not. We examined the weight of advice, the behavioral intention to use the system, and the perceptions with quantitative and qualitative measures. Our results indicate a more significant impact of advice when an explanation for the DSS decision is provided. Additionally, through the open-ended questions, we provide some insights on how to improve the explanations in the diagnosis forecasts for healthcare assistants, nurses, and doctors.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @inproceedings{Panigutti_2022,\n",
       "                    doi = {10.1145/3491102.3502104},\n",
       "                    url = {https://doi.org/10.1145%2F3491102.3502104},\n",
       "                    year = 2022,\n",
       "                    month = {apr},\n",
       "                    publisher = {{ACM}},\n",
       "                    author = {Cecilia Panigutti and Andrea Beretta and Fosca Giannotti and Dino Pedreschi},\n",
       "                    title = {Understanding the impact of explanations on advice-taking: a user study for {AI}-based clinical Decision Support Systems},\n",
       "                    booktitle = {{CHI} Conference on Human Factors in Computing Systems}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-eight' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        \n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 11.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-ten.accordion\n",
       "        | #[strong Explaining Black Box with visual exploration of Latent Space] \n",
       "        br\n",
       "        | #[em Francesco Bodria, Salvatore Rinzivillo, Daniele Fadda, Riccardo Guidotti, Fosca Giannotti, Dino Pedreschi] (2022) - EUROVIS 2022\n",
       "        #collapse-ten.collapse(aria-labelledby='heading-ten' data-parent='#accordion-ten')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Autoencoders are a powerful yet opaque feature reduction technique, on top of which we propose a novel way for the joint visual exploration of both latent and real space. By interactively exploiting the mapping between latent and real features, it is possible to unveil the meaning of latent features while providing deeper insight into the original variables. To achieve this goal, we exploit and re-adapt existing approaches from eXplainable Artificial Intelligence (XAI) to understand the relationships between the input and latent features. The uncovered relationships between input features and latent ones allow the user to understand the data structure concerning external variables such as the predictions of a classification model. We developed an interactive framework that visually explores the latent space and allows the user to understand the relationships of the input features with model prediction.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-ten' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        \n",
       "        p.my-1\n",
       "                small Research Line #[strong 3]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 12.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-eleven.accordion\n",
       "        | #[strong Investigating Debiasing Effects on Classification and Explainability] \n",
       "        br\n",
       "        | #[em Marta Marchiori Manerba, Riccardo Guidotti] (2022) - Conference on AI, Ethics, and Society (AIES 2022). In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES'22)\n",
       "        #collapse-eleven.collapse(aria-labelledby='heading-eleven' data-parent='#accordion-eleven')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small During each stage of a dataset creation and development process, harmful biases can be accidentally introduced, leading to models that perpetuates marginalization and discrimination of minorities, as the role of the data used during the training is critical. We propose an evaluation framework that investigates the impact on classification and explainability of bias mitigation preprocessing techniques used to assess data imbalances concerning minorities' representativeness and mitigate the skewed distributions discovered. Our evaluation focuses on assessing fairness, explainability and performance metrics. We analyze the behavior of local model-agnostic explainers on the original and mitigated datasets to examine whether the proxy models learned by the explainability techniques to mimic the black-boxes disproportionately rely on sensitive attributes, demonstrating biases rooted in the explainers. We conduct several experiments about known biased datasets to demonstrate our proposal’s novelty and effectiveness for evaluation and bias detection purposes.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-eleven' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        \n",
       "        p.my-1\n",
       "                small Research Line #[strong 1▪5]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 13.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-twelve.accordion\n",
       "        | #[strong Investigating Neighborhood Generation Methods for Explanations of Obscure Image Classifiers] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, Monreale Anna, Cariaggi Leonardo] (2021) - Advances in Knowledge Discovery and Data Mining. In In Pacific-Asia Conference on Knowledge Discovery and Data Mining (pp. 55-68). Springer, Cham.\n",
       "        #collapse-twelve.collapse(aria-labelledby='heading-twelve' data-parent='#accordion-twelve')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Given the wide use of machine learning approaches based on opaque prediction models, understanding the reasons behind decisions of black box decision systems is nowadays a crucial topic. We address the problem of providing meaningful explanations in the widely-applied image classification tasks. In particular, we explore the impact of changing the neighborhood generation function for a local interpretable model-agnostic explanator by proposing four different variants. All the proposed methods are based on a grid-based segmentation of the images, but each of them proposes a different strategy for generating the neighborhood of the image for which an explanation is required. A deep experimentation shows both improvements and weakness of each proposed approach.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @incollection{Guidotti_2019,\n",
       "                    doi = {10.1007/978-3-030-16148-4_5},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-16148-4_5},\n",
       "                    year = 2019,\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    pages = {55--68},\n",
       "                    author = {Riccardo Guidotti and Anna Monreale and Leonardo Cariaggi},\n",
       "                    title = {Investigating Neighborhood Generation Methods for Explanations of Obscure Image Classifiers},\n",
       "                    booktitle = {Advances in Knowledge Discovery and Data Mining}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twelve' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-16148-4_5', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 14.\n",
       "    .col-lg-2.pl-0\n",
       "        img(src='assets/images/publication/Explaining Multi-label Black-Box Classifiers for Health Applications.png ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-thirteen' type='button').mr-3\n",
       "        #modal-thirteen.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-thirteen-Title' aria-hidden='true')\n",
       "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
       "                .modal-content\n",
       "                    .modal-header\n",
       "                        p.small Explaining Multi-label Black-Box Classifiers for Health Applications\n",
       "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
       "                            span(aria-hidden='true') &times;\n",
       "                    .modal-body\n",
       "                        img(src='assets/images/publication/Explaining Multi-label Black-Box Classifiers for Health Applications.png ' alt=\"immagine\" )\n",
       "    .col-lg-6.bg-yellow.p-3\n",
       "        #accordion-thirteen.accordion\n",
       "        | #[strong Explaining Multi-label Black-Box Classifiers for Health Applications] \n",
       "        br\n",
       "        | #[em Panigutti Cecilia, Guidotti Riccardo, Monreale Anna, Pedreschi Dino] (2021) - Precision Health and Medicine. In International Workshop on Health Intelligence (pp. 97-110). Springer, Cham.\n",
       "        #collapse-thirteen.collapse(aria-labelledby='heading-thirteen' data-parent='#accordion-thirteen')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Today the state-of-the-art performance in classification is achieved by the so-called “black boxes”, i.e. decision-making systems whose internal logic is obscure. Such models could revolutionize the health-care system, however their deployment in real-world diagnosis decision support systems is subject to several risks and limitations due to the lack of transparency. The typical classification problem in health-care requires a multi-label approach since the possible labels are not mutually exclusive, e.g. diagnoses. We propose MARLENA, a model-agnostic method which explains multi-label black box decisions. MARLENA explains an individual decision in three steps. First, it generates a synthetic neighborhood around the instance to be explained using a strategy suitable for multi-label decisions. It then learns a decision tree on such neighborhood and finally derives from it a decision rule that explains the black box decision. Our experiments show that MARLENA performs well in terms of mimicking the black box behavior while gaining at the same time a notable amount of interpretability through compact decision rules, i.e. rules with limited length.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @incollection{Panigutti_2019,\n",
       "                    doi = {10.1007/978-3-030-24409-5_9},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-24409-5_9},\n",
       "                    year = 2019,\n",
       "                    month = {aug},\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    pages = {97--110},\n",
       "                    author = {Cecilia Panigutti and Riccardo Guidotti and Anna Monreale and Dino Pedreschi},\n",
       "                    title = {Explaining Multi-label Black-Box Classifiers for Health Applications},\n",
       "                    booktitle = {Precision Health and Medicine}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirteen' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-24409-5_9', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 15.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-fourteen.accordion\n",
       "        | #[strong Explaining Sentiment Classification with Synthetic Exemplars and Counter-Exemplars] \n",
       "        br\n",
       "        | #[em Lampridis Orestis, Guidotti Riccardo, Ruggieri Salvatore] (2021) - Discovery Science. In In International Conference on Discovery Science (pp. 357-373). Springer, Cham.\n",
       "        #collapse-fourteen.collapse(aria-labelledby='heading-fourteen' data-parent='#accordion-fourteen')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small We present xspells, a model-agnostic local approach for explaining the decisions of a black box model for sentiment classification of short texts. The explanations provided consist of a set of exemplar sentences and a set of counter-exemplar sentences. The former are examples classified by the black box with the same label as the text to explain. The latter are examples classified with a different label (a form of counter-factuals). Both are close in meaning to the text to explain, and both are meaningful sentences – albeit they are synthetically generated. xspells generates neighbors of the text to explain in a latent space using Variational Autoencoders for encoding text and decoding latent instances. A decision tree is learned from randomly generated neighbors, and used to drive the selection of the exemplars and counter-exemplars. We report experiments on two datasets showing that xspells outperforms the well-known lime method in terms of quality of explanations, fidelity, and usefulness, and that is comparable to it in terms of stability.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @incollection{Lampridis_2020,\n",
       "                    doi = {10.1007/978-3-030-61527-7_24},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-61527-7_24},\n",
       "                    year = 2020,\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    pages = {357--373},\n",
       "                    author = {Orestis Lampridis and Riccardo Guidotti and Salvatore Ruggieri},\n",
       "                    title = {Explaining Sentiment Classification with Synthetic Exemplars and Counter-Exemplars},\n",
       "                    booktitle = {Discovery Science}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-fourteen' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-61527-7_24', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 16.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-fifteen.accordion\n",
       "        | #[strong Evaluating local explanation methods on ground truth] \n",
       "        br\n",
       "        | #[em Riccardo Guidotti] (2021) - Artificial Intelligence. In Artificial Intelligence, 103428\n",
       "        #collapse-fifteen.collapse(aria-labelledby='heading-fifteen' data-parent='#accordion-fifteen')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Evaluating local explanation methods is a difficult task due to the lack of a shared and universally accepted definition of explanation. In the literature, one of the most common ways to assess the performance of an explanation method is to measure the fidelity of the explanation with respect to the classification of a black box model adopted by an Artificial Intelligent system for making a decision. However, this kind of evaluation only measures the degree of adherence of the local explainer in reproducing the behavior of the black box classifier with respect to the final decision. Therefore, the explanation provided by the local explainer could be different in the content even though it leads to the same decision of the AI system. In this paper, we propose an approach that allows to measure to which extent the explanations returned by local explanation methods are correct with respect to a synthetic ground truth explanation. Indeed, the proposed methodology enables the generation of synthetic transparent classifiers for which the reason for the decision taken, i.e., a synthetic ground truth explanation, is available by design. Experimental results show how the proposed approach allows to easily evaluate local explanations on the ground truth and to characterize the quality of local explanation methods.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{Guidotti_2021,\n",
       "                    doi = {10.1016/j.artint.2020.103428},\n",
       "                    url = {https://doi.org/10.1016%2Fj.artint.2020.103428},\n",
       "                    year = 2021,\n",
       "                    month = {feb},\n",
       "                    publisher = {Elsevier {BV}},\n",
       "                    volume = {291},\n",
       "                    pages = {103428},\n",
       "                    author = {Riccardo Guidotti},\n",
       "                    title = {Evaluating local explanation methods on ground truth},\n",
       "                    journal = {Artificial Intelligence}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-fifteen' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1016/j.artint.2020.103428', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 17.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-sixteen.accordion\n",
       "        | #[strong Meaningful Explanations of Black Box AI Decision Systems] \n",
       "        br\n",
       "        | #[em Pedreschi Dino, Giannotti Fosca, Guidotti Riccardo, Monreale Anna, Ruggieri Salvatore, Turini Franco] (2021) - Proceedings of the AAAI Conference on Artificial Intelligence. In Proceedings of the AAAI Conference on Artificial Intelligence\n",
       "        #collapse-sixteen.collapse(aria-labelledby='heading-sixteen' data-parent='#accordion-sixteen')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Black box AI systems for automated decision making, often based on machine learning over (big) data, map a user’s features into a class or a score without exposing the reasons why. This is problematic not only for lack of transparency, but also for possible biases inherited by the algorithms from human prejudices and collection artifacts hidden in the training data, which may lead to unfair or wrong decisions. We focus on the urgent open challenge of how to construct meaningful explanations of opaque AI/ML systems, introducing the local-toglobal framework for black box explanation, articulated along three lines: (i) the language for expressing explanations in terms of logic rules, with statistical and causal interpretation; (ii) the inference of local explanations for revealing the decision rationale for a specific case, by auditing the black box in the vicinity of the target instance; (iii), the bottom-up generalization of many local explanations into simple global ones, with algorithms that optimize for quality and comprehensibility. We argue that the local-first approach opens the door to a wide variety of alternative solutions along different dimensions: a variety of data sources (relational, text, images, etc.), a variety of learning problems (multi-label classification, regression, scoring, ranking), a variety of languages for expressing meaningful explanations, a variety of means to audit a black box.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{Pedreschi_2019,\n",
       "                    doi = {10.1609/aaai.v33i01.33019780},\n",
       "                    url = {https://doi.org/10.1609%2Faaai.v33i01.33019780},\n",
       "                    year = 2019,\n",
       "                    month = {jul},\n",
       "                    publisher = {Association for the Advancement of Artificial Intelligence ({AAAI})},\n",
       "                    volume = {33},\n",
       "                    pages = {9780--9784},\n",
       "                    author = {Dino Pedreschi and Fosca Giannotti and Riccardo Guidotti and Anna Monreale and Salvatore Ruggieri and Franco Turini},\n",
       "                    title = {Meaningful Explanations of Black Box {AI} Decision Systems},\n",
       "                    journal = {Proceedings of the {AAAI} Conference on Artificial Intelligence}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-sixteen' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1609/aaai.v33i01.33019780', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 18.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-seventeen.accordion\n",
       "        | #[strong Black Box Explanation by Learning Image Exemplars in the Latent Feature Space] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, Monreale Anna, Matwin Stan, Pedreschi Dino] (2021) - Machine Learning and Knowledge Discovery in Databases. In Black Box Explanation by Learning Image Exemplars in the Latent Feature Space.\n",
       "        #collapse-seventeen.collapse(aria-labelledby='heading-seventeen' data-parent='#accordion-seventeen')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small We present an approach to explain the decisions of black box models for image classification. While using the black box to label images, our explanation method exploits the latent feature space learned through an adversarial autoencoder. The proposed method first generates exemplar images in the latent feature space and learns a decision tree classifier. Then, it selects and decodes exemplars respecting local decision rules. Finally, it visualizes them in a manner that shows to the user how the exemplars can be modified to either stay within their class, or to become counter-factuals by “morphing” into another class. Since we focus on black box decision systems for image classification, the explanation obtained from the exemplars also provides a saliency map highlighting the areas of the image that contribute to its classification, and areas of the image that push it into another class. We present the results of an experimental evaluation on three datasets and two black box models. Besides providing the most useful and interpretable explanations, we show that the proposed method outperforms existing explainers in terms of fidelity, relevance, coherence, and stability.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @incollection{Guidotti_2020,\n",
       "                    doi = {10.1007/978-3-030-46150-8_12},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-46150-8_12},\n",
       "                    year = 2020,\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    pages = {189--205},\n",
       "                    author = {Riccardo Guidotti and Anna Monreale and Stan Matwin and Dino Pedreschi},\n",
       "                    title = {Black Box Explanation by Learning Image Exemplars in the Latent Feature Space},\n",
       "                    booktitle = {Machine Learning and Knowledge Discovery in Databases}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-seventeen' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-46150-8_12', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1▪4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 19.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-eighteen.accordion\n",
       "        | #[strong Explaining Image Classifiers Generating Exemplars and Counter-Exemplars from Latent Representations] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, Monreale Anna, Matwin Stan, Pedreschi Dino] (2021) - Proceedings of the AAAI Conference on Artificial Intelligence\n",
       "        #collapse-eighteen.collapse(aria-labelledby='heading-eighteen' data-parent='#accordion-eighteen')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small We present an approach to explain the decisions of black box image classifiers through synthetic exemplar and counter-exemplar learnt in the latent feature space. Our explanation method exploits the latent representations learned through an adversarial autoencoder for generating a synthetic neighborhood of the image for which an explanation is required. A decision tree is trained on a set of images represented in the latent space, and its decision rules are used to generate exemplar images showing how the original image can be modified to stay within its class. Counterfactual rules are used to generate counter-exemplars showing how the original image can “morph” into another class. The explanation also comprehends a saliency map highlighting the areas that contribute to its classification, and areas that push it into another class. A wide and deep experimental evaluation proves that the proposed method outperforms existing explainers in terms of fidelity, relevance, coherence, and stability, besides providing the most useful and interpretable explanations.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{Guidotti_2020,\n",
       "                    doi = {10.1609/aaai.v34i09.7116},\n",
       "                    url = {https://doi.org/10.1609%2Faaai.v34i09.7116},\n",
       "                    year = 2020,\n",
       "                    month = {apr},\n",
       "                    publisher = {Association for the Advancement of Artificial Intelligence ({AAAI})},\n",
       "                    volume = {34},\n",
       "                    number = {09},\n",
       "                    pages = {13665--13668},\n",
       "                    author = {Riccardo Guidotti and Anna Monreale and Stan Matwin and Dino Pedreschi},\n",
       "                    title = {Explaining Image Classifiers Generating Exemplars and Counter-Exemplars from Latent Representations},\n",
       "                    journal = {Proceedings of the {AAAI} Conference on Artificial Intelligence}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-eighteen' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1609/aaai.v34i09.7116', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 20.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-nineteen.accordion\n",
       "        | #[strong Global Explanations with Local Scoring] \n",
       "        br\n",
       "        | #[em Setzu Mattia, Guidotti Riccardo, Monreale Anna, Turini Franco] (2021) - Machine Learning and Knowledge Discovery in Databases. In ECML PKDD 2019: Machine Learning and Knowledge Discovery in Databases\n",
       "        #collapse-nineteen.collapse(aria-labelledby='heading-nineteen' data-parent='#accordion-nineteen')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Artificial Intelligence systems often adopt machine learning models encoding complex algorithms with potentially unknown behavior. As the application of these “black box” models grows, it is our responsibility to understand their inner working and formulate them in human-understandable explanations. To this end, we propose a rule-based model-agnostic explanation method that follows a local-to-global schema: it generalizes a global explanation summarizing the decision logic of a black box starting from the local explanations of single predicted instances. We define a scoring system based on a rule relevance score to extract global explanations from a set of local explanations in the form of decision rules. Experiments on several datasets and black boxes show the stability, and low complexity of the global explanations provided by the proposed solution in comparison with baselines and state-of-the-art global explainers.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @incollection{Setzu_2020,\n",
       "                    doi = {10.1007/978-3-030-43823-4_14},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-43823-4_14},\n",
       "                    year = 2020,\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    pages = {159--171},\n",
       "                    author = {Mattia Setzu and Riccardo Guidotti and Anna Monreale and Franco Turini},\n",
       "                    title = {Global Explanations with Local Scoring},\n",
       "                    booktitle = {Machine Learning and Knowledge Discovery in Databases}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-nineteen' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-43823-4_14', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 21.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-twenty.accordion\n",
       "        | #[strong Predicting and Explaining Privacy Risk Exposure in Mobility Data] \n",
       "        br\n",
       "        | #[em Naretto Francesca, Pellungrini Roberto, Monreale Anna, Nardini Franco Maria, Musolesi Mirco] (2021) - Discovery Science. In Discovery Science Conference\n",
       "        #collapse-twenty.collapse(aria-labelledby='heading-twenty' data-parent='#accordion-twenty')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Mobility data is a proxy of different social dynamics and its analysis enables a wide range of user services. Unfortunately, mobility data are very sensitive because the sharing of people’s whereabouts may arise serious privacy concerns. Existing frameworks for privacy risk assessment provide tools to identify and measure privacy risks, but they often (i) have high computational complexity; and (ii) are not able to provide users with a justification of the reported risks. In this paper, we propose expert, a new framework for the prediction and explanation of privacy risk on mobility data. We empirically evaluate privacy risk on real data, simulating a privacy attack with a state-of-the-art privacy risk assessment framework. We then extract individual mobility profiles from the data for predicting their risk. We compare the performance of several machine learning algorithms in order to identify the best approach for our task. Finally, we show how it is possible to explain privacy risk prediction on real data, using two algorithms: Shap, a feature importance-based method and Lore, a rule-based method. Overall, expert is able to provide a user with the privacy risk and an explanation of the risk itself. The experiments show excellent performance for the prediction task.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @incollection{Naretto_2020,\n",
       "                    doi = {10.1007/978-3-030-61527-7_27},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-61527-7_27},\n",
       "                    year = 2020,\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    pages = {403--418},\n",
       "                    author = {Francesca Naretto and Roberto Pellungrini and Anna Monreale and Franco Maria Nardini and Mirco Musolesi},\n",
       "                    title = {Predicting and Explaining Privacy Risk Exposure in Mobility Data},\n",
       "                    booktitle = {Discovery Science}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twenty' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-61527-7_27', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 22.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-twenty-one.accordion\n",
       "        | #[strong Prediction and Explanation of Privacy Risk on Mobility Data with Neural Networks] \n",
       "        br\n",
       "        | #[em Naretto Francesca, Pellungrini Roberto, Nardini Franco Maria, Giannotti Fosca] (2021) - ECML PKDD 2020 Workshops. In ECML PKDD 2020 Workshops\n",
       "        #collapse-twenty-one.collapse(aria-labelledby='heading-twenty-one' data-parent='#accordion-twenty-one')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small The analysis of privacy risk for mobility data is a fundamental part of any privacy-aware process based on such data. Mobility data are highly sensitive. Therefore, the correct identification of the privacy risk before releasing the data to the public is of utmost importance. However, existing privacy risk assessment frameworks have high computational complexity. To tackle these issues, some recent work proposed a solution based on classification approaches to predict privacy risk using mobility features extracted from the data. In this paper, we propose an improvement of this approach by applying long short-term memory (LSTM) neural networks to predict the privacy risk directly from original mobility data. We empirically evaluate privacy risk on real data by applying our LSTM-based approach. Results show that our proposed method based on a LSTM network is effective in predicting the privacy risk with results in terms of F1 of up to 0.91. Moreover, to explain the predictions of our model, we employ a state-of-the-art explanation algorithm, Shap. We explore the resulting explanation, showing how it is possible to provide effective predictions while explaining them to the end-user.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @incollection{Naretto_2020,\n",
       "                    doi = {10.1007/978-3-030-65965-3_34},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-65965-3_34},\n",
       "                    year = 2020,\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    pages = {501--516},\n",
       "                    author = {Francesca Naretto and Roberto Pellungrini and Franco Maria Nardini and Fosca Giannotti},\n",
       "                    title = {Prediction and Explanation of Privacy Risk on Mobility Data with Neural Networks},\n",
       "                    booktitle = {{ECML} {PKDD} 2020 Workshops}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twenty-one' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-65965-3_34', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 23.\n",
       "    .col-lg-2.pl-0\n",
       "        img(src='assets/images/publication/FairLens.png ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-twenty-two' type='button').mr-3\n",
       "        #modal-twenty-two.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-twenty-two-Title' aria-hidden='true')\n",
       "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
       "                .modal-content\n",
       "                    .modal-header\n",
       "                        p.small FairLens: Auditing black-box clinical decision support systems\n",
       "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
       "                            span(aria-hidden='true') &times;\n",
       "                    .modal-body\n",
       "                        img(src='assets/images/publication/FairLens.png ' alt=\"immagine\" )\n",
       "    .col-lg-6.bg-yellow.p-3\n",
       "        #accordion-twenty-two.accordion\n",
       "        | #[strong FairLens: Auditing black-box clinical decision support systems] \n",
       "        br\n",
       "        | #[em Panigutti Cecilia, Perotti Alan, Panisson André, Bajardi Paolo, Pedreschi Dino] (2021) - Information Processing & Management. In Journal of Information Processing and Management\n",
       "        #collapse-twenty-two.collapse(aria-labelledby='heading-twenty-two' data-parent='#accordion-twenty-two')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Highlights: We present a pipeline to detect and explain potential fairness issues in Clinical DSS. We study and compare different multi-label classification disparity measures. We explore ICD9 bias in MIMIC-IV, an openly available ICU benchmark dataset\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{Panigutti_2021,\n",
       "                    doi = {10.1016/j.ipm.2021.102657},\n",
       "                    url = {https://doi.org/10.1016%2Fj.ipm.2021.102657},\n",
       "                    year = 2021,\n",
       "                    month = {sep},\n",
       "                    publisher = {Elsevier {BV}},\n",
       "                    volume = {58},\n",
       "                    number = {5},\n",
       "                    pages = {102657},\n",
       "                    author = {Cecilia Panigutti and Alan Perotti and Andr{\\'{e}} Panisson and Paolo Bajardi and Dino Pedreschi},\n",
       "                    title = {{FairLens}: Auditing black-box clinical decision support systems},\n",
       "                    journal = {Information Processing {\\&}amp$\\mathsemicolon$ Management}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twenty-two' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1016/j.ipm.2021.102657', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 24.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-twenty-three.accordion\n",
       "        | #[strong Intelligenza artificiale in ambito diabetologico: prospettive, dalla ricerca di base alle applicazioni cliniche] \n",
       "        br\n",
       "        | #[em Panigutti Cecilia, Bosi Emanuele] (2021) - Il Diabete Online, Organo ufficiale della Società Italiana di Diabetologia, Medicina traslazionale: Applicazioni cliniche della ricerca di base, Vol. 33, N. 1 2021. In Il Diabete\n",
       "        #collapse-twenty-three.collapse(aria-labelledby='heading-twenty-three' data-parent='#accordion-twenty-three')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small ABSTRACT NOT FOUND\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{2021,\n",
       "                    doi = {10.30682/ildia2101f},\n",
       "                    url = {https://doi.org/10.30682%2Fildia2101f},\n",
       "                    year = 2021,\n",
       "                    publisher = {Bononia University Press},\n",
       "                    volume = {33},\n",
       "                    number = {1},\n",
       "                    title = {Intelligenza artificiale in ambito diabetologico: prospettive, dalla ricerca di base alle applicazioni cliniche},\n",
       "                    journal = {il Diabete}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twenty-three' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='10.30682/ildia2101f', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 25.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-twenty-four.accordion\n",
       "        | #[strong Occlusion-Based Explanations in Deep Recurrent Models for Biomedical Signals] \n",
       "        br\n",
       "        | #[em Resta Michele, Monreale Anna, Bacciu Davide] (2021) - Entropy. In Entropy\n",
       "        #collapse-twenty-four.collapse(aria-labelledby='heading-twenty-four' data-parent='#accordion-twenty-four')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small The biomedical field is characterized by an ever-increasing production of sequential data, which often come in the form of biosignals capturing the time-evolution of physiological processes, such as blood pressure and brain activity. This has motivated a large body of research dealing with the development of machine learning techniques for the predictive analysis of such biosignals. Unfortunately, in high-stakes decision making, such as clinical diagnosis, the opacity of machine learning models becomes a crucial aspect to be addressed in order to increase the trust and adoption of AI technology. In this paper, we propose a model agnostic explanation method, based on occlusion, that enables the learning of the input’s influence on the model predictions. We specifically target problems involving the predictive analysis of time-series data and the models that are typically used to deal with data of such nature, i.e., recurrent neural networks. Our approach is able to provide two different kinds of explanations: one suitable for technical experts, who need to verify the quality and correctness of machine learning models, and one suited to physicians, who need to understand the rationale underlying the prediction to make aware decisions. A wide experimentation on different physiological data demonstrates the effectiveness of our approach both in classification and regression tasks.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{Resta_2021,\n",
       "                    doi = {10.3390/e23081064},\n",
       "                    url = {https://doi.org/10.3390%2Fe23081064},\n",
       "                    year = 2021,\n",
       "                    month = {aug},\n",
       "                    publisher = {{MDPI} {AG}},\n",
       "                    volume = {23},\n",
       "                    number = {8},\n",
       "                    pages = {1064},\n",
       "                    author = {Michele Resta and Anna Monreale and Davide Bacciu},\n",
       "                    title = {Occlusion-Based Explanations in Deep Recurrent Models for Biomedical Signals},\n",
       "                    journal = {Entropy}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twenty-four' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.3390/e23081064', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 26.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-twenty-five.accordion\n",
       "        | #[strong Deriving a Single Interpretable Model by Merging Tree-Based Classifiers] \n",
       "        br\n",
       "        | #[em Bonsignori Valerio, Guidotti Riccardo, Monreale Anna] (2021) - Discovery Science\n",
       "        #collapse-twenty-five.collapse(aria-labelledby='heading-twenty-five' data-parent='#accordion-twenty-five')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Decision tree classifiers have been proved to be among the most interpretable models due to their intuitive structure that illustrates decision processes in form of logical rules. Unfortunately, more complex tree-based classifiers such as oblique trees and random forests overcome the accuracy of decision trees at the cost of becoming non interpretable. In this paper, we propose a method that takes as input any tree-based classifier and returns a single decision tree able to approximate its behavior. Our proposal merges tree-based classifiers by an intensional and extensional approach and applies a post-hoc explanation strategy. Our experiments shows that the retrieved single decision tree is at least as accurate as the original tree-based model, faithful, and more interpretable.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @incollection{Bonsignori_2021,\n",
       "                    doi = {10.1007/978-3-030-88942-5_27},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-88942-5_27},\n",
       "                    year = 2021,\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    pages = {347--357},\n",
       "                    author = {Valerio Bonsignori and Riccardo Guidotti and Anna Monreale},\n",
       "                    title = {Deriving a Single Interpretable Model by Merging Tree-Based Classifiers},\n",
       "                    booktitle = {Discovery Science}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twenty-five' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-88942-5_27', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1▪2]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 28.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-twenty-seven.accordion\n",
       "        | #[strong Ensemble of Counterfactual Explainers] \n",
       "        br\n",
       "        | #[em Riccardo Guidotti, Ruggieri Salvatore] (2021)\n",
       "        #collapse-twenty-seven.collapse(aria-labelledby='heading-twenty-seven' data-parent='#accordion-twenty-seven')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small In eXplainable Artificial Intelligence (XAI), several counterfactual explainers have been proposed, each focusing on some desirable properties of counterfactual instances: minimality, actionability, stability, diversity, plausibility, discriminative power. We propose an ensemble of counterfactual explainers that boosts weak explainers, which provide only a subset of such properties, to a powerful method covering all of them. The ensemble runs weak explainers on a sample of instances and of features, and it combines their results by exploiting a diversity-driven selection function. The method is model-agnostic and, through a wrapping approach based on autoencoders, it is also data-agnostic\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twenty-seven' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://pages.di.unipi.it/ruggieri/Papers/ds2021.pdf', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 29.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-twenty-eight.accordion\n",
       "        | #[strong Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling] \n",
       "        br\n",
       "        | #[em Metta Carlo, Guidotti Riccardo, Yin Yuan, Gallinari Patrick, Rinzivillo Salvatore] (2021) - 2021 IEEE Symposium on Computers and Communications (ISCC). In 2021 IEEE Symposium on Computers and Communications (ISCC)\n",
       "        #collapse-twenty-eight.collapse(aria-labelledby='heading-twenty-eight' data-parent='#accordion-twenty-eight')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Explainable AI consists in developing mechanisms allowing for an interaction between decision systems and humans by making the decisions of the formers understandable. This is particularly important in sensitive contexts like in the medical domain. We propose a use case study, for skin lesion diagnosis, illustrating how it is possible to provide the practitioner with explanations on the decisions of a state of the art deep neural network classifier trained to characterize skin lesions from examples. Our framework consists of a trained classifier onto which an explanation module operates. The latter is able to offer the practitioner exemplars and counterexemplars for the classification diagnosis thus allowing the physician to interact with the automatic diagnosis system. The exemplars are generated via an adversarial autoencoder. We illustrate the behavior of the system on representative examples.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @inproceedings{Metta_2021,\n",
       "                    doi = {10.1109/iscc53001.2021.9631485},\n",
       "                    url = {https://doi.org/10.1109%2Fiscc53001.2021.9631485},\n",
       "                    year = 2021,\n",
       "                    month = {sep},\n",
       "                    publisher = {{IEEE}},\n",
       "                    author = {Carlo Metta and Riccardo Guidotti and Yuan Yin and Patrick Gallinari and Salvatore Rinzivillo},\n",
       "                    title = {Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling},\n",
       "                    booktitle = {2021 {IEEE} Symposium on Computers and Communications ({ISCC})}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twenty-eight' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1109/iscc53001.2021.9631485', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 30.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-twenty-nine.accordion\n",
       "        | #[strong Designing Shapelets for Interpretable Data-Agnostic Classification] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, Monreale Anna] (2021) - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society\n",
       "        #collapse-twenty-nine.collapse(aria-labelledby='heading-twenty-nine' data-parent='#accordion-twenty-nine')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Time series shapelets are discriminatory subsequences which are representative of a class, and their similarity to a time series can be used for successfully tackling the time series classification problem. The literature shows that Artificial Intelligence (AI) systems adopting classification models based on time series shapelets can be interpretable, more accurate, and significantly fast. Thus, in order to design a data-agnostic and interpretable classification approach, in this paper we first extend the notion of shapelets to different types of data, i.e., images, tabular and textual data. Then, based on this extended notion of shapelets we propose an interpretable data-agnostic classification method. Since the shapelets discovery can be time consuming, especially for data types more complex than time series, we exploit a notion of prototypes for finding candidate shapelets, and reducing both the time required to find a solution and the variance of shapelets. A wide experimentation on datasets of different types shows that the data-agnostic prototype-based shapelets returned by the proposed method empower an interpretable classification which is also fast, accurate, and stable. In addition, we show and we prove that shapelets can be at the basis of explainable AI methods.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @inproceedings{Guidotti_2021,\n",
       "                    doi = {10.1145/3461702.3462553},\n",
       "                    url = {https://doi.org/10.1145%2F3461702.3462553},\n",
       "                    year = 2021,\n",
       "                    month = {jul},\n",
       "                    publisher = {{ACM}},\n",
       "                    author = {Riccardo Guidotti and Anna Monreale},\n",
       "                    title = {Designing Shapelets for Interpretable Data-Agnostic Classification},\n",
       "                    booktitle = {Proceedings of the 2021 {AAAI}/{ACM} Conference on {AI}, Ethics, and Society}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-twenty-nine' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://doi.org/10.1145/3461702.3462553', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 31.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-thirty.accordion\n",
       "        | #[strong Helping Your Docker Images to Spread Based on Explainable Models] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, Soldani Jacopo, Neri Davide, Brogi Antonio, Pedreschi Dino] (2021) - Machine Learning and Knowledge Discovery in Databases. In In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 205-221). Springer, Cham.\n",
       "        #collapse-thirty.collapse(aria-labelledby='heading-thirty' data-parent='#accordion-thirty')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Docker is on the rise in today’s enterprise IT. It permits shipping applications inside portable containers, which run from so-called Docker images. Docker images are distributed in public registries, which also monitor their popularity. The popularity of an image impacts on its actual usage, and hence on the potential revenues for its developers. In this paper, we present a solution based on interpretable decision tree and regression trees for estimating the popularity of a given Docker image, and for understanding how to improve an image to increase its popularity. The results presented in this work can provide valuable insights to Docker developers, helping them in spreading their images. Code related to this paper is available at: https://github.com/di-unipi-socc/DockerImageMiner.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @incollection{Guidotti_2019,\n",
       "                    doi = {10.1007/978-3-030-10997-4_13},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-10997-4_13},\n",
       "                    year = 2019,\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    pages = {205--221},\n",
       "                    author = {Riccardo Guidotti and Jacopo Soldani and Davide Neri and Antonio Brogi and Dino Pedreschi},\n",
       "                    title = {Helping Your Docker Images to Spread Based on Explainable Models},\n",
       "                    booktitle = {Machine Learning and Knowledge Discovery in Databases}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirty' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1007/978-3-030-10997-4_13', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 32.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-thirty-one.accordion\n",
       "        | #[strong Matrix Profile-Based Interpretable Time Series Classifier] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, D’Onofrio Matteo] (2021) - Frontiers in Artificial Intelligence\n",
       "        #collapse-thirty-one.collapse(aria-labelledby='heading-thirty-one' data-parent='#accordion-thirty-one')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Time series classification (TSC) is a pervasive and transversal problem in various fields ranging from disease diagnosis to anomaly detection in finance. Unfortunately, the most effective models used by Artificial Intelligence (AI) systems for TSC are not interpretable and hide the logic of the decision process, making them unusable in sensitive domains. Recent research is focusing on explanation methods to pair with the obscure classifier to recover this weakness. However, a TSC approach that is transparent by design and is simultaneously efficient and effective is even more preferable. To this aim, we propose an interpretable TSC method based on the patterns, which is possible to extract from the Matrix Profile (MP) of the time series in the training set. A smart design of the classification procedure allows obtaining an efficient and effective transparent classifier modeled as a decision tree that expresses the reasons for the classification as the presence of discriminative subsequences. Quantitative and qualitative experimentation shows that the proposed method overcomes the state-of-the-art interpretable approaches.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @article{Guidotti_2021,\n",
       "                    doi = {10.3389/frai.2021.699448},\n",
       "                    url = {https://doi.org/10.3389%2Ffrai.2021.699448},\n",
       "                    year = 2021,\n",
       "                    month = {oct},\n",
       "                    publisher = {Frontiers Media {SA}},\n",
       "                    volume = {4},\n",
       "                    author = {Riccardo Guidotti and Matteo D'Onofrio},\n",
       "                    title = {Matrix Profile-Based Interpretable Time Series Classifier},\n",
       "                    journal = {Frontiers in Artificial Intelligence}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirty-one' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.3389/frai.2021.699448', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 33.\n",
       "    .col-lg-2.pl-0\n",
       "        img(src='assets/images/publication/springer_book_explain.jpg ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-thirty-two' type='button').mr-3\n",
       "        #modal-thirty-two.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-thirty-two-Title' aria-hidden='true')\n",
       "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
       "                .modal-content\n",
       "                    .modal-header\n",
       "                        p.small Explainable AI Within the Digital Transformation and Cyber Physical Systems: XAI Methods and Applications\n",
       "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
       "                            span(aria-hidden='true') &times;\n",
       "                    .modal-body\n",
       "                        img(src='assets/images/publication/springer_book_explain.jpg ' alt=\"immagine\" )\n",
       "    .col-lg-6.bg-yellow.p-3\n",
       "        #accordion-thirty-two.accordion\n",
       "        | #[strong Explainable AI Within the Digital Transformation and Cyber Physical Systems: XAI Methods and Applications] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, Monreale Anna, Pedreschi Dino, Giannotti Fosca] (2021) - Explainable AI Within the Digital Transformation and Cyber Physical Systems (pp. 9-31)\n",
       "        #collapse-thirty-two.collapse(aria-labelledby='heading-thirty-two' data-parent='#accordion-thirty-two')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small This book presents Explainable Artificial Intelligence (XAI), which aims at producing explainable models that enable human users to understand and appropriately trust the obtained results. The authors discuss the challenges involved in making machine learning-based AI explainable. Firstly, that the explanations must be adapted to different stakeholders (end-users, policy makers, industries, utilities etc.) with different levels of technical knowledge (managers, engineers, technicians, etc.) in different application domains. Secondly, that it is important to develop an evaluation framework and standards in order to measure the effectiveness of the provided explanations at the human and the technical levels. This book gathers research contributions aiming at the development and/or the use of XAI techniques in order to address the aforementioned challenges in different applications such as healthcare, finance, cybersecurity, and document summarization. It allows highlighting the benefits and requirements of using explainable models in different application domains in order to provide guidance to readers to select the most adapted models to their specified problem and conditions. Includes recent developments of the use of Explainable Artificial Intelligence (XAI) in order to address the challenges of digital transition and cyber-physical systems; Provides a textual scientific description of the use of XAI in order to address the challenges of digital transition and cyber-physical systems; Presents examples and case studies in order to increase transparency and understanding of the methodological concepts.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @book{2021,\n",
       "                    doi = {10.1007/978-3-030-76409-8},\n",
       "                    url = {https://doi.org/10.1007%2F978-3-030-76409-8},\n",
       "                    year = 2021,\n",
       "                    publisher = {Springer International Publishing},\n",
       "                    editor = {Moamar Sayed-Mouchaweh},\n",
       "                    title = {Explainable {AI} Within the Digital Transformation and Cyber Physical Systems}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirty-two' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://doi.org/10.1007/978-3-030-76409-8', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1▪5]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 34.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-thirty-three.accordion\n",
       "        | #[strong Benchmarking and survey of explanation methods for black box models] \n",
       "        br\n",
       "        | #[em Francesco Bodria, Fosca Giannotti, Riccardo Guidotti, Francesca Naretto, Dino Pedreschi, Salvatore Rinzivillo] (2021)\n",
       "        #collapse-thirty-three.collapse(aria-labelledby='heading-thirty-three' data-parent='#accordion-thirty-three')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small The widespread adoption of black-box models in Artificial Intelligence has enhanced the need for explanation methods to reveal how these obscure models reach specific decisions. Retrieving explanations is fundamental to unveil possible biases and to resolve practical or ethical issues. Nowadays, the literature is full of methods with different explanations. We provide a categorization of explanation methods based on the type of explanation returned. We present the most recent and widely used explainers, and we show a visual comparison among explanations and a quantitative benchmarking.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirty-three' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://arxiv.org/abs/2102.13076', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 35.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-thirty-four.accordion\n",
       "        | #[strong FairShades: Fairness Auditing via Explainability in Abusive Language Detection Systems] \n",
       "        br\n",
       "        | #[em Marta Marchiori Manerba, Riccardo Guidotti] (2021) - Third Conference on Cognitive Machine Intelligence (COGMI) 2021. In 2021 IEEE Third International Conference on Cognitive Machine Intelligence (CogMI)\n",
       "        #collapse-thirty-four.collapse(aria-labelledby='heading-thirty-four' data-parent='#accordion-thirty-four')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small At every stage of a supervised learning process, harmful biases can arise and be inadvertently introduced, ultimately leading to marginalization, discrimination, and abuse towards minorities. This phenomenon becomes particularly impactful in the sensitive real-world context of abusive language detection systems, where non-discrimination is difficult to assess. In addition, given the opaqueness of their internal behavior, the dynamics leading a model to a certain decision are often not clear nor accountable, and significant problems of trust could emerge. A robust value-oriented evaluation of models' fairness is therefore necessary. In this paper, we present FairShades, a model-agnostic approach for auditing the outcomes of abusive language detection systems.  Combining explainability and fairness evaluation, FairShades can identify unintended biases and sensitive categories towards which models are most discriminative. This objective is pursued through the auditing of meaningful counterfactuals generated within CheckList framework. We conduct several experiments on BERT-based models to demonstrate our proposal's novelty and effectiveness for unmasking biases. \n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @inproceedings{Manerba_2021,\n",
       "                    doi = {10.1109/cogmi52975.2021.00014},\n",
       "                    url = {https://doi.org/10.1109%2Fcogmi52975.2021.00014},\n",
       "                    year = 2021,\n",
       "                    month = {dec},\n",
       "                    publisher = {{IEEE}},\n",
       "                    author = {Marta Marchiori Manerba and Riccardo Guidotti},\n",
       "                    title = {{FairShades}: Fairness Auditing via Explainability in Abusive Language Detection Systems},\n",
       "                    booktitle = {2021 {IEEE} Third International Conference on Cognitive Machine Intelligence ({CogMI})}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirty-four' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://ieeexplore.ieee.org/document/9750356', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1▪5]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 36.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-thirty-five.accordion\n",
       "        | #[strong Rischi etico-legali dell’Intelligenza Artificiale] \n",
       "        br\n",
       "        | #[em Anna Monreale] (2020) - DPCE Online, [S.l.], v. 44, n. 3. In DPCE Online, [S.l.], v. 44, n. 3, oct. 2020. ISSN 2037-6677\n",
       "        #collapse-thirty-five.collapse(aria-labelledby='heading-thirty-five' data-parent='#accordion-thirty-five')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small nan\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        \n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://www.dpceonline.it/index.php/dpceonline/article/view/1083', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 5]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 37.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-thirty-six.accordion\n",
       "        | #[strong Explainability Methods for Natural Language Processing: Applications to Sentiment Analysis] \n",
       "        br\n",
       "        | #[em Francesco Bodria , André Panisson , Alan Perotti , Simone Piaggesi] (2020) - Discussion Paper\n",
       "        #collapse-thirty-six.collapse(aria-labelledby='heading-thirty-six' data-parent='#accordion-thirty-six')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small nan\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        \n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://ceur-ws.org/Vol-2646/18-paper.pdf', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 38.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-thirty-seven.accordion\n",
       "        | #[strong Data-Agnostic Local Neighborhood Generation] \n",
       "        br\n",
       "        | #[em Riccardo Guidotti, Anna Monreale] (2020) - 2020 IEEE International Conference on Data Mining (ICDM). In 2020 IEEE International Conference on Data Mining (ICDM)\n",
       "        #collapse-thirty-seven.collapse(aria-labelledby='heading-thirty-seven' data-parent='#accordion-thirty-seven')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Synthetic data generation has been widely adopted in software testing, data privacy, imbalanced learning, machine learning explanation, etc. In such contexts, it is important to generate data samples located within “local” areas surrounding specific instances. Local synthetic data can help the learning phase of predictive models, and it is fundamental for methods explaining the local behavior of obscure classifiers. The contribution of this paper is twofold. First, we introduce a method based on generative operators allowing the synthetic neighborhood generation by applying specific perturbations on a given input instance. The key factor consists in performing a data transformation that makes applicable to any type of data, i.e., data-agnostic. Second, we design a framework for evaluating the goodness of local synthetic neighborhoods exploiting both supervised and unsupervised methodologies. A deep experimentation shows the effectiveness of the proposed method.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @inproceedings{Guidotti_2020,\n",
       "                    doi = {10.1109/icdm50108.2020.00122},\n",
       "                    url = {https://doi.org/10.1109%2Ficdm50108.2020.00122},\n",
       "                    year = 2020,\n",
       "                    month = {nov},\n",
       "                    publisher = {{IEEE}},\n",
       "                    author = {Riccardo Guidotti and Anna Monreale},\n",
       "                    title = {Data-Agnostic Local Neighborhood Generation},\n",
       "                    booktitle = {2020 {IEEE} International Conference on Data Mining ({ICDM})}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirty-seven' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://ieeexplore.ieee.org/document/9338395', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 39.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-thirty-eight.accordion\n",
       "        | #[strong Opening the black box: a primer for anti-discrimination] \n",
       "        br\n",
       "        | #[em Ruggieri Salvatore, Giannotti Fosca, Guidotti Riccardo; Monreale Anna, Pedreschi Dino, Turini Franco] (2020). In ANNUARIO DI DIRITTO COMPARATO E DI STUDI LEGISLATIVI\n",
       "        #collapse-thirty-eight.collapse(aria-labelledby='heading-thirty-eight' data-parent='#accordion-thirty-eight')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small The pervasive adoption of Artificial Intelligence (AI) models in the modern information society, requires counterbalancing the growing decision power demanded to AI models with risk assessment methodologies. In this paper, we consider the risk of discriminatory decisions and review approaches for discovering discrimination and for designing fair AI models. We highlight the tight relations between discrimination discovery and explainable AI, with the latter being a more general approach for understanding the behavior of black boxes.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirty-eight' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://hdl.handle.net/11568/1088440', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 40.\n",
       "    .col-lg-2.pl-0\n",
       "        img(src='assets/images/publication/Doctor XAI.jpg ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-thirty-nine' type='button').mr-3\n",
       "        #modal-thirty-nine.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-thirty-nine-Title' aria-hidden='true')\n",
       "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
       "                .modal-content\n",
       "                    .modal-header\n",
       "                        p.small Doctor XAI: an ontology-based approach to black-box sequential data classification explanations\n",
       "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
       "                            span(aria-hidden='true') &times;\n",
       "                    .modal-body\n",
       "                        img(src='assets/images/publication/Doctor XAI.jpg ' alt=\"immagine\" )\n",
       "    .col-lg-6.bg-yellow.p-3\n",
       "        #accordion-thirty-nine.accordion\n",
       "        | #[strong Doctor XAI: an ontology-based approach to black-box sequential data classification explanations] \n",
       "        br\n",
       "        | #[em Panigutti Cecilia, Perrotti Alan, Pedreschi Dino] (2020) - FAT* '20: Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. In FAT* '20: Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency\n",
       "        #collapse-thirty-nine.collapse(aria-labelledby='heading-thirty-nine' data-parent='#accordion-thirty-nine')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Several recent advancements in Machine Learning involve blackbox models: algorithms that do not provide human-understandable explanations in support of their decisions. This limitation hampers the fairness, accountability and transparency of these models; the field of eXplainable Artificial Intelligence (XAI) tries to solve this problem providing human-understandable explanations for black-box models. However, healthcare datasets (and the related learning tasks) often present peculiar features, such as sequential data, multi-label predictions, and links to structured background knowledge. In this paper, we introduce Doctor XAI, a model-agnostic explainability technique able to deal with multi-labeled, sequential, ontology-linked data. We focus on explaining Doctor AI, a multilabel classifier which takes as input the clinical history of a patient in order to predict the next visit. Furthermore, we show how exploiting the temporal dimension in the data and the domain knowledge encoded in the medical ontology improves the quality of the mined explanations.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @inproceedings{Panigutti_2020,\n",
       "                    doi = {10.1145/3351095.3372855},\n",
       "                    url = {https://doi.org/10.1145%2F3351095.3372855},\n",
       "                    year = 2020,\n",
       "                    month = {jan},\n",
       "                    publisher = {{ACM}},\n",
       "                    author = {Cecilia Panigutti and Alan Perotti and Dino Pedreschi},\n",
       "                    title = {Doctor {XAI}},\n",
       "                    booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-thirty-nine' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://dl.acm.org/doi/10.1145/3351095.3372855', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 4]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 41.\n",
       "    .col-lg-2.pl-0\n",
       "        img(src='assets/images/publication/ex_time_series_calssifier.png ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-forty' type='button').mr-3\n",
       "        #modal-forty.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-forty-Title' aria-hidden='true')\n",
       "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
       "                .modal-content\n",
       "                    .modal-header\n",
       "                        p.small Explaining Any Time Series Classifier\n",
       "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
       "                            span(aria-hidden='true') &times;\n",
       "                    .modal-body\n",
       "                        img(src='assets/images/publication/ex_time_series_calssifier.png ' alt=\"immagine\" )\n",
       "    .col-lg-6.bg-yellow.p-3\n",
       "        #accordion-forty.accordion\n",
       "        | #[strong Explaining Any Time Series Classifier] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, Monreale Anna, Spinnato Francesco, Pedreschi Dino, Giannotti Fosca] (2020) - 2020 IEEE Second International Conference on Cognitive Machine Intelligence (CogMI)\n",
       "        #collapse-forty.collapse(aria-labelledby='heading-forty' data-parent='#accordion-forty')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small We present a method to explain the decisions of black box models for time series classification. The explanation consists of factual and counterfactual shapelet-based rules revealing the reasons for the classification, and of a set of exemplars and counter-exemplars highlighting similarities and differences with the time series under analysis. The proposed method first generates exemplar and counter-exemplar time series in the latent feature space and learns a local latent decision tree classifier. Then, it selects and decodes those respecting the decision rules explaining the decision. Finally, it learns on them a shapelet-tree that reveals the parts of the time series that must, and must not, be contained for getting the returned outcome from the black box. A wide experimentation shows that the proposed method provides faithful, meaningful and interpretable explanations.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                @inproceedings{Guidotti_2020,\n",
       "                    doi = {10.1109/cogmi50398.2020.00029},\n",
       "                    url = {https://doi.org/10.1109%2Fcogmi50398.2020.00029},\n",
       "                    year = 2020,\n",
       "                    month = {oct},\n",
       "                    publisher = {{IEEE}},\n",
       "                    author = {Riccardo Guidotti and Anna Monreale and Francesco Spinnato and Dino Pedreschi and Fosca Giannotti},\n",
       "                    title = {Explaining Any Time Series Classifier},\n",
       "                    booktitle = {2020 {IEEE} Second International Conference on Cognitive Machine Intelligence ({CogMI})}\n",
       "                }\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-forty' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='http://dx.doi.org/10.1109/cogmi50398.2020.00029', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 42.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-forty-one.accordion\n",
       "        | #[strong The AI black box explanation problem] \n",
       "        br\n",
       "        | #[em Guidotti Riccardo, Monreale Anna, Pedreschi Dino] (2019) - ERCIM News, 116, 12-13. In ERCIM News, 116, 12-13\n",
       "        #collapse-forty-one.collapse(aria-labelledby='heading-forty-one' data-parent='#accordion-forty-one')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small nan\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        \n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://ercim-news.ercim.eu/images/stories/EN116/EN116-web.pdf#page=12', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1▪2▪3]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 43.\n",
       "    .col-lg-2.pl-0\n",
       "        img(src='assets/images/publication/mulino_pandemia.jpg ' alt=\"immagine\" style='width:100%;' data-toggle='modal' data-target='#modal-forty-two' type='button').mr-3\n",
       "        #modal-forty-two.modal.fade(tabindex='-1' role='dialog' aria-labelledby='#modal-forty-two-Title' aria-hidden='true')\n",
       "            .modal-dialog.modal-lg.modal-dialog-centered(role='document')\n",
       "                .modal-content\n",
       "                    .modal-header\n",
       "                        p.small I.A. comprensibile per il supporto alle decisioni: doctor XAI\n",
       "                        button.close(type='button' data-dismiss='modal' aria-label='Close')\n",
       "                            span(aria-hidden='true') &times;\n",
       "                    .modal-body\n",
       "                        img(src='assets/images/publication/mulino_pandemia.jpg ' alt=\"immagine\" )\n",
       "    .col-lg-6.bg-yellow.p-3\n",
       "        #accordion-forty-two.accordion\n",
       "        | #[strong I.A. comprensibile per il supporto alle decisioni: doctor XAI] \n",
       "        br\n",
       "        | #[em Giannotti Fosca, Pedreschi Dino, Panigutti Cecilia] (2019) - Biopolitica, Pandemia e democrazia. Rule of law nella società digitale. In BIOPOLITICA, PANDEMIA E DEMOCRAZIA Rule of law nella società digitale\n",
       "        #collapse-forty-two.collapse(aria-labelledby='heading-forty-two' data-parent='#accordion-forty-two')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small La crisi sanitaria ha trasformato le relazioni tra Stato e cittadini, conducendo a limitazioni temporanee dei diritti fondamentali e facendo emergere conflitti tra le due dimensioni della salute, come diritto della persona e come diritto della comunità, e tra il diritto alla salute e le esigenze del sistema economico. Per far fronte all’emergenza, si è modificato il tradizionale equilibrio tra i poteri dello Stato, in una prospettiva in cui il tempo dell’emergenza sembra proiettarsi ancora a lungo sul futuro. La pandemia ha inoltre potenziato la centralità del digitale, dall’utilizzo di software di intelligenza artificiale per il tracciamento del contagio alla nuova connettività del lavoro remoto, passando per la telemedicina. Le nuove tecnologie svolgono un ruolo di prevenzione e controllo, ma pongono anche delicate questioni costituzionali: come tutelare la privacy individuale di fronte al Panopticon digitale? Come inquadrare lo statuto delle piattaforme digitali, veri e propri poteri tecnologici privati, all’interno dei nostri ordinamenti? La ricerca presentata in questo volume e nei due volumi collegati propone le riflessioni su questi temi di studiosi afferenti a una moltitudine di aree disciplinari: medici, giuristi, ingegneri, esperti di robotica e di IA analizzano gli effetti dell’emergenza sanitaria sulla tenuta del modello democratico occidentale, con l’obiettivo di aprire una riflessione sulle linee guida per la ricostruzione del Paese, oltre la pandemia. In particolare, questo terzo volume affronta gli aspetti legati all’impatto della tecnologia digitale e dell’IA sui processi, sulla scuola e sulla medicina, con una riflessione su temi quali l’organizzazione della giustizia, le responsabilità, le carenze organizzative degli enti.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-forty-two' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://www.mulino.it/isbn/9788815293060#', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 3]\n",
       ".row.mt-4.justify-content-center\n",
       "    .col-lg-1.text-right\n",
       "        h4 44.\n",
       "    .col-lg-8.bg-yellow.p-3\n",
       "        #accordion-forty-three.accordion\n",
       "        | #[strong Open the Black Box Data-Driven Explanation of Black Box Decision Systems] \n",
       "        br\n",
       "        | #[em Dino Pedreschi, Fosca Giannotti, Riccardo Guidotti, Anna Monreale, Luca Pappalardo, Salvatore Ruggieri, Franco Turini] (2018) - Arxive preprint\n",
       "        #collapse-forty-three.collapse(aria-labelledby='heading-forty-three' data-parent='#accordion-forty-three')\n",
       "            div.bg-yellow\n",
       "                hr\n",
       "                p.small #[strong Abstract]\n",
       "                p.small Black box systems for automated decision making, often based on machine learning over (big) data, map a user's features into a class or a score without exposing the reasons why. This is problematic not only for lack of transparency, but also for possible biases hidden in the algorithms, due to human prejudices and collection artifacts hidden in the training data, which may lead to unfair or wrong decisions. We introduce the local-to-global framework for black box explanation, a novel approach with promising early results, which paves the road for a wide spectrum of future developments along three dimensions: (i) the language for expressing explanations in terms of highly expressive logic-based rules, with a statistical and causal interpretation; (ii) the inference of local explanations aimed at revealing the logic of the decision adopted for a specific instance by querying and auditing the black box in the vicinity of the target instance; (iii), the bottom-up generalization of the many local explanations into simple global ones, with algorithms that optimize the quality and comprehensibility of explanations.\n",
       "            p.small.pt-2 #[strong BibTex]\n",
       "            p.small.\n",
       "                BibTex not found\n",
       "    .col-lg-2.pl-3\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='#' data-toggle='collapse' data-target='#collapse-forty-three' aria-expanded='true' aria-controls='collapseAbs') More information\n",
       "        p.my-1\n",
       "            a.btn-mini.px-2.btn-secondary.small(href='https://arxiv.org/abs/1806.09936', target=\"_blank\") External Link\n",
       "        p.my-1\n",
       "                small Research Line #[strong 1]\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(cards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_html(cards, filename='paper-cards')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name= sheet_names[3]\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Thesis #', 'Thesis ', 'Title', 'Author', 'Tutor',\n",
       "       'Status [Ongoing] / [completed]', 'Year', 'visible on website',\n",
       "       'Abstract'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterThesis = pd.read_csv(url)\n",
    "masterThesis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thesis #</th>\n",
       "      <th>Thesis</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tutor</th>\n",
       "      <th>Status [Ongoing] / [completed]</th>\n",
       "      <th>Year</th>\n",
       "      <th>visible on website</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>A Model Agnostic Local Explainer for Time Seri...</td>\n",
       "      <td>Francesco Spinnato</td>\n",
       "      <td>Guidotti, Monreale</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>Increasing the Interpretability of Deep Recurr...</td>\n",
       "      <td>Michele Resta</td>\n",
       "      <td>Monreale</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>Privacy risk analysis of LIME explanations</td>\n",
       "      <td>Francesco Sabiu</td>\n",
       "      <td>Monreale</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Phd Thesis</td>\n",
       "      <td>Understanding and Exploiting the Latent Space ...</td>\n",
       "      <td>Francesco Bodria</td>\n",
       "      <td>Giannotti Guidotti</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2019</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Phd Thesis</td>\n",
       "      <td>Opening the Black Box: Empowering Machine Lear...</td>\n",
       "      <td>Mattia Setzu</td>\n",
       "      <td>Monreale, Pedreschi</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2021</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Phd Thesis</td>\n",
       "      <td>eXplainable AI for trustworthy healthcare appl...</td>\n",
       "      <td>Cecilia Panigutti</td>\n",
       "      <td>Pedreschi</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2017</td>\n",
       "      <td>YES</td>\n",
       "      <td>Acknowledging that AI will inevitably become a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Phd Thesis</td>\n",
       "      <td>The relationship between privacy and explanations</td>\n",
       "      <td>Francesca Naretto</td>\n",
       "      <td>Giannotti Monreale</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2019</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Phd Thesis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Giovanni Puccetti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2021</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Phd Thesis</td>\n",
       "      <td>Explanation Methods for Sequential Data Models</td>\n",
       "      <td>Francesco Spinnato</td>\n",
       "      <td>Guidotti, Monreale</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2021</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>Explaining Siamese Networks in Few-Shot Learni...</td>\n",
       "      <td>Andrea Fedele</td>\n",
       "      <td>Guidotti</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>Semantic enrichment of XAI explanations for he...</td>\n",
       "      <td>Luca Corbucci</td>\n",
       "      <td>Monreale, Panigutti</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2021</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>Design and Application of ProtopNET for Audio ...</td>\n",
       "      <td>Andrea dell'Abate</td>\n",
       "      <td>Guidotti Fidecaro</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2022</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>X-Bot: Development of a Model and Data Agnosti...</td>\n",
       "      <td>Reza Puarrim</td>\n",
       "      <td>Giannotti Guidotti</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2021</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Phd Thesis</td>\n",
       "      <td>Causal Explainable Artificial Intelligence</td>\n",
       "      <td>Isacco Beretta</td>\n",
       "      <td>Pedreschi, Ruggieri</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2021</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>Deriving a Single Interpretable Model by Mergi...</td>\n",
       "      <td>Valerio Bonsignori</td>\n",
       "      <td>Monreale Guidotti</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2021</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>FairShades: Fairness Auditing in Abusive Langu...</td>\n",
       "      <td>Marta Marchiori Manerba</td>\n",
       "      <td>Guidotti</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2021</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor Thesis</td>\n",
       "      <td>Matrix Profile-based Interpretable Time Series...</td>\n",
       "      <td>Matteo D'Onofrio</td>\n",
       "      <td>Guidotti</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2021</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Phd Thesis</td>\n",
       "      <td>FairCheck: Fairness Checking and Debiasing in ...</td>\n",
       "      <td>Marta Marchiori Manerba</td>\n",
       "      <td>Guidotti Ruggieri</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2021</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PhD Thesis</td>\n",
       "      <td>Machine Learning Explanation as Human-machine ...</td>\n",
       "      <td>Giovanni Camarda</td>\n",
       "      <td>Giannotti Pedreschi</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2021</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PhD Thesis</td>\n",
       "      <td>Mechanicistic Explanation of NN based prediction</td>\n",
       "      <td>Robin Thierrault</td>\n",
       "      <td>Giannotti</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2021</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PhD Thesis</td>\n",
       "      <td>Fairness assessment in decentralized ML</td>\n",
       "      <td>Fontana</td>\n",
       "      <td>Giannotti Monreale</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2021</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>Explanation of Cardiovascular Risk Model Estim...</td>\n",
       "      <td>Alessandra Galassi</td>\n",
       "      <td>Rinzivillo</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>Non-melanoma skin cancer image classification ...</td>\n",
       "      <td>Valenzano Raffaele</td>\n",
       "      <td>Rinzivillo</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2020</td>\n",
       "      <td>NO, tesi secretata da azienda tirocinio</td>\n",
       "      <td>Non-melanoma skin cancers are frequently occur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Master Thesis</td>\n",
       "      <td>An explainability framework for fiscal fradu d...</td>\n",
       "      <td>Valeria Messina</td>\n",
       "      <td>Rinzivillo, Monreale</td>\n",
       "      <td>On Going</td>\n",
       "      <td>2022</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Thesis #          Thesis   \\\n",
       "0        1.0    Master Thesis   \n",
       "1        2.0    Master Thesis   \n",
       "2        3.0    Master Thesis   \n",
       "3        4.0       Phd Thesis   \n",
       "4        5.0       Phd Thesis   \n",
       "5        6.0       Phd Thesis   \n",
       "6        7.0       Phd Thesis   \n",
       "7        NaN       Phd Thesis   \n",
       "8        NaN       Phd Thesis   \n",
       "9        NaN    Master Thesis   \n",
       "10       NaN    Master Thesis   \n",
       "11       NaN    Master Thesis   \n",
       "12       NaN    Master Thesis   \n",
       "13       NaN       Phd Thesis   \n",
       "14       NaN    Master Thesis   \n",
       "15       NaN    Master Thesis   \n",
       "16       NaN  Bachelor Thesis   \n",
       "17       NaN       Phd Thesis   \n",
       "18       NaN       PhD Thesis   \n",
       "19       NaN       PhD Thesis   \n",
       "20       NaN       PhD Thesis   \n",
       "21       NaN    Master Thesis   \n",
       "22       NaN    Master Thesis   \n",
       "23       NaN    Master Thesis   \n",
       "\n",
       "                                                Title  \\\n",
       "0   A Model Agnostic Local Explainer for Time Seri...   \n",
       "1   Increasing the Interpretability of Deep Recurr...   \n",
       "2          Privacy risk analysis of LIME explanations   \n",
       "3   Understanding and Exploiting the Latent Space ...   \n",
       "4   Opening the Black Box: Empowering Machine Lear...   \n",
       "5   eXplainable AI for trustworthy healthcare appl...   \n",
       "6   The relationship between privacy and explanations   \n",
       "7                                                 NaN   \n",
       "8      Explanation Methods for Sequential Data Models   \n",
       "9   Explaining Siamese Networks in Few-Shot Learni...   \n",
       "10  Semantic enrichment of XAI explanations for he...   \n",
       "11  Design and Application of ProtopNET for Audio ...   \n",
       "12  X-Bot: Development of a Model and Data Agnosti...   \n",
       "13         Causal Explainable Artificial Intelligence   \n",
       "14  Deriving a Single Interpretable Model by Mergi...   \n",
       "15  FairShades: Fairness Auditing in Abusive Langu...   \n",
       "16  Matrix Profile-based Interpretable Time Series...   \n",
       "17  FairCheck: Fairness Checking and Debiasing in ...   \n",
       "18  Machine Learning Explanation as Human-machine ...   \n",
       "19   Mechanicistic Explanation of NN based prediction   \n",
       "20            Fairness assessment in decentralized ML   \n",
       "21  Explanation of Cardiovascular Risk Model Estim...   \n",
       "22  Non-melanoma skin cancer image classification ...   \n",
       "23  An explainability framework for fiscal fradu d...   \n",
       "\n",
       "                     Author                 Tutor  \\\n",
       "0        Francesco Spinnato    Guidotti, Monreale   \n",
       "1             Michele Resta              Monreale   \n",
       "2           Francesco Sabiu              Monreale   \n",
       "3          Francesco Bodria    Giannotti Guidotti   \n",
       "4              Mattia Setzu   Monreale, Pedreschi   \n",
       "5         Cecilia Panigutti             Pedreschi   \n",
       "6         Francesca Naretto    Giannotti Monreale   \n",
       "7         Giovanni Puccetti                   NaN   \n",
       "8        Francesco Spinnato    Guidotti, Monreale   \n",
       "9             Andrea Fedele              Guidotti   \n",
       "10            Luca Corbucci   Monreale, Panigutti   \n",
       "11        Andrea dell'Abate     Guidotti Fidecaro   \n",
       "12             Reza Puarrim    Giannotti Guidotti   \n",
       "13           Isacco Beretta   Pedreschi, Ruggieri   \n",
       "14       Valerio Bonsignori     Monreale Guidotti   \n",
       "15  Marta Marchiori Manerba              Guidotti   \n",
       "16         Matteo D'Onofrio              Guidotti   \n",
       "17  Marta Marchiori Manerba     Guidotti Ruggieri   \n",
       "18         Giovanni Camarda   Giannotti Pedreschi   \n",
       "19         Robin Thierrault             Giannotti   \n",
       "20                  Fontana    Giannotti Monreale   \n",
       "21       Alessandra Galassi            Rinzivillo   \n",
       "22       Valenzano Raffaele            Rinzivillo   \n",
       "23          Valeria Messina  Rinzivillo, Monreale   \n",
       "\n",
       "   Status [Ongoing] / [completed]  Year  \\\n",
       "0                       Completed  2020   \n",
       "1                       Completed  2020   \n",
       "2                       Completed  2020   \n",
       "3                        On Going  2019   \n",
       "4                       Completed  2021   \n",
       "5                       Completed  2017   \n",
       "6                        On Going  2019   \n",
       "7                        On Going  2021   \n",
       "8                        On Going  2021   \n",
       "9                       Completed  2022   \n",
       "10                      Completed  2021   \n",
       "11                       On Going  2022   \n",
       "12                      Completed  2021   \n",
       "13                       On Going  2021   \n",
       "14                      Completed  2021   \n",
       "15                      Completed  2021   \n",
       "16                      Completed  2021   \n",
       "17                       On Going  2021   \n",
       "18                       On Going  2021   \n",
       "19                       On Going  2021   \n",
       "20                       On Going  2021   \n",
       "21                      Completed  2020   \n",
       "22                      Completed  2020   \n",
       "23                       On Going  2022   \n",
       "\n",
       "                         visible on website  \\\n",
       "0                                       YES   \n",
       "1                                       YES   \n",
       "2                                       YES   \n",
       "3                                       YES   \n",
       "4                                       YES   \n",
       "5                                       YES   \n",
       "6                                       YES   \n",
       "7                                        NO   \n",
       "8                                       YES   \n",
       "9                                       YES   \n",
       "10                                      YES   \n",
       "11                                      YES   \n",
       "12                                      YES   \n",
       "13                                      YES   \n",
       "14                                       NO   \n",
       "15                                       NO   \n",
       "16                                      YES   \n",
       "17                                       NO   \n",
       "18                                      YES   \n",
       "19                                      YES   \n",
       "20                                       NO   \n",
       "21                                      YES   \n",
       "22  NO, tesi secretata da azienda tirocinio   \n",
       "23                                      YES   \n",
       "\n",
       "                                             Abstract  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5   Acknowledging that AI will inevitably become a...  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  \n",
       "20                                                NaN  \n",
       "21                                                NaN  \n",
       "22  Non-melanoma skin cancers are frequently occur...  \n",
       "23                                                NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterThesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterThesis=masterThesis.sort_values(['Thesis ','Status [Ongoing] / [completed]'],ascending=[False,True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul><li>Mattia Setzu, <strong>Opening the Black Box: Empowering Machine Learning Models with Explanations</strong> [Phd Thesis - 2021 - Completed]</li><li>Cecilia Panigutti, <strong>eXplainable AI for trustworthy healthcare applications</strong> [Phd Thesis - 2017 - Completed]</li><li>Francesco Bodria, <strong>Understanding and Exploiting the Latent Space of Machine Learning Models</strong> [Phd Thesis - 2019 - On Going]</li><li>Francesca Naretto, <strong>The relationship between privacy and explanations</strong> [Phd Thesis - 2019 - On Going]</li><li>Francesco Spinnato, <strong>Explanation Methods for Sequential Data Models</strong> [Phd Thesis - 2021 - On Going]</li><li>Isacco Beretta, <strong>Causal Explainable Artificial Intelligence</strong> [Phd Thesis - 2021 - On Going]</li><li>Giovanni Camarda, <strong>Machine Learning Explanation as Human-machine collaboration</strong> [PhD Thesis - 2021 - On Going]</li><li>Robin Thierrault, <strong>Mechanicistic Explanation of NN based prediction</strong> [PhD Thesis - 2021 - On Going]</li><li>Francesco Spinnato, <strong>A Model Agnostic Local Explainer for Time Series Black-Box Classifiers</strong> [Master Thesis - 2020 - Completed]</li><li>Michele Resta, <strong>Increasing the Interpretability of Deep Recurrent Models for Biomedical Signals Analysis</strong> [Master Thesis - 2020 - Completed]</li><li>Francesco Sabiu, <strong>Privacy risk analysis of LIME explanations</strong> [Master Thesis - 2020 - Completed]</li><li>Andrea Fedele, <strong>Explaining Siamese Networks in Few-Shot Learning for Audio Data</strong> [Master Thesis - 2022 - Completed]</li><li>Luca Corbucci, <strong>Semantic enrichment of XAI explanations for healthcare</strong> [Master Thesis - 2021 - Completed]</li><li>Reza Puarrim, <strong>X-Bot: Development of a Model and Data Agnostic Chatbot for Explaining the Decisions of Black Box Classifiers</strong> [Master Thesis - 2021 - Completed]</li><li>Alessandra Galassi, <strong>Explanation of Cardiovascular Risk Model Estimator</strong> [Master Thesis - 2020 - Completed]</li><li>Andrea dell'Abate, <strong>Design and Application of ProtopNET for Audio Data</strong> [Master Thesis - 2022 - On Going]</li><li>Valeria Messina, <strong>An explainability framework for fiscal fradu detection classifier [provvisorio]</strong> [Master Thesis - 2022 - On Going]</li><li>Matteo D'Onofrio, <strong>Matrix Profile-based Interpretable Time Series Classifier</strong> [Bachelor Thesis - 2021 - Completed]</li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bulletsThesis='<ul>'\n",
    "\n",
    "for i, row in masterThesis.iterrows():\n",
    "    author= row['Author']\n",
    "    title= row['Title']\n",
    "    title = '' if title!=title else title\n",
    "    \n",
    "    status= row['Status [Ongoing] / [completed]']\n",
    "    \n",
    "    classification = row['Thesis ']\n",
    "    year= row['Year']\n",
    "    bullet=f\"<li>{author}, <strong>{title}</strong> [{classification} - {year} - {status}]</li>\"\n",
    "    if row['visible on website'] == 'YES':\n",
    "        bulletsThesis+=bullet\n",
    "bulletsThesis+='</ul>'\n",
    "display(HTML(bulletsThesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<ul><li>Francesco Spinnato, <strong>A Model Agnostic Local Explainer for Time Series Black-Box Classifiers</strong> [Master Thesis - 2020.0 - Completed]</li><li>Michele Resta, <strong>Increasing the Interpretability of Deep Recurrent Models for Biomedical Signals Analysis</strong> [Master Thesis - 2020.0 - Completed]</li><li>Francesco Sabiu, <strong>Privacy risk analysis of LIME explanations</strong> [Master Thesis - 2020.0 - Completed]</li><li>Francesco Bodria, <strong>Understanding and Exploiting the Latent Space of Machine Learning Models</strong> [Phd Thesis - 2019.0 - On Going]</li><li>Mattia Setzu, <strong>Opening the Black Box: Empowering Machine Learning Models with Explanations</strong> [Phd Thesis - 2021.0 - On Going]</li><li>Cecilia Panigutti, <strong>eXplainable AI for trustworthy healthcare applications</strong> [Phd Thesis - 2017.0 - On Going]</li><li>Francesca Naretto, <strong>The relationship between privacy and explanations</strong> [Phd Thesis - 2019.0 - On Going]</li></ul>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulletsThesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "li\n",
       "    div.mb-3\n",
       "        | Francesco Spinnato - #[strong A Model Agnostic Local Explainer for Time Series Black-Box Classifiers]. [Master Thesis - 2020 - Completed]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Michele Resta - #[strong Increasing the Interpretability of Deep Recurrent Models for Biomedical Signals Analysis]. [Master Thesis - 2020 - Completed]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Francesco Sabiu - #[strong Privacy risk analysis of LIME explanations]. [Master Thesis - 2020 - Completed]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Francesco Bodria - #[strong Understanding and Exploiting the Latent Space of Machine Learning Models]. [Phd Thesis - 2019 - On Going]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Mattia Setzu - #[strong Opening the Black Box: Empowering Machine Learning Models with Explanations]. [Phd Thesis - 2021 - Completed]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Cecilia Panigutti - #[strong eXplainable AI for trustworthy healthcare applications]. [Phd Thesis - 2017 - Completed]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Francesca Naretto - #[strong The relationship between privacy and explanations]. [Phd Thesis - 2019 - On Going]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Francesco Spinnato - #[strong Explanation Methods for Sequential Data Models]. [Phd Thesis - 2021 - On Going]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Andrea Fedele - #[strong Explaining Siamese Networks in Few-Shot Learning for Audio Data]. [Master Thesis - 2022 - Completed]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Luca Corbucci - #[strong Semantic enrichment of XAI explanations for healthcare]. [Master Thesis - 2021 - Completed]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Andrea dell'Abate - #[strong Design and Application of ProtopNET for Audio Data]. [Master Thesis - 2022 - On Going]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Reza Puarrim - #[strong X-Bot: Development of a Model and Data Agnostic Chatbot for Explaining the Decisions of Black Box Classifiers]. [Master Thesis - 2021 - Completed]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Isacco Beretta - #[strong Causal Explainable Artificial Intelligence]. [Phd Thesis - 2021 - On Going]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Matteo D'Onofrio - #[strong Matrix Profile-based Interpretable Time Series Classifier]. [Bachelor Thesis - 2021 - Completed]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Giovanni Camarda - #[strong Machine Learning Explanation as Human-machine collaboration]. [PhD Thesis - 2021 - On Going]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Robin Thierrault - #[strong Mechanicistic Explanation of NN based prediction]. [PhD Thesis - 2021 - On Going]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Alessandra Galassi - #[strong Explanation of Cardiovascular Risk Model Estimator]. [Master Thesis - 2020 - Completed]\n",
       "li\n",
       "    div.mb-3\n",
       "        | Valeria Messina - #[strong An explainability framework for fiscal fradu detection classifier [provvisorio]]. [Master Thesis - 2022 - On Going]\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bulletsThesis=''\n",
    "for i, row in masterThesis.iterrows():\n",
    "    author= row['Author']\n",
    "    title= row['Title']\n",
    "    title = '' if title!=title else title\n",
    "    \n",
    "    status= row['Status [Ongoing] / [completed]']\n",
    "    \n",
    "    classification = row['Thesis ']\n",
    "    year= row['Year']\n",
    "    \n",
    "    bullet=f'''li\n",
    "    div.mb-3\n",
    "        | {author} - #[strong {title}]. [{classification} - {year} - {status}]\n",
    "'''\n",
    "    if row['visible on website'] == 'YES':\n",
    "        bulletsThesis+=bullet\n",
    "    \n",
    "#     bullet=f\"<li>{author}, <strong>{title}</strong> [{classification} - {year} - {status}]</li>\"\n",
    "display(HTML(bulletsThesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_html(bulletsThesis, filename='thesis-list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms made by XAI group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name= sheet_names[2]\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Authors', 'Title', 'github link', 'Brief Description',\n",
       "       'visible on website'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = pd.read_csv(url)\n",
    "algo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul><li><strong>Lore (A,B,C)</strong>  [ Guidotti ] </li><li><strong>ABELE</strong>  [ Guidotti ] </li><li><strong>GlocalX</strong>  [ Setzu ] </li><li><strong>LASTS</strong>  [ Spinnato ] </li><li><strong>DoctorXAI</strong>  - DoctorXAI is an ontology-based approach to black box sequential data classification explanations,  [ Panigutti ] </li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bulletsAlgo='<ul>'\n",
    "\n",
    "for i, row in algo.iterrows():\n",
    "    author= row['Authors']\n",
    "    title= row['Title']\n",
    "    title = '' if title!=title else title\n",
    "    \n",
    "    description= row['Brief Description']\n",
    "    description = '' if description!=description else ' - '+description.strip('.')+', '\n",
    "    \n",
    "    githubLink=row['github link']\n",
    "    \n",
    "    bullet=f\"<li><strong>{title}</strong> {description} [ {author} ] </li>\"\n",
    "    bulletsAlgo+=bullet\n",
    "bulletsAlgo+='</ul>'\n",
    "display(HTML(bulletsAlgo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
