extends includes/layout
include includes/mixin

block content

  article.entry
    .entry-content
      .twenty-percent-bg-yellow
        .container.pt-lg-4.pt-md-4.pt-4.pb-6
          .row.gx-lg-5.mt-3
            .col-lg-6.col-md-8s
              h3.text-black.text-uppercase.py-lg-6.mb-0 Science and technology for the explanation of ai decision making.
              p.lead.mb-5.mt-sm-3 The XAI project, focuses on the urgent open challenge of how to construct meaningful explanations of opaque AI/ML systems in the context of ai based decision making, aiming at empowering individual against undesired effects of automated decision making, implementing the “right of explanation”, helping people make better decisions preserving (and expand) human autonomy.
                |
                |
            .col-lg-6.pt-lg-2.pb-lg-7.mt-lg-8
              .bg-black
                .py-lg-6.px-lg-6.py-md-5.px-md-5.py-5.px-4
                  a(href='https://cordis.europa.eu/project/id/834756' target='_blank')
                    h4.text-yellow.mb-3 Project Information
                    div.lead.text-white
                      p.mb-0.text-white Grant agreement ID: 834756
                      p.mb-0 Call: #[em ERC-2018-ADG]
                      p.mb-0 Total cost: #[em 2 500 000€]
                      p.mb-4 EU Contribution: #[em 2 500 000€]
                      p.mb-0 Principal investigator: #[em Fosca Giannotti]
                      p.mb-0 Email: #[em fosca.giannotti @ sns.it]

      .container.mb-4
        .row.justify-content-lg-center
          .col-lg-8
            p.lead Black box AI systems for automated decision making, often based on ML over (big) data, map a user’s features into a class or a score without exposing the reasons why. This is problematic both for the lack of transparency and also for possible biases inherited by the algorithms from prejudices and collection artifacts hidden in the training data, which may lead to unfair or wrong decisions. The future of AI lies in enabling people to collaborate with machines, requiring good communication, trust, clarity, and understanding.
            ol.mt-4 This project aims at developing:
              li.mt-2 an explanation infrastructure for benchmarking, equipped with platforms for the users' assessment of the explanations;
              li an ethical-legal framework, in compliance with the provisions of the GDPR;
              li a repertoire of case studies in explanation-by-design, mainly focused on health and fraud detection applications.
            |
            div.pb-md-2.mt-4
              a.btn.btn-outline-black(href="about.html") MORE ON THE PROJECT

    // Last News SECTION
    .entry-content#news
      // head blog
      .bg-yellow
        .container.pt-lg-5.pb-lg-5.pt-md-7.pb-md-5.pt-5.pb-4
          .row
            .col-lg-6
              h1.my-3 Last News
              p.lead Events, tutorials, round tables, conferences and more...
      // blog
      .container.my-lg-9.my-md-7.my-6
        h2.mb-lg-5.mb-md-4.mb-3
        +blogLast(
          'card-post-style',
          'col-lg-4 col-12',
          false,
          news
        )
        |
        div.pb-md-2.mt-4.text-center
          a.btn.btn-outline-black(href="news.html") READ ALL NEWS

    // PARTNERS SECTION
    .entry-content
      .bg-yellow
        .container.py-lg-5.py-md-7.py-5
          .row
            .col-lg-6
              h1.my-3 Partners​
              //- p.lead Consetetur lorem ipsum dolor sit amet, sadipscing elitr,
    .entry-content.mt-5
      .bg-grayphite
        .container.mb-lg-1.mb-md-1.mb-1
          .row.gx-lg-5.gy-5
            .col-lg-4
              .text-center.align-items-center
                .px-lg-5.mt-lg-4.px-5.mt-4.mb-5
                  img(src="assets/images/logo_normale.jpg" alt="Normale").rounded-circle
                  .px-lg-4.px-4
                    .mt-lg-4.mt-5
                      h4 Scuola Normale Superiore
            .col-lg-4
              .text-center.align-items-center
                .px-lg-5.mt-lg-4.px-5.mt-4.mb-5
                  img(src="assets/images/logo_Cnr.jpg" alt="CNR").rounded-circle
                  .px-lg-4.px-4
                    .mt-lg-4.mt-5
                      h4 CNR
                    .px-lg-4.px-4
                      p National Research Council
            .col-lg-4
              .text-center.align-items-center
                .px-lg-5.mt-lg-4.px-5.mt-4.mb-5
                  img(src="assets/images/logo_unipi.jpg" alt="Unipi").rounded-circle
                  .px-lg-4.px-4
                  .mt-lg-4.mt-5
                    h4 University of Pisa
                  .px-lg-4.px-4
                    p Department of Computer Science
    //- Research lines title
    .entry-content.mt-0
      .twenty-percent-bg-yellow
        .container.px-3.py-5
          .row
            .col-lg-6.col-md-6.ml-lg-4.p-lg-4.bg-black.text-white
              .pr-lg-5
                h1.text-yellow The 5 XAI #[br] research lines
                div
                  //- p.text-white Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore.
      .container
        .row.justify-content-lg-center
          .col-lg-6
            p.mt-4 The XAI project faces the challenge of requiring AI to be explainable and understandable in human terms and articulates its research along 5 Research Activities: #[a(href='/line_1.html') #[strong 1] algorithms to infer local explanations and their generalization to global ones (post-hoc) and algorithms that are transparent by-design]; #[a(href='/line_2.html') #[strong 2] languages for expressing explanations in terms of logic rules, with statistical and causal interpretation];  #[a(href='/line_3.html') #[strong 3] XAI watchdog platform for sharing experimental dataset and explanation algorithms; #[a(href='/line_4.html') #[strong 4]] a repertoire of case studies aimed at in involving also final users] ; #[a(href='/line_5.html') #[strong 5] a framework to study the interplay between XAI and ethical and legal dimensions.]
    .entry-content.mt-4
      .container
        .row.mt-0.text-center.justify-content-center
          .col-lg-6
            .row
              .col-md-6.mb-4
                a(href='/line_1.html')
                  .bg-yellow.px-5.py-5.line-numbers-box
                    h1.mb-3 1
                    h4.mb-3 Local-to-global paradigm for explanation by design
                    //- p Research manager #[br]#[em Mario Rossi]
              .col-md-6.mb-4
                a(href='/line_2.html')
                  .bg-black.px-5.py-5.line-numbers-box
                    .text-white
                      h1.mb-3 2
                      h4.mb-3 From statistical to causal and mechanistic, physical explanations
                      //- p Research manager #[br]#[em Mario Rossi]
              .col-md-6.mb-4
                a(href='/line_3.html')
                  .bg-grayphite.px-5.py-5.line-numbers-box
                    .text-black
                      h1.mb-3 3
                      h4.mb-3 XAI #[br] platform
                      //- p Research manager #[br]#[em Mario Rossi]
              .col-md-6.mb-4
                a(href='/line_4.html')
                  .bg-yellow.px-5.py-5.line-numbers-box
                    .text-black
                      h1.mb-3 4
                      h4.mb-3 Case#[br]studies
                      //- p Research manager #[br]#[em Mario Rossi]
              .col-md-12.mb-4
                a(href='/line_5.html')
                  .bg-black.px-5.pt-4.pb-1.line-numbers-box-half.text-white
                    .text-white
                      h1.mb-3 5
                      h4.mb-3 Ethical/legal framework #[br] for explanation
                      //- p Research manager #[br]#[em Mario Rossi]
