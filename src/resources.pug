extends includes/layout
include includes/mixin

block content

  article.entry
    .entry-content
    .bg-yellow
      .container.pt-lg-8.pb-lg-5.pt-md-7.pb-md-5.pt-5.pb-4
        .row
          .col-lg-6
            h1.my-3 Resources
            //- p.lead Consetetur lorem ipsum dolor sit amet, sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua.
    .entry-content
      .container.mb-4
        .row
          .col-12
            h1 Publications
        .row.justify-content-lg-center
          .col-lg-6
            ol
              li
                div.mb-3
                  | Guidotti, R. (2020). Evaluating local explanation methods on ground truth. Artificial Intelligence, 103428.
              li
                div.mb-3
                  | Bodria, F., Panisson, A., Perotti, A., & Piaggesi, S. Explainability Methods for Natural Language Processing: Applications to Sentiment Analysis (Discussion Paper).
              li
                div.mb-3
                  | Panigutti, C., Perotti, A., & Pedreschi, D. (2020, January). Doctor XAI: an ontology-based approach to black-box sequential data classification explanations. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 629-639).
              li
                div.mb-3
                  | Cecilia Panigutti, Alan Perotti, Andrè Panisson, Paolo Bajardi, Dino Pedreschi (2020, November). FairLens: Auditing Black-box Clinical Decision Support Systems. arXiv preprint. arXiv:2011.04049
              li
                div.mb-3
                  | Lampridis, O., Guidotti, R., & Ruggieri, S. (2020, October). Explaining Sentiment Classification with Synthetic Exemplars and Counter-Exemplars. In International Conference on Discovery Science (pp. 357-373). Springer, Cham.
              li
                div.mb-3
                  | Naretto, F., Pellungrini, R., Monreale, A., Nardini, F. M., & Musolesi, M. (2020, October). Predicting and Explaining Privacy Risk Exposure in Mobility Data. In International Conference on Discovery Science (pp. 403-418). Springer, Cham.
              li
                div.mb-3
                  | Monreale, A. Rischi etico-legali dell’Intelligenza Artificiale. DPCE Online, [S.l.], v. 44, n. 3, oct. 2020. ISSN 2037-6677.
              li
                div.mb-3
                  | Guidotti, R., Monreale, A., Matwin, S., & Pedreschi, D. (2020). Explaining Image Classifiers Generating Exemplars and Counter-Exemplars from Latent Representations. In AAAI (pp. 13665-13668).
              li
                div.mb-3
                  | Guidotti, R., Monreale, A., Matwin, S., & Pedreschi, D. (2019, September). Black Box Explanation by Learning Image Exemplars in the Latent Feature Space. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 189-205). Springer, Cham.
              li
                div.mb-3
                  | Guidotti, R., Monreale, A., Giannotti, F., Pedreschi, D., Ruggieri, S., & Turini, F. (2019). Factual and counterfactual explanations for black box decision making. IEEE Intelligent Systems, 34(6), 14-23.
              li
                div.mb-3
                  | Pedreschi, D., Giannotti, F., Guidotti, R., Monreale, A., Ruggieri, S., & Turini, F. (2019, July). Meaningful explanations of Black Box AI decision systems. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 33, pp. 9780-9784).
              li
                div.mb-3
                  | Setzu, M., Guidotti, R., Monreale, A., & Turini, F. (2019, September). Global Explanations with Local Scoring. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 159-171). Springer, Cham.
              li
                div.mb-3
                  | Panigutti, C., Guidotti, R., Monreale, A., & Pedreschi, D. (2019, January). Explaining multi-label black-box classifiers for health applications. In International Workshop on Health Intelligence (pp. 97-110). Springer, Cham.
              li
                div.mb-3
                  | Guidotti, R., Monreale, A., & Cariaggi, L. (2019, April). Investigating Neighborhood Generation Methods for Explanations of Obscure Image Classifiers. In Pacific-Asia Conference on Knowledge Discovery and Data Mining (pp. 55-68). Springer, Cham.
              li
                div.mb-3
                  | Guidotti, R., Monreale, A., & Pedreschi, D. (2019). The AI black box explanation problem. ERCIM News, 116, 12-13.
              li
                div.mb-3
                  | Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., & Pedreschi, D. (2018). A survey of methods for explaining black box models. ACM computing surveys (CSUR), 51(5), 1-42.
              li
                div.mb-3
                  | Guidotti, R., Monreale, A., Ruggieri, S., Pedreschi, D., Turini, F., & Giannotti, F. (2018). Local rule-based explanations of black box decision systems. arXiv preprint arXiv:1805.10820.
              li
                div.mb-3
                  | Guidotti, R., Soldani, J., Neri, D., Brogi, A., & Pedreschi, D. (2018, September). Helping your docker images to spread based on explainable models. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 205-221). Springer, Cham.
              li
                div.mb-3
                  | Pedreschi, D., Giannotti, F., Guidotti, R., Monreale, A., Pappalardo, L., Ruggieri, S., & Turini, F. (2018). Open the black box data-driven explanation of black box decision systems. arXiv preprint arXiv:1806.09936.
